INFO - utils.py - 2025-01-14 11:53:01,265 - {'setup': {'method': 'dpsgd-lora', 'run_type': 'normal', 'n_gpus_per_node': 1, 'n_nodes': 1, 'node_rank': 0, 'master_address': '127.0.0.1', 'master_port': 6025, 'omp_n_threads': 8, 'workdir': 'exp/dp-lora/fmnist_28_eps10.0val_large28-2025-01-14-11-53-01', 'local_rank': 0, 'global_rank': 0, 'global_size': 1, 'root_folder': '.'}, 'public_data': {'name': None, 'num_channels': 1, 'resolution': 28, 'n_classes': 1000, 'train_path': 'dataset/imagenet/imagenet_32', 'selective': {'ratio': 1.0}}, 'sensitive_data': {'name': 'fmnist', 'num_channels': 1, 'resolution': 28, 'n_classes': 10, 'train_path': 'dataset/fmnist/train_28.zip', 'test_path': 'dataset/fmnist/test_28.zip', 'fid_stats': 'dataset/fmnist/fid_stats_28.npz'}, 'model': {'ckpt': None, 'private_num_classes': 10, 'public_num_classes': 1000, 'local_rank': 0, 'global_rank': 0, 'global_size': 1}, 'pretrain': {'log_dir': 'exp/dp-lora/fmnist_28_eps10.0val_large28-2025-01-14-11-53-01/pretrain', 'autoencoder': {'config_path': None, 'n_epochs': 4, 'batch_size': 64, 'cond': True}, 'unet': {'config_path': './models/DP_LDM/configs/latent-diffusion/imagenet28-conditional_ours.yaml', 'pretrain_model': '/p/fzv6enresearch/DPImageBench/DP-LDM_for_merge/logs/2024-12-11T02-09-34_autoencoder_kl_imagenet28_28x28x1/checkpoints/last.ckpt', 'n_epochs': 160, 'batch_size': 1024, 'cond': True}, 'batch_size': 1024}, 'train': {'config_path': '/p/fzv6enresearch/DPImageBench/models/DP_LORA/configs/finetuning/28-dp-1.8M_nf64.yaml', 'pretrain_model': '/p/fzv6enresearch/DPImageBench/exp/dp-ldm/mnist_28_eps10.0val_large28-2025-01-12-07-43-03/pretrain/unet/checkpoints/last.ckpt', 'log_dir': 'exp/dp-lora/fmnist_28_eps10.0val_large28-2025-01-14-11-53-01/train', 'seed': 0, 'batch_size': 4096, 'n_epochs': 150, 'dp': {'sdq': None, 'max_grad_norm': 0.001, 'delta': 1e-05, 'epsilon': 10.0, 'max_physical_batch_size': 8192}, 'n_splits': 64}, 'gen': {'data_num': 60000, 'batch_size': 1000, 'log_dir': 'exp/dp-lora/fmnist_28_eps10.0val_large28-2025-01-14-11-53-01/gen', 'n_classes': 10}, 'eval': {'batch_size': 1000, 'mode': 'val'}}
INFO - dataset_loader.py - 2025-01-14 11:53:01,635 - delta is reset as 1.6657508770018431e-06
Epoch 0 is finished
Epoch 1 is finished
Epoch 2 is finished
Epoch 3 is finished
Epoch 4 is finished
Epoch 5 is finished
Epoch 6 is finished
Epoch 7 is finished
Epoch 8 is finished
Epoch 9 is finished
Epoch 10 is finished
Epoch 11 is finished
Epoch 12 is finished
Epoch 13 is finished
Epoch 14 is finished
Epoch 15 is finished
Epoch 16 is finished
Epoch 17 is finished
Epoch 18 is finished
Epoch 19 is finished
Epoch 20 is finished
Epoch 21 is finished
Epoch 22 is finished
Epoch 23 is finished
Epoch 24 is finished
Epoch 25 is finished
Epoch 26 is finished
Epoch 27 is finished
Epoch 28 is finished
Epoch 29 is finished
Epoch 30 is finished
Epoch 31 is finished
Epoch 32 is finished
Epoch 33 is finished
Epoch 34 is finished
Epoch 35 is finished
Epoch 36 is finished
Epoch 37 is finished
Epoch 38 is finished
Epoch 39 is finished
Epoch 40 is finished
Epoch 41 is finished
Epoch 42 is finished
Epoch 43 is finished
Epoch 44 is finished
Epoch 45 is finished
Epoch 46 is finished
Epoch 47 is finished
Epoch 48 is finished
Epoch 49 is finished
Epoch 50 is finished
Epoch 51 is finished
Epoch 52 is finished
Epoch 53 is finished
Epoch 54 is finished
Epoch 55 is finished
Epoch 56 is finished
Epoch 57 is finished
Epoch 58 is finished
Epoch 59 is finished
Epoch 60 is finished
Epoch 61 is finished
Epoch 62 is finished
Epoch 63 is finished
Epoch 64 is finished
Epoch 65 is finished
Epoch 66 is finished
Epoch 67 is finished
Epoch 68 is finished
Epoch 69 is finished
Epoch 70 is finished
Epoch 71 is finished
Epoch 72 is finished
Epoch 73 is finished
Epoch 74 is finished
Epoch 75 is finished
Epoch 76 is finished
Epoch 77 is finished
Epoch 78 is finished
Epoch 79 is finished
Epoch 80 is finished
Epoch 81 is finished
Epoch 82 is finished
Epoch 83 is finished
Epoch 84 is finished
Epoch 85 is finished
Epoch 86 is finished
Epoch 87 is finished
Epoch 88 is finished
Epoch 89 is finished
Epoch 90 is finished
Epoch 91 is finished
Epoch 92 is finished
Epoch 93 is finished
Epoch 94 is finished
Epoch 95 is finished
Epoch 96 is finished
Epoch 97 is finished
Epoch 98 is finished
Epoch 99 is finished
Epoch 100 is finished
Epoch 101 is finished
Epoch 102 is finished
Epoch 103 is finished
Epoch 104 is finished
Epoch 105 is finished
Epoch 106 is finished
Epoch 107 is finished
Epoch 108 is finished
Epoch 109 is finished
Epoch 110 is finished
Epoch 111 is finished
Epoch 112 is finished
Epoch 113 is finished
Epoch 114 is finished
Epoch 115 is finished
Epoch 116 is finished
Epoch 117 is finished
Epoch 118 is finished
Epoch 119 is finished
Epoch 120 is finished
Epoch 121 is finished
Epoch 122 is finished
Epoch 123 is finished
Epoch 124 is finished
Epoch 125 is finished
Epoch 126 is finished
Epoch 127 is finished
Epoch 128 is finished
Epoch 129 is finished
Epoch 130 is finished
Epoch 131 is finished
Epoch 132 is finished
Epoch 133 is finished
Epoch 134 is finished
Epoch 135 is finished
Epoch 136 is finished
Epoch 137 is finished
Epoch 138 is finished
Epoch 139 is finished
Epoch 140 is finished
Epoch 141 is finished
Epoch 142 is finished
Epoch 143 is finished
Epoch 144 is finished
Epoch 145 is finished
Epoch 146 is finished
Epoch 147 is finished
Epoch 148 is finished
Epoch 149 is finished
INFO - dpsgd_lora_sc.py - 2025-01-15 03:35:22,788 - Output:
Running on GPUs 0,
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 7.11 M params.
making attention of type 'vanilla' with 256 in_channels
Working with z of shape (1, 3, 14, 14) = 588 dimensions.
making attention of type 'vanilla' with 256 in_channels
Deleting key cond_stage_model.embedding.weight from state_dict.
Restored from /p/fzv6enresearch/DPImageBench/exp/dp-ldm/mnist_28_eps10.0val_large28-2025-01-12-07-43-03/pretrain/unet/checkpoints/last.ckpt with 1 missing and 486 unexpected keys
Missing Keys: ['cond_stage_model.embedding.weight']
Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates', 'model_ema.diffusion_modeltime_embed0weight', 'model_ema.diffusion_modeltime_embed0bias', 'model_ema.diffusion_modeltime_embed2weight', 'model_ema.diffusion_modeltime_embed2bias', 'model_ema.diffusion_modelinput_blocks00weight', 'model_ema.diffusion_modelinput_blocks00bias', 'model_ema.diffusion_modelinput_blocks10in_layers0weight', 'model_ema.diffusion_modelinput_blocks10in_layers0bias', 'model_ema.diffusion_modelinput_blocks10in_layers2weight', 'model_ema.diffusion_modelinput_blocks10in_layers2bias', 'model_ema.diffusion_modelinput_blocks10emb_layers1weight', 'model_ema.diffusion_modelinput_blocks10emb_layers1bias', 'model_ema.diffusion_modelinput_blocks10out_layers0weight', 'model_ema.diffusion_modelinput_blocks10out_layers0bias', 'model_ema.diffusion_modelinput_blocks10out_layers3weight', 'model_ema.diffusion_modelinput_blocks10out_layers3bias', 'model_ema.diffusion_modelinput_blocks11normweight', 'model_ema.diffusion_modelinput_blocks11normbias', 'model_ema.diffusion_modelinput_blocks11proj_inweight', 'model_ema.diffusion_modelinput_blocks11proj_inbias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks11proj_outweight', 'model_ema.diffusion_modelinput_blocks11proj_outbias', 'model_ema.diffusion_modelinput_blocks20in_layers0weight', 'model_ema.diffusion_modelinput_blocks20in_layers0bias', 'model_ema.diffusion_modelinput_blocks20in_layers2weight', 'model_ema.diffusion_modelinput_blocks20in_layers2bias', 'model_ema.diffusion_modelinput_blocks20emb_layers1weight', 'model_ema.diffusion_modelinput_blocks20emb_layers1bias', 'model_ema.diffusion_modelinput_blocks20out_layers0weight', 'model_ema.diffusion_modelinput_blocks20out_layers0bias', 'model_ema.diffusion_modelinput_blocks20out_layers3weight', 'model_ema.diffusion_modelinput_blocks20out_layers3bias', 'model_ema.diffusion_modelinput_blocks21normweight', 'model_ema.diffusion_modelinput_blocks21normbias', 'model_ema.diffusion_modelinput_blocks21proj_inweight', 'model_ema.diffusion_modelinput_blocks21proj_inbias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks21proj_outweight', 'model_ema.diffusion_modelinput_blocks21proj_outbias', 'model_ema.diffusion_modelinput_blocks30opweight', 'model_ema.diffusion_modelinput_blocks30opbias', 'model_ema.diffusion_modelinput_blocks40in_layers0weight', 'model_ema.diffusion_modelinput_blocks40in_layers0bias', 'model_ema.diffusion_modelinput_blocks40in_layers2weight', 'model_ema.diffusion_modelinput_blocks40in_layers2bias', 'model_ema.diffusion_modelinput_blocks40emb_layers1weight', 'model_ema.diffusion_modelinput_blocks40emb_layers1bias', 'model_ema.diffusion_modelinput_blocks40out_layers0weight', 'model_ema.diffusion_modelinput_blocks40out_layers0bias', 'model_ema.diffusion_modelinput_blocks40out_layers3weight', 'model_ema.diffusion_modelinput_blocks40out_layers3bias', 'model_ema.diffusion_modelinput_blocks40skip_connectionweight', 'model_ema.diffusion_modelinput_blocks40skip_connectionbias', 'model_ema.diffusion_modelinput_blocks41normweight', 'model_ema.diffusion_modelinput_blocks41normbias', 'model_ema.diffusion_modelinput_blocks41proj_inweight', 'model_ema.diffusion_modelinput_blocks41proj_inbias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks41proj_outweight', 'model_ema.diffusion_modelinput_blocks41proj_outbias', 'model_ema.diffusion_modelinput_blocks50in_layers0weight', 'model_ema.diffusion_modelinput_blocks50in_layers0bias', 'model_ema.diffusion_modelinput_blocks50in_layers2weight', 'model_ema.diffusion_modelinput_blocks50in_layers2bias', 'model_ema.diffusion_modelinput_blocks50emb_layers1weight', 'model_ema.diffusion_modelinput_blocks50emb_layers1bias', 'model_ema.diffusion_modelinput_blocks50out_layers0weight', 'model_ema.diffusion_modelinput_blocks50out_layers0bias', 'model_ema.diffusion_modelinput_blocks50out_layers3weight', 'model_ema.diffusion_modelinput_blocks50out_layers3bias', 'model_ema.diffusion_modelinput_blocks51normweight', 'model_ema.diffusion_modelinput_blocks51normbias', 'model_ema.diffusion_modelinput_blocks51proj_inweight', 'model_ema.diffusion_modelinput_blocks51proj_inbias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks51proj_outweight', 'model_ema.diffusion_modelinput_blocks51proj_outbias', 'model_ema.diffusion_modelmiddle_block0in_layers0weight', 'model_ema.diffusion_modelmiddle_block0in_layers0bias', 'model_ema.diffusion_modelmiddle_block0in_layers2weight', 'model_ema.diffusion_modelmiddle_block0in_layers2bias', 'model_ema.diffusion_modelmiddle_block0emb_layers1weight', 'model_ema.diffusion_modelmiddle_block0emb_layers1bias', 'model_ema.diffusion_modelmiddle_block0out_layers0weight', 'model_ema.diffusion_modelmiddle_block0out_layers0bias', 'model_ema.diffusion_modelmiddle_block0out_layers3weight', 'model_ema.diffusion_modelmiddle_block0out_layers3bias', 'model_ema.diffusion_modelmiddle_block1normweight', 'model_ema.diffusion_modelmiddle_block1normbias', 'model_ema.diffusion_modelmiddle_block1proj_inweight', 'model_ema.diffusion_modelmiddle_block1proj_inbias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm1weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm1bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm2weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm2bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm3weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm3bias', 'model_ema.diffusion_modelmiddle_block1proj_outweight', 'model_ema.diffusion_modelmiddle_block1proj_outbias', 'model_ema.diffusion_modelmiddle_block2in_layers0weight', 'model_ema.diffusion_modelmiddle_block2in_layers0bias', 'model_ema.diffusion_modelmiddle_block2in_layers2weight', 'model_ema.diffusion_modelmiddle_block2in_layers2bias', 'model_ema.diffusion_modelmiddle_block2emb_layers1weight', 'model_ema.diffusion_modelmiddle_block2emb_layers1bias', 'model_ema.diffusion_modelmiddle_block2out_layers0weight', 'model_ema.diffusion_modelmiddle_block2out_layers0bias', 'model_ema.diffusion_modelmiddle_block2out_layers3weight', 'model_ema.diffusion_modelmiddle_block2out_layers3bias', 'model_ema.diffusion_modeloutput_blocks00in_layers0weight', 'model_ema.diffusion_modeloutput_blocks00in_layers0bias', 'model_ema.diffusion_modeloutput_blocks00in_layers2weight', 'model_ema.diffusion_modeloutput_blocks00in_layers2bias', 'model_ema.diffusion_modeloutput_blocks00emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks00emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks00out_layers0weight', 'model_ema.diffusion_modeloutput_blocks00out_layers0bias', 'model_ema.diffusion_modeloutput_blocks00out_layers3weight', 'model_ema.diffusion_modeloutput_blocks00out_layers3bias', 'model_ema.diffusion_modeloutput_blocks00skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks00skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks01normweight', 'model_ema.diffusion_modeloutput_blocks01normbias', 'model_ema.diffusion_modeloutput_blocks01proj_inweight', 'model_ema.diffusion_modeloutput_blocks01proj_inbias', 'model_ema.diffusion_modeloutput_blocks01transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks01transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks01transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks01transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks01transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks01transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks01transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks01transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks01transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks01transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks01transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks01transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks01transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks01transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks01transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks01transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks01transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks01transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks01transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks01transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks01proj_outweight', 'model_ema.diffusion_modeloutput_blocks01proj_outbias', 'model_ema.diffusion_modeloutput_blocks10in_layers0weight', 'model_ema.diffusion_modeloutput_blocks10in_layers0bias', 'model_ema.diffusion_modeloutput_blocks10in_layers2weight', 'model_ema.diffusion_modeloutput_blocks10in_layers2bias', 'model_ema.diffusion_modeloutput_blocks10emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks10emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks10out_layers0weight', 'model_ema.diffusion_modeloutput_blocks10out_layers0bias', 'model_ema.diffusion_modeloutput_blocks10out_layers3weight', 'model_ema.diffusion_modeloutput_blocks10out_layers3bias', 'model_ema.diffusion_modeloutput_blocks10skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks10skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks11normweight', 'model_ema.diffusion_modeloutput_blocks11normbias', 'model_ema.diffusion_modeloutput_blocks11proj_inweight', 'model_ema.diffusion_modeloutput_blocks11proj_inbias', 'model_ema.diffusion_modeloutput_blocks11transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks11transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks11transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks11transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks11transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks11transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks11transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks11transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks11transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks11transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks11transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks11transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks11transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks11transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks11transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks11transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks11transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks11transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks11transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks11transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks11proj_outweight', 'model_ema.diffusion_modeloutput_blocks11proj_outbias', 'model_ema.diffusion_modeloutput_blocks20in_layers0weight', 'model_ema.diffusion_modeloutput_blocks20in_layers0bias', 'model_ema.diffusion_modeloutput_blocks20in_layers2weight', 'model_ema.diffusion_modeloutput_blocks20in_layers2bias', 'model_ema.diffusion_modeloutput_blocks20emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks20emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks20out_layers0weight', 'model_ema.diffusion_modeloutput_blocks20out_layers0bias', 'model_ema.diffusion_modeloutput_blocks20out_layers3weight', 'model_ema.diffusion_modeloutput_blocks20out_layers3bias', 'model_ema.diffusion_modeloutput_blocks20skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks20skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks21normweight', 'model_ema.diffusion_modeloutput_blocks21normbias', 'model_ema.diffusion_modeloutput_blocks21proj_inweight', 'model_ema.diffusion_modeloutput_blocks21proj_inbias', 'model_ema.diffusion_modeloutput_blocks21transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks21transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks21transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks21transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks21transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks21transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks21transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks21transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks21transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks21transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks21transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks21transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks21transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks21transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks21transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks21transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks21transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks21transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks21transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks21transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks21proj_outweight', 'model_ema.diffusion_modeloutput_blocks21proj_outbias', 'model_ema.diffusion_modeloutput_blocks22convweight', 'model_ema.diffusion_modeloutput_blocks22convbias', 'model_ema.diffusion_modeloutput_blocks30in_layers0weight', 'model_ema.diffusion_modeloutput_blocks30in_layers0bias', 'model_ema.diffusion_modeloutput_blocks30in_layers2weight', 'model_ema.diffusion_modeloutput_blocks30in_layers2bias', 'model_ema.diffusion_modeloutput_blocks30emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks30emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks30out_layers0weight', 'model_ema.diffusion_modeloutput_blocks30out_layers0bias', 'model_ema.diffusion_modeloutput_blocks30out_layers3weight', 'model_ema.diffusion_modeloutput_blocks30out_layers3bias', 'model_ema.diffusion_modeloutput_blocks30skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks30skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks31normweight', 'model_ema.diffusion_modeloutput_blocks31normbias', 'model_ema.diffusion_modeloutput_blocks31proj_inweight', 'model_ema.diffusion_modeloutput_blocks31proj_inbias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks31proj_outweight', 'model_ema.diffusion_modeloutput_blocks31proj_outbias', 'model_ema.diffusion_modeloutput_blocks40in_layers0weight', 'model_ema.diffusion_modeloutput_blocks40in_layers0bias', 'model_ema.diffusion_modeloutput_blocks40in_layers2weight', 'model_ema.diffusion_modeloutput_blocks40in_layers2bias', 'model_ema.diffusion_modeloutput_blocks40emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks40emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks40out_layers0weight', 'model_ema.diffusion_modeloutput_blocks40out_layers0bias', 'model_ema.diffusion_modeloutput_blocks40out_layers3weight', 'model_ema.diffusion_modeloutput_blocks40out_layers3bias', 'model_ema.diffusion_modeloutput_blocks40skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks40skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks41normweight', 'model_ema.diffusion_modeloutput_blocks41normbias', 'model_ema.diffusion_modeloutput_blocks41proj_inweight', 'model_ema.diffusion_modeloutput_blocks41proj_inbias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks41proj_outweight', 'model_ema.diffusion_modeloutput_blocks41proj_outbias', 'model_ema.diffusion_modeloutput_blocks50in_layers0weight', 'model_ema.diffusion_modeloutput_blocks50in_layers0bias', 'model_ema.diffusion_modeloutput_blocks50in_layers2weight', 'model_ema.diffusion_modeloutput_blocks50in_layers2bias', 'model_ema.diffusion_modeloutput_blocks50emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks50emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks50out_layers0weight', 'model_ema.diffusion_modeloutput_blocks50out_layers0bias', 'model_ema.diffusion_modeloutput_blocks50out_layers3weight', 'model_ema.diffusion_modeloutput_blocks50out_layers3bias', 'model_ema.diffusion_modeloutput_blocks50skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks50skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks51normweight', 'model_ema.diffusion_modeloutput_blocks51normbias', 'model_ema.diffusion_modeloutput_blocks51proj_inweight', 'model_ema.diffusion_modeloutput_blocks51proj_inbias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks51proj_outweight', 'model_ema.diffusion_modeloutput_blocks51proj_outbias', 'model_ema.diffusion_modelout0weight', 'model_ema.diffusion_modelout0bias', 'model_ema.diffusion_modelout2weight', 'model_ema.diffusion_modelout2bias', 'first_stage_model.encoder.down.1.attn.0.norm.weight', 'first_stage_model.encoder.down.1.attn.0.norm.bias', 'first_stage_model.encoder.down.1.attn.0.q.weight', 'first_stage_model.encoder.down.1.attn.0.q.bias', 'first_stage_model.encoder.down.1.attn.0.k.weight', 'first_stage_model.encoder.down.1.attn.0.k.bias', 'first_stage_model.encoder.down.1.attn.0.v.weight', 'first_stage_model.encoder.down.1.attn.0.v.bias', 'first_stage_model.encoder.down.1.attn.0.proj_out.weight', 'first_stage_model.encoder.down.1.attn.0.proj_out.bias', 'first_stage_model.encoder.down.1.attn.1.norm.weight', 'first_stage_model.encoder.down.1.attn.1.norm.bias', 'first_stage_model.encoder.down.1.attn.1.q.weight', 'first_stage_model.encoder.down.1.attn.1.q.bias', 'first_stage_model.encoder.down.1.attn.1.k.weight', 'first_stage_model.encoder.down.1.attn.1.k.bias', 'first_stage_model.encoder.down.1.attn.1.v.weight', 'first_stage_model.encoder.down.1.attn.1.v.bias', 'first_stage_model.encoder.down.1.attn.1.proj_out.weight', 'first_stage_model.encoder.down.1.attn.1.proj_out.bias', 'first_stage_model.decoder.up.1.attn.0.norm.weight', 'first_stage_model.decoder.up.1.attn.0.norm.bias', 'first_stage_model.decoder.up.1.attn.0.q.weight', 'first_stage_model.decoder.up.1.attn.0.q.bias', 'first_stage_model.decoder.up.1.attn.0.k.weight', 'first_stage_model.decoder.up.1.attn.0.k.bias', 'first_stage_model.decoder.up.1.attn.0.v.weight', 'first_stage_model.decoder.up.1.attn.0.v.bias', 'first_stage_model.decoder.up.1.attn.0.proj_out.weight', 'first_stage_model.decoder.up.1.attn.0.proj_out.bias', 'first_stage_model.decoder.up.1.attn.1.norm.weight', 'first_stage_model.decoder.up.1.attn.1.norm.bias', 'first_stage_model.decoder.up.1.attn.1.q.weight', 'first_stage_model.decoder.up.1.attn.1.q.bias', 'first_stage_model.decoder.up.1.attn.1.k.weight', 'first_stage_model.decoder.up.1.attn.1.k.bias', 'first_stage_model.decoder.up.1.attn.1.v.weight', 'first_stage_model.decoder.up.1.attn.1.v.bias', 'first_stage_model.decoder.up.1.attn.1.proj_out.weight', 'first_stage_model.decoder.up.1.attn.1.proj_out.bias', 'first_stage_model.decoder.up.1.attn.2.norm.weight', 'first_stage_model.decoder.up.1.attn.2.norm.bias', 'first_stage_model.decoder.up.1.attn.2.q.weight', 'first_stage_model.decoder.up.1.attn.2.q.bias', 'first_stage_model.decoder.up.1.attn.2.k.weight', 'first_stage_model.decoder.up.1.attn.2.k.bias', 'first_stage_model.decoder.up.1.attn.2.v.weight', 'first_stage_model.decoder.up.1.attn.2.v.bias', 'first_stage_model.decoder.up.1.attn.2.proj_out.weight', 'first_stage_model.decoder.up.1.attn.2.proj_out.bias']
Monitoring val/loss_simple_ema as checkpoint metric.
Merged modelckpt-cfg: 
{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': 'exp/dp-lora/fmnist_28_eps10.0val_large28-2025-01-14-11-53-01/train/checkpoints', 'filename': '{epoch:06}', 'verbose': True, 'save_last': True, 'monitor': 'val/loss_simple_ema', 'save_top_k': 3}}
#### Data #####
  train, WrappedDataset_lora, 55000
  validation, WrappedDataset_lora, 55000
Using Poisson sampling
Using virtual batch size of 64
#### Learning Rate ####
Setting learning rate to 4.10e-03  = 1 (accumulate_grad_batches)  * 1 (num_gpus)  * 4096 (batchsize)  * 1.00e-06 (base_lr)

#### Finetuning ####
  182272/7289411 (2.50%) parameters will compute gradients
  7289411/7289411 (100.00%) parameters will be trained
final sigma:  1.8994140625

#### Differential Privacy ####
  Epsilon: 10.0
  Delta: 1.6657508770018431e-06
  Noise Scale: 1.8994140625


#### Project config ####
model:
  base_learning_rate: 1.0e-06
  target: models.DP_LORA.ldm.models.diffusion.ddpm.LatentDiffusion
  params:
    output_file: exp/dp-lora/fmnist_28_eps10.0val_large28-2025-01-14-11-53-01/stdout.txt
    ckpt_path: /p/fzv6enresearch/DPImageBench/exp/dp-ldm/mnist_28_eps10.0val_large28-2025-01-12-07-43-03/pretrain/unet/checkpoints/last.ckpt
    ignore_keys:
    - cond_stage_model
    linear_start: 0.0015
    linear_end: 0.0155
    num_timesteps_cond: 1
    log_every_t: 200
    timesteps: 1000
    first_stage_key: image
    cond_stage_key: class_label
    image_size: 14
    channels: 3
    cond_stage_trainable: true
    conditioning_key: crossattn
    monitor: val/loss_simple_ema
    train_condition_only: true
    loss_type: l2
    attention_flag: spatial
    use_ema: false
    use_model_lora: true
    model_lora_r: 8
    model_lora_target:
    - to_q
    - to_v
    - to_k
    - to_out.Linear
    use_cond_lora: false
    DPDM_k: 8
    dp_config:
      enabled: true
      epsilon: 10.0
      delta: 1.6657508770018431e-06
      max_grad_norm: 0.001
      poisson_sampling: true
      max_batch_size: 64
    unet_config:
      target: models.DP_LORA.ldm.modules.diffusionmodules.openaimodel.UNetModel
      params:
        image_size: 14
        in_channels: 3
        out_channels: 3
        model_channels: 64
        attention_resolutions:
        - 1
        - 2
        - 4
        channel_mult:
        - 1
        - 2
        num_res_blocks: 2
        num_head_channels: 8
        use_spatial_transformer: true
        transformer_depth: 1
        context_dim: 512
    first_stage_config:
      target: models.DP_LORA.ldm.models.autoencoder.AutoencoderKL
      params:
        embed_dim: 3
        monitor: val/rec_loss
        ddconfig:
          double_z: true
          z_channels: 3
          resolution: 28
          in_channels: 1
          out_ch: 1
          ch: 128
          ch_mult:
          - 1
          - 2
          num_res_blocks: 2
          attn_resolutions:
          - 16
          - 8
          dropout: 0.0
        lossconfig:
          target: torch.nn.Identity
    cond_stage_config:
      target: models.DP_LORA.ldm.modules.encoders.modules.ClassEmbedder
      params:
        embed_dim: 512
        key: class_label
        n_classes: 10
data:
  target: models.DP_LORA.main.DataModuleFromConfig
  params:
    batch_size: 4096
    num_workers: 0
    train:
      params:
        path: dataset/fmnist/train_28.zip
        resolution: 28
        use_labels: true
        c: 1
      target: data.stylegan3.dataset.ImageFolderDataset
      data_num: 55000
    validation:
      params:
        path: dataset/fmnist/train_28.zip
        resolution: 28
        use_labels: true
        c: 1
      target: data.stylegan3.dataset.ImageFolderDataset
      data_num: 55000


#### Lightning config ####
callbacks:
  image_logger:
    target: models.DP_LORA.main.ImageLogger
    params:
      batch_frequency: 500
      max_images: 8
      increase_log_steps: false
trainer:
  benchmark: true
  max_epochs: 150
  accelerator: gpu
  gpus: 0,



Training: -1it [00:00, ?it/s]
Training:   0%|          | 0/859 [00:00<00:00, 65536.00it/s]
Epoch 0:   0%|          | 0/859 [00:00<00:00, 14122.24it/s] 
Epoch 0:  23%|██▎       | 200/859 [01:21<04:25,  2.48it/s] 
Epoch 0:  23%|██▎       | 200/859 [01:21<04:25,  2.48it/s, loss=0.158, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00331, train/loss_step=0.149, global_step=199.0]
Epoch 0:  47%|████▋     | 400/859 [02:26<02:48,  2.73it/s, loss=0.158, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00331, train/loss_step=0.149, global_step=199.0]
Epoch 0:  47%|████▋     | 400/859 [02:26<02:48,  2.73it/s, loss=0.154, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00139, train/loss_step=0.149, global_step=399.0]Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 0:  70%|██████▉   | 600/859 [03:59<01:43,  2.51it/s, loss=0.154, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00139, train/loss_step=0.149, global_step=399.0]
Epoch 0:  70%|██████▉   | 600/859 [03:59<01:43,  2.51it/s, loss=0.153, v_num=38, loss_step=0.171, train/loss_simple_step=0.171, train/loss_vlb_step=0.0018, train/loss_step=0.171, global_step=599.0] 
Epoch 0:  93%|█████████▎| 800/859 [05:05<00:22,  2.62it/s, loss=0.153, v_num=38, loss_step=0.171, train/loss_simple_step=0.171, train/loss_vlb_step=0.0018, train/loss_step=0.171, global_step=599.0]
Epoch 0:  93%|█████████▎| 800/859 [05:05<00:22,  2.62it/s, loss=0.146, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00242, train/loss_step=0.136, global_step=799.0]
Epoch 0: 100%|██████████| 859/859 [05:24<00:00,  2.65it/s, loss=0.146, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00242, train/loss_step=0.136, global_step=799.0]
Epoch 0: 100%|██████████| 859/859 [05:24<00:00,  2.65it/s, loss=0.151, v_num=38, loss_step=0.157, train/loss_simple_step=0.157, train/loss_vlb_step=0.00321, train/loss_step=0.157, global_step=858.0]
Epoch 0:   0%|          | 0/859 [00:00<00:00, 26715.31it/s, loss=0.151, v_num=38, loss_step=0.157, train/loss_simple_step=0.157, train/loss_vlb_step=0.00321, train/loss_step=0.157, global_step=858.0]
Epoch 1:   0%|          | 0/859 [00:00<00:00, 2832.08it/s, loss=0.151, v_num=38, loss_step=0.157, train/loss_simple_step=0.157, train/loss_vlb_step=0.00321, train/loss_step=0.157, global_step=858.0] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 1:  23%|██▎       | 200/859 [01:33<05:04,  2.16it/s, loss=0.151, v_num=38, loss_step=0.157, train/loss_simple_step=0.157, train/loss_vlb_step=0.00321, train/loss_step=0.157, global_step=858.0]
Epoch 1:  23%|██▎       | 200/859 [01:33<05:04,  2.16it/s, loss=0.153, v_num=38, loss_step=0.154, train/loss_simple_step=0.154, train/loss_vlb_step=0.00248, train/loss_step=0.154, global_step=1058.0, loss_epoch=0.159, train/loss_simple_epoch=0.159, train/loss_vlb_epoch=0.00269, train/loss_epoch=0.159]
Epoch 1:  47%|████▋     | 400/859 [02:39<03:01,  2.52it/s, loss=0.153, v_num=38, loss_step=0.154, train/loss_simple_step=0.154, train/loss_vlb_step=0.00248, train/loss_step=0.154, global_step=1058.0, loss_epoch=0.159, train/loss_simple_epoch=0.159, train/loss_vlb_epoch=0.00269, train/loss_epoch=0.159]
Epoch 1:  47%|████▋     | 400/859 [02:39<03:01,  2.52it/s, loss=0.15, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00247, train/loss_step=0.142, global_step=1258.0, loss_epoch=0.159, train/loss_simple_epoch=0.159, train/loss_vlb_epoch=0.00269, train/loss_epoch=0.159] 
Epoch 1:  70%|██████▉   | 600/859 [03:45<01:37,  2.67it/s, loss=0.15, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00247, train/loss_step=0.142, global_step=1258.0, loss_epoch=0.159, train/loss_simple_epoch=0.159, train/loss_vlb_epoch=0.00269, train/loss_epoch=0.159]
Epoch 1:  70%|██████▉   | 600/859 [03:45<01:37,  2.67it/s, loss=0.148, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00263, train/loss_step=0.150, global_step=1458.0, loss_epoch=0.159, train/loss_simple_epoch=0.159, train/loss_vlb_epoch=0.00269, train/loss_epoch=0.159]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 1:  93%|█████████▎| 800/859 [05:19<00:23,  2.51it/s, loss=0.148, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00263, train/loss_step=0.150, global_step=1458.0, loss_epoch=0.159, train/loss_simple_epoch=0.159, train/loss_vlb_epoch=0.00269, train/loss_epoch=0.159]
Epoch 1:  93%|█████████▎| 800/859 [05:19<00:23,  2.51it/s, loss=0.148, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00225, train/loss_step=0.145, global_step=1658.0, loss_epoch=0.159, train/loss_simple_epoch=0.159, train/loss_vlb_epoch=0.00269, train/loss_epoch=0.159]
Epoch 1: 100%|██████████| 859/859 [05:39<00:00,  2.54it/s, loss=0.148, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00225, train/loss_step=0.145, global_step=1658.0, loss_epoch=0.159, train/loss_simple_epoch=0.159, train/loss_vlb_epoch=0.00269, train/loss_epoch=0.159]
Epoch 1: 100%|██████████| 859/859 [05:39<00:00,  2.54it/s, loss=0.148, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00388, train/loss_step=0.150, global_step=1717.0, loss_epoch=0.159, train/loss_simple_epoch=0.159, train/loss_vlb_epoch=0.00269, train/loss_epoch=0.159]
Epoch 1:   0%|          | 0/859 [00:00<00:00, 25575.02it/s, loss=0.148, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00388, train/loss_step=0.150, global_step=1717.0, loss_epoch=0.159, train/loss_simple_epoch=0.159, train/loss_vlb_epoch=0.00269, train/loss_epoch=0.159]
Epoch 2:   0%|          | 0/859 [00:00<00:00, 2400.86it/s, loss=0.148, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00388, train/loss_step=0.150, global_step=1717.0, loss_epoch=0.159, train/loss_simple_epoch=0.159, train/loss_vlb_epoch=0.00269, train/loss_epoch=0.159] 
Epoch 2:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.148, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00388, train/loss_step=0.150, global_step=1717.0, loss_epoch=0.159, train/loss_simple_epoch=0.159, train/loss_vlb_epoch=0.00269, train/loss_epoch=0.159]
Epoch 2:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.147, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00157, train/loss_step=0.137, global_step=1917.0, loss_epoch=0.150, train/loss_simple_epoch=0.150, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.150]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 2:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.147, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00157, train/loss_step=0.137, global_step=1917.0, loss_epoch=0.150, train/loss_simple_epoch=0.150, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.150]
Epoch 2:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.147, v_num=38, loss_step=0.123, train/loss_simple_step=0.123, train/loss_vlb_step=0.00184, train/loss_step=0.123, global_step=2117.0, loss_epoch=0.150, train/loss_simple_epoch=0.150, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.150]
Epoch 2:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.147, v_num=38, loss_step=0.123, train/loss_simple_step=0.123, train/loss_vlb_step=0.00184, train/loss_step=0.123, global_step=2117.0, loss_epoch=0.150, train/loss_simple_epoch=0.150, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.150]
Epoch 2:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.147, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00327, train/loss_step=0.134, global_step=2317.0, loss_epoch=0.150, train/loss_simple_epoch=0.150, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.150]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 2:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.147, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00327, train/loss_step=0.134, global_step=2317.0, loss_epoch=0.150, train/loss_simple_epoch=0.150, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.150]
Epoch 2:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.15, v_num=38, loss_step=0.156, train/loss_simple_step=0.156, train/loss_vlb_step=0.00184, train/loss_step=0.156, global_step=2517.0, loss_epoch=0.150, train/loss_simple_epoch=0.150, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.150] 
Epoch 2: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.15, v_num=38, loss_step=0.156, train/loss_simple_step=0.156, train/loss_vlb_step=0.00184, train/loss_step=0.156, global_step=2517.0, loss_epoch=0.150, train/loss_simple_epoch=0.150, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.150]
Epoch 2: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.146, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00213, train/loss_step=0.134, global_step=2576.0, loss_epoch=0.150, train/loss_simple_epoch=0.150, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.150]
Epoch 2:   0%|          | 0/859 [00:00<00:00, 19972.88it/s, loss=0.146, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00213, train/loss_step=0.134, global_step=2576.0, loss_epoch=0.150, train/loss_simple_epoch=0.150, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.150]
Epoch 3:   0%|          | 0/859 [00:00<00:00, 2195.97it/s, loss=0.146, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00213, train/loss_step=0.134, global_step=2576.0, loss_epoch=0.150, train/loss_simple_epoch=0.150, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.150] 
Epoch 3:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.146, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00213, train/loss_step=0.134, global_step=2576.0, loss_epoch=0.150, train/loss_simple_epoch=0.150, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.150]
Epoch 3:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.145, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00217, train/loss_step=0.140, global_step=2776.0, loss_epoch=0.147, train/loss_simple_epoch=0.147, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.147]
Epoch 3:  47%|████▋     | 400/859 [02:12<02:31,  3.03it/s, loss=0.145, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00217, train/loss_step=0.140, global_step=2776.0, loss_epoch=0.147, train/loss_simple_epoch=0.147, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.147]
Epoch 3:  47%|████▋     | 400/859 [02:12<02:31,  3.03it/s, loss=0.146, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00148, train/loss_step=0.141, global_step=2976.0, loss_epoch=0.147, train/loss_simple_epoch=0.147, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.147]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 3:  70%|██████▉   | 600/859 [03:47<01:37,  2.64it/s, loss=0.146, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00148, train/loss_step=0.141, global_step=2976.0, loss_epoch=0.147, train/loss_simple_epoch=0.147, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.147]
Epoch 3:  70%|██████▉   | 600/859 [03:47<01:37,  2.64it/s, loss=0.149, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00366, train/loss_step=0.146, global_step=3176.0, loss_epoch=0.147, train/loss_simple_epoch=0.147, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.147]
Epoch 3:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.149, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00366, train/loss_step=0.146, global_step=3176.0, loss_epoch=0.147, train/loss_simple_epoch=0.147, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.147]
Epoch 3:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.146, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.003, train/loss_step=0.134, global_step=3376.0, loss_epoch=0.147, train/loss_simple_epoch=0.147, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.147]  
Epoch 3: 100%|██████████| 859/859 [05:13<00:00,  2.75it/s, loss=0.146, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.003, train/loss_step=0.134, global_step=3376.0, loss_epoch=0.147, train/loss_simple_epoch=0.147, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.147]
Epoch 3: 100%|██████████| 859/859 [05:13<00:00,  2.75it/s, loss=0.145, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00172, train/loss_step=0.140, global_step=3435.0, loss_epoch=0.147, train/loss_simple_epoch=0.147, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.147]
Epoch 3:   0%|          | 0/859 [00:00<00:00, 26051.58it/s, loss=0.145, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00172, train/loss_step=0.140, global_step=3435.0, loss_epoch=0.147, train/loss_simple_epoch=0.147, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.147]
Epoch 4:   0%|          | 0/859 [00:00<00:00, 2619.80it/s, loss=0.145, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00172, train/loss_step=0.140, global_step=3435.0, loss_epoch=0.147, train/loss_simple_epoch=0.147, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.147] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 4:  23%|██▎       | 200/859 [01:34<05:08,  2.13it/s, loss=0.145, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00172, train/loss_step=0.140, global_step=3435.0, loss_epoch=0.147, train/loss_simple_epoch=0.147, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.147]
Epoch 4:  23%|██▎       | 200/859 [01:34<05:08,  2.13it/s, loss=0.145, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00246, train/loss_step=0.151, global_step=3635.0, loss_epoch=0.146, train/loss_simple_epoch=0.146, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.146]
Epoch 4:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.145, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00246, train/loss_step=0.151, global_step=3635.0, loss_epoch=0.146, train/loss_simple_epoch=0.146, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.146]
Epoch 4:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.143, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00385, train/loss_step=0.139, global_step=3835.0, loss_epoch=0.146, train/loss_simple_epoch=0.146, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.146]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 4:  70%|██████▉   | 600/859 [04:14<01:49,  2.36it/s, loss=0.143, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00385, train/loss_step=0.139, global_step=3835.0, loss_epoch=0.146, train/loss_simple_epoch=0.146, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.146]
Epoch 4:  70%|██████▉   | 600/859 [04:14<01:49,  2.36it/s, loss=0.144, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00308, train/loss_step=0.142, global_step=4035.0, loss_epoch=0.146, train/loss_simple_epoch=0.146, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.146]
Epoch 4:  93%|█████████▎| 800/859 [05:20<00:23,  2.50it/s, loss=0.144, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00308, train/loss_step=0.142, global_step=4035.0, loss_epoch=0.146, train/loss_simple_epoch=0.146, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.146]
Epoch 4:  93%|█████████▎| 800/859 [05:20<00:23,  2.50it/s, loss=0.142, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00239, train/loss_step=0.133, global_step=4235.0, loss_epoch=0.146, train/loss_simple_epoch=0.146, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.146]
Epoch 4: 100%|██████████| 859/859 [05:40<00:00,  2.53it/s, loss=0.142, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00239, train/loss_step=0.133, global_step=4235.0, loss_epoch=0.146, train/loss_simple_epoch=0.146, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.146]
Epoch 4: 100%|██████████| 859/859 [05:40<00:00,  2.53it/s, loss=0.144, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00381, train/loss_step=0.147, global_step=4294.0, loss_epoch=0.146, train/loss_simple_epoch=0.146, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.146]
Epoch 4:   0%|          | 0/859 [00:00<00:00, 19508.39it/s, loss=0.144, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00381, train/loss_step=0.147, global_step=4294.0, loss_epoch=0.146, train/loss_simple_epoch=0.146, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.146]
Epoch 5:   0%|          | 0/859 [00:00<00:00, 2837.82it/s, loss=0.144, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00381, train/loss_step=0.147, global_step=4294.0, loss_epoch=0.146, train/loss_simple_epoch=0.146, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.146] 
Epoch 5:  23%|██▎       | 200/859 [01:06<03:38,  3.02it/s, loss=0.144, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00381, train/loss_step=0.147, global_step=4294.0, loss_epoch=0.146, train/loss_simple_epoch=0.146, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.146]
Epoch 5:  23%|██▎       | 200/859 [01:06<03:38,  3.02it/s, loss=0.143, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00131, train/loss_step=0.135, global_step=4494.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.144]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 5:  47%|████▋     | 400/859 [02:41<03:04,  2.49it/s, loss=0.143, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00131, train/loss_step=0.135, global_step=4494.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.144]
Epoch 5:  47%|████▋     | 400/859 [02:41<03:04,  2.49it/s, loss=0.142, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00225, train/loss_step=0.140, global_step=4694.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.144]
Epoch 5:  70%|██████▉   | 600/859 [03:47<01:38,  2.64it/s, loss=0.142, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00225, train/loss_step=0.140, global_step=4694.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.144]
Epoch 5:  70%|██████▉   | 600/859 [03:47<01:38,  2.64it/s, loss=0.143, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00216, train/loss_step=0.145, global_step=4894.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.144]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 5:  93%|█████████▎| 800/859 [05:22<00:23,  2.49it/s, loss=0.143, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00216, train/loss_step=0.145, global_step=4894.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.144]
Epoch 5:  93%|█████████▎| 800/859 [05:22<00:23,  2.49it/s, loss=0.14, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00495, train/loss_step=0.133, global_step=5094.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.144] 
Epoch 5: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.14, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00495, train/loss_step=0.133, global_step=5094.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.144]
Epoch 5: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.145, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00143, train/loss_step=0.137, global_step=5153.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.144]
Epoch 5:   0%|          | 0/859 [00:00<00:00, 25731.93it/s, loss=0.145, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00143, train/loss_step=0.137, global_step=5153.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.144]
Epoch 6:   0%|          | 0/859 [00:00<00:00, 3634.58it/s, loss=0.145, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00143, train/loss_step=0.137, global_step=5153.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.144] 
Epoch 6:  23%|██▎       | 200/859 [01:06<03:38,  3.02it/s, loss=0.145, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00143, train/loss_step=0.137, global_step=5153.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.144]
Epoch 6:  23%|██▎       | 200/859 [01:06<03:38,  3.02it/s, loss=0.147, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00157, train/loss_step=0.145, global_step=5353.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.144]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 6:  47%|████▋     | 400/859 [02:41<03:04,  2.49it/s, loss=0.147, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00157, train/loss_step=0.145, global_step=5353.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.144]
Epoch 6:  47%|████▋     | 400/859 [02:41<03:04,  2.49it/s, loss=0.141, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00153, train/loss_step=0.137, global_step=5553.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.144]
Epoch 6:  70%|██████▉   | 600/859 [03:47<01:37,  2.65it/s, loss=0.141, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00153, train/loss_step=0.137, global_step=5553.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.144]
Epoch 6:  70%|██████▉   | 600/859 [03:47<01:37,  2.65it/s, loss=0.147, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00294, train/loss_step=0.134, global_step=5753.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.144]
Epoch 6:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.147, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00294, train/loss_step=0.134, global_step=5753.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.144]
Epoch 6:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.149, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00327, train/loss_step=0.145, global_step=5953.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.144]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 6: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.149, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00327, train/loss_step=0.145, global_step=5953.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.144]
Epoch 6: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.145, v_num=38, loss_step=0.162, train/loss_simple_step=0.162, train/loss_vlb_step=0.00392, train/loss_step=0.162, global_step=6012.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.144]
Epoch 6:   0%|          | 0/859 [00:00<00:00, 25890.77it/s, loss=0.145, v_num=38, loss_step=0.162, train/loss_simple_step=0.162, train/loss_vlb_step=0.00392, train/loss_step=0.162, global_step=6012.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.144]
Epoch 7:   0%|          | 0/859 [00:00<00:00, 3533.53it/s, loss=0.145, v_num=38, loss_step=0.162, train/loss_simple_step=0.162, train/loss_vlb_step=0.00392, train/loss_step=0.162, global_step=6012.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.144] 
Epoch 7:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.145, v_num=38, loss_step=0.162, train/loss_simple_step=0.162, train/loss_vlb_step=0.00392, train/loss_step=0.162, global_step=6012.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.144]
Epoch 7:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.14, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00181, train/loss_step=0.136, global_step=6212.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.144] 
Epoch 7:  47%|████▋     | 400/859 [02:12<02:31,  3.03it/s, loss=0.14, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00181, train/loss_step=0.136, global_step=6212.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.144]
Epoch 7:  47%|████▋     | 400/859 [02:12<02:31,  3.03it/s, loss=0.144, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.0026, train/loss_step=0.141, global_step=6412.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.144]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 7:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.144, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.0026, train/loss_step=0.141, global_step=6412.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.144]
Epoch 7:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.145, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00276, train/loss_step=0.150, global_step=6612.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.144]
Epoch 7:  93%|█████████▎| 800/859 [04:52<00:21,  2.73it/s, loss=0.145, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00276, train/loss_step=0.150, global_step=6612.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.144]
Epoch 7:  93%|█████████▎| 800/859 [04:52<00:21,  2.73it/s, loss=0.146, v_num=38, loss_step=0.159, train/loss_simple_step=0.159, train/loss_vlb_step=0.00277, train/loss_step=0.159, global_step=6812.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.144]
Epoch 7: 100%|██████████| 859/859 [05:12<00:00,  2.75it/s, loss=0.146, v_num=38, loss_step=0.159, train/loss_simple_step=0.159, train/loss_vlb_step=0.00277, train/loss_step=0.159, global_step=6812.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.144]
Epoch 7: 100%|██████████| 859/859 [05:12<00:00,  2.75it/s, loss=0.139, v_num=38, loss_step=0.129, train/loss_simple_step=0.129, train/loss_vlb_step=0.00202, train/loss_step=0.129, global_step=6871.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.144]
Epoch 7:   0%|          | 0/859 [00:00<00:00, 24528.09it/s, loss=0.139, v_num=38, loss_step=0.129, train/loss_simple_step=0.129, train/loss_vlb_step=0.00202, train/loss_step=0.129, global_step=6871.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.144]
Epoch 8:   0%|          | 0/859 [00:00<00:00, 3539.50it/s, loss=0.139, v_num=38, loss_step=0.129, train/loss_simple_step=0.129, train/loss_vlb_step=0.00202, train/loss_step=0.129, global_step=6871.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.144] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 8:  23%|██▎       | 200/859 [01:34<05:09,  2.13it/s, loss=0.139, v_num=38, loss_step=0.129, train/loss_simple_step=0.129, train/loss_vlb_step=0.00202, train/loss_step=0.129, global_step=6871.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.144]
Epoch 8:  23%|██▎       | 200/859 [01:34<05:09,  2.13it/s, loss=0.148, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00324, train/loss_step=0.144, global_step=7071.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.143]
Epoch 8:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.148, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00324, train/loss_step=0.144, global_step=7071.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.143]
Epoch 8:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.139, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00161, train/loss_step=0.144, global_step=7271.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.143]
Epoch 8:  70%|██████▉   | 600/859 [03:47<01:37,  2.65it/s, loss=0.139, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00161, train/loss_step=0.144, global_step=7271.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.143]
Epoch 8:  70%|██████▉   | 600/859 [03:47<01:37,  2.65it/s, loss=0.147, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00107, train/loss_step=0.150, global_step=7471.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.143]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 8:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.147, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00107, train/loss_step=0.150, global_step=7471.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.143]
Epoch 8:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.142, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00172, train/loss_step=0.149, global_step=7671.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.143]
Epoch 8: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.142, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00172, train/loss_step=0.149, global_step=7671.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.143]
Epoch 8: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.142, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00218, train/loss_step=0.144, global_step=7730.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.143]
Epoch 8:   0%|          | 0/859 [00:00<00:00, 27235.74it/s, loss=0.142, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00218, train/loss_step=0.144, global_step=7730.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.143]
Epoch 9:   0%|          | 0/859 [00:00<00:00, 3813.00it/s, loss=0.142, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00218, train/loss_step=0.144, global_step=7730.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.143] 
Epoch 9:  23%|██▎       | 200/859 [01:06<03:38,  3.02it/s, loss=0.142, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00218, train/loss_step=0.144, global_step=7730.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.143]
Epoch 9:  23%|██▎       | 200/859 [01:06<03:38,  3.02it/s, loss=0.151, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00421, train/loss_step=0.151, global_step=7930.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.144]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 9:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.151, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00421, train/loss_step=0.151, global_step=7930.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.144]
Epoch 9:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.144, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00241, train/loss_step=0.150, global_step=8130.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.144]
Epoch 9:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.144, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00241, train/loss_step=0.150, global_step=8130.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.144]
Epoch 9:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.141, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00339, train/loss_step=0.134, global_step=8330.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.144]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 9:  93%|█████████▎| 800/859 [05:19<00:23,  2.51it/s, loss=0.141, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00339, train/loss_step=0.134, global_step=8330.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.144]
Epoch 9:  93%|█████████▎| 800/859 [05:19<00:23,  2.51it/s, loss=0.141, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00142, train/loss_step=0.137, global_step=8530.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.144]
Epoch 9: 100%|██████████| 859/859 [05:38<00:00,  2.54it/s, loss=0.141, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00142, train/loss_step=0.137, global_step=8530.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.144]
Epoch 9: 100%|██████████| 859/859 [05:38<00:00,  2.54it/s, loss=0.146, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00129, train/loss_step=0.149, global_step=8589.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.144]
Epoch 9:   0%|          | 0/859 [00:00<00:00, 26546.23it/s, loss=0.146, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00129, train/loss_step=0.149, global_step=8589.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.144]
Epoch 10:   0%|          | 0/859 [00:00<00:00, 2668.13it/s, loss=0.146, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00129, train/loss_step=0.149, global_step=8589.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.144]
Epoch 10:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.146, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00129, train/loss_step=0.149, global_step=8589.0, loss_epoch=0.144, train/loss_simple_epoch=0.144, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.144]
Epoch 10:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.139, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00519, train/loss_step=0.142, global_step=8789.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.143]
Epoch 10:  47%|████▋     | 400/859 [02:12<02:31,  3.03it/s, loss=0.139, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00519, train/loss_step=0.142, global_step=8789.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.143]
Epoch 10:  47%|████▋     | 400/859 [02:12<02:31,  3.03it/s, loss=0.145, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00336, train/loss_step=0.152, global_step=8989.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.143]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 10:  70%|██████▉   | 600/859 [03:44<01:36,  2.68it/s, loss=0.145, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00336, train/loss_step=0.152, global_step=8989.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.143]
Epoch 10:  70%|██████▉   | 600/859 [03:44<01:36,  2.68it/s, loss=0.141, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00176, train/loss_step=0.136, global_step=9189.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.143]
Epoch 10:  93%|█████████▎| 800/859 [04:50<00:21,  2.76it/s, loss=0.141, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00176, train/loss_step=0.136, global_step=9189.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.143]
Epoch 10:  93%|█████████▎| 800/859 [04:50<00:21,  2.76it/s, loss=0.142, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00143, train/loss_step=0.134, global_step=9389.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.143]
Epoch 10: 100%|██████████| 859/859 [05:10<00:00,  2.77it/s, loss=0.142, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00143, train/loss_step=0.134, global_step=9389.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.143]
Epoch 10: 100%|██████████| 859/859 [05:10<00:00,  2.77it/s, loss=0.14, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00271, train/loss_step=0.137, global_step=9448.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.143] 
Epoch 10:   0%|          | 0/859 [00:00<00:00, 26546.23it/s, loss=0.14, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00271, train/loss_step=0.137, global_step=9448.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.143]
Epoch 11:   0%|          | 0/859 [00:00<00:00, 4275.54it/s, loss=0.14, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00271, train/loss_step=0.137, global_step=9448.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.143] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 11:  23%|██▎       | 200/859 [01:33<05:04,  2.16it/s, loss=0.14, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00271, train/loss_step=0.137, global_step=9448.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.143]
Epoch 11:  23%|██▎       | 200/859 [01:33<05:04,  2.16it/s, loss=0.141, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00243, train/loss_step=0.148, global_step=9648.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.143]
Epoch 11:  47%|████▋     | 400/859 [02:38<03:01,  2.52it/s, loss=0.141, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00243, train/loss_step=0.148, global_step=9648.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.143]
Epoch 11:  47%|████▋     | 400/859 [02:38<03:01,  2.52it/s, loss=0.143, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00221, train/loss_step=0.132, global_step=9848.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.143]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 11:  70%|██████▉   | 600/859 [04:11<01:48,  2.39it/s, loss=0.143, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00221, train/loss_step=0.132, global_step=9848.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.143]
Epoch 11:  70%|██████▉   | 600/859 [04:11<01:48,  2.39it/s, loss=0.144, v_num=38, loss_step=0.176, train/loss_simple_step=0.176, train/loss_vlb_step=0.00424, train/loss_step=0.176, global_step=1e+4, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.143]  
Epoch 11:  93%|█████████▎| 800/859 [05:17<00:23,  2.52it/s, loss=0.144, v_num=38, loss_step=0.176, train/loss_simple_step=0.176, train/loss_vlb_step=0.00424, train/loss_step=0.176, global_step=1e+4, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.143]
Epoch 11:  93%|█████████▎| 800/859 [05:17<00:23,  2.52it/s, loss=0.142, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00176, train/loss_step=0.140, global_step=10248.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.143]
Epoch 11: 100%|██████████| 859/859 [05:36<00:00,  2.55it/s, loss=0.142, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00176, train/loss_step=0.140, global_step=10248.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.143]
Epoch 11: 100%|██████████| 859/859 [05:36<00:00,  2.55it/s, loss=0.145, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00368, train/loss_step=0.141, global_step=10307.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.143]
Epoch 11:   0%|          | 0/859 [00:00<00:00, 26886.56it/s, loss=0.145, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00368, train/loss_step=0.141, global_step=10307.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.143]
Epoch 12:   0%|          | 0/859 [00:00<00:00, 4573.94it/s, loss=0.145, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00368, train/loss_step=0.141, global_step=10307.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.143] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 12:  23%|██▎       | 200/859 [01:34<05:10,  2.13it/s, loss=0.145, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00368, train/loss_step=0.141, global_step=10307.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.143]
Epoch 12:  23%|██▎       | 200/859 [01:34<05:10,  2.13it/s, loss=0.143, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00439, train/loss_step=0.152, global_step=10507.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.143]
Epoch 12:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.143, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00439, train/loss_step=0.152, global_step=10507.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.143]
Epoch 12:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.142, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00228, train/loss_step=0.144, global_step=10707.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.143]
Epoch 12:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.142, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00228, train/loss_step=0.144, global_step=10707.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.143]
Epoch 12:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.146, v_num=38, loss_step=0.160, train/loss_simple_step=0.160, train/loss_vlb_step=0.00156, train/loss_step=0.160, global_step=10907.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.143]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 12:  93%|█████████▎| 800/859 [05:23<00:23,  2.48it/s, loss=0.146, v_num=38, loss_step=0.160, train/loss_simple_step=0.160, train/loss_vlb_step=0.00156, train/loss_step=0.160, global_step=10907.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.143]
Epoch 12:  93%|█████████▎| 800/859 [05:23<00:23,  2.48it/s, loss=0.146, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00301, train/loss_step=0.142, global_step=11107.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.143]
Epoch 12: 100%|██████████| 859/859 [05:42<00:00,  2.51it/s, loss=0.146, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00301, train/loss_step=0.142, global_step=11107.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.143]
Epoch 12: 100%|██████████| 859/859 [05:42<00:00,  2.51it/s, loss=0.143, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00224, train/loss_step=0.142, global_step=11166.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.143]
Epoch 12:   0%|          | 0/859 [00:00<00:00, 22550.02it/s, loss=0.143, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00224, train/loss_step=0.142, global_step=11166.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.143]
Epoch 13:   0%|          | 0/859 [00:00<00:00, 3063.77it/s, loss=0.143, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00224, train/loss_step=0.142, global_step=11166.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.143] 
Epoch 13:  23%|██▎       | 200/859 [01:06<03:39,  3.01it/s, loss=0.143, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00224, train/loss_step=0.142, global_step=11166.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.143]
Epoch 13:  23%|██▎       | 200/859 [01:06<03:39,  3.01it/s, loss=0.141, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00357, train/loss_step=0.140, global_step=11366.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 13:  47%|████▋     | 400/859 [02:43<03:07,  2.45it/s, loss=0.141, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00357, train/loss_step=0.140, global_step=11366.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 13:  47%|████▋     | 400/859 [02:43<03:07,  2.45it/s, loss=0.146, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00343, train/loss_step=0.152, global_step=11566.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 13:  70%|██████▉   | 600/859 [03:50<01:39,  2.61it/s, loss=0.146, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00343, train/loss_step=0.152, global_step=11566.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 13:  70%|██████▉   | 600/859 [03:50<01:39,  2.61it/s, loss=0.14, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00305, train/loss_step=0.139, global_step=11766.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142] 
Epoch 13:  93%|█████████▎| 800/859 [04:57<00:21,  2.70it/s, loss=0.14, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00305, train/loss_step=0.139, global_step=11766.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 13:  93%|█████████▎| 800/859 [04:57<00:21,  2.70it/s, loss=0.147, v_num=38, loss_step=0.162, train/loss_simple_step=0.162, train/loss_vlb_step=0.00241, train/loss_step=0.162, global_step=1.2e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 13: 100%|██████████| 859/859 [05:47<00:00,  2.48it/s, loss=0.147, v_num=38, loss_step=0.162, train/loss_simple_step=0.162, train/loss_vlb_step=0.00241, train/loss_step=0.162, global_step=1.2e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 13: 100%|██████████| 859/859 [05:47<00:00,  2.48it/s, loss=0.138, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00265, train/loss_step=0.142, global_step=1.2e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 13:   0%|          | 0/859 [00:00<00:00, 25731.93it/s, loss=0.138, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00265, train/loss_step=0.142, global_step=1.2e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 14:   0%|          | 0/859 [00:00<00:00, 3279.36it/s, loss=0.138, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00265, train/loss_step=0.142, global_step=1.2e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142] 
Epoch 14:  23%|██▎       | 200/859 [01:06<03:37,  3.02it/s, loss=0.138, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00265, train/loss_step=0.142, global_step=1.2e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 14:  23%|██▎       | 200/859 [01:06<03:37,  3.02it/s, loss=0.143, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00158, train/loss_step=0.137, global_step=12225.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 14:  47%|████▋     | 400/859 [02:12<02:31,  3.02it/s, loss=0.143, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00158, train/loss_step=0.137, global_step=12225.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 14:  47%|████▋     | 400/859 [02:12<02:31,  3.02it/s, loss=0.146, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00197, train/loss_step=0.151, global_step=12425.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 14:  70%|██████▉   | 600/859 [03:47<01:37,  2.64it/s, loss=0.146, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00197, train/loss_step=0.151, global_step=12425.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 14:  70%|██████▉   | 600/859 [03:47<01:37,  2.64it/s, loss=0.14, v_num=38, loss_step=0.129, train/loss_simple_step=0.129, train/loss_vlb_step=0.00216, train/loss_step=0.129, global_step=12625.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142] 
Epoch 14:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.14, v_num=38, loss_step=0.129, train/loss_simple_step=0.129, train/loss_vlb_step=0.00216, train/loss_step=0.129, global_step=12625.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 14:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.145, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00279, train/loss_step=0.135, global_step=12825.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 14: 100%|██████████| 859/859 [05:13<00:00,  2.75it/s, loss=0.145, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00279, train/loss_step=0.135, global_step=12825.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 14: 100%|██████████| 859/859 [05:13<00:00,  2.75it/s, loss=0.142, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00143, train/loss_step=0.133, global_step=12884.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 14:   0%|          | 0/859 [00:00<00:00, 25266.89it/s, loss=0.142, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00143, train/loss_step=0.133, global_step=12884.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 15:   0%|          | 0/859 [00:00<00:00, 2489.20it/s, loss=0.142, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00143, train/loss_step=0.133, global_step=12884.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 15:  23%|██▎       | 200/859 [01:34<05:09,  2.13it/s, loss=0.142, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00143, train/loss_step=0.133, global_step=12884.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 15:  23%|██▎       | 200/859 [01:34<05:09,  2.13it/s, loss=0.14, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00234, train/loss_step=0.144, global_step=13084.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142] 
Epoch 15:  47%|████▋     | 400/859 [02:40<03:04,  2.49it/s, loss=0.14, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00234, train/loss_step=0.144, global_step=13084.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]
Epoch 15:  47%|████▋     | 400/859 [02:40<03:04,  2.49it/s, loss=0.142, v_num=38, loss_step=0.178, train/loss_simple_step=0.178, train/loss_vlb_step=0.0049, train/loss_step=0.178, global_step=13284.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]
Epoch 15:  70%|██████▉   | 600/859 [03:47<01:38,  2.64it/s, loss=0.142, v_num=38, loss_step=0.178, train/loss_simple_step=0.178, train/loss_vlb_step=0.0049, train/loss_step=0.178, global_step=13284.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]
Epoch 15:  70%|██████▉   | 600/859 [03:47<01:38,  2.64it/s, loss=0.143, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00207, train/loss_step=0.145, global_step=13484.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 15:  93%|█████████▎| 800/859 [05:25<00:23,  2.46it/s, loss=0.143, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00207, train/loss_step=0.145, global_step=13484.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]
Epoch 15:  93%|█████████▎| 800/859 [05:25<00:23,  2.46it/s, loss=0.142, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00178, train/loss_step=0.151, global_step=13684.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]
Epoch 15: 100%|██████████| 859/859 [05:44<00:00,  2.49it/s, loss=0.142, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00178, train/loss_step=0.151, global_step=13684.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]
Epoch 15: 100%|██████████| 859/859 [05:44<00:00,  2.49it/s, loss=0.148, v_num=38, loss_step=0.159, train/loss_simple_step=0.159, train/loss_vlb_step=0.00344, train/loss_step=0.159, global_step=13743.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]
Epoch 15:   0%|          | 0/859 [00:00<00:00, 23431.87it/s, loss=0.148, v_num=38, loss_step=0.159, train/loss_simple_step=0.159, train/loss_vlb_step=0.00344, train/loss_step=0.159, global_step=13743.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]
Epoch 16:   0%|          | 0/859 [00:00<00:00, 2152.03it/s, loss=0.148, v_num=38, loss_step=0.159, train/loss_simple_step=0.159, train/loss_vlb_step=0.00344, train/loss_step=0.159, global_step=13743.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142] 
Epoch 16:  23%|██▎       | 200/859 [01:06<03:39,  3.00it/s, loss=0.148, v_num=38, loss_step=0.159, train/loss_simple_step=0.159, train/loss_vlb_step=0.00344, train/loss_step=0.159, global_step=13743.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]
Epoch 16:  23%|██▎       | 200/859 [01:06<03:39,  3.00it/s, loss=0.139, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.0013, train/loss_step=0.144, global_step=13943.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 16:  47%|████▋     | 400/859 [02:44<03:07,  2.44it/s, loss=0.139, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.0013, train/loss_step=0.144, global_step=13943.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 16:  47%|████▋     | 400/859 [02:44<03:07,  2.44it/s, loss=0.143, v_num=38, loss_step=0.155, train/loss_simple_step=0.155, train/loss_vlb_step=0.0034, train/loss_step=0.155, global_step=14143.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 16:  70%|██████▉   | 600/859 [03:50<01:39,  2.61it/s, loss=0.143, v_num=38, loss_step=0.155, train/loss_simple_step=0.155, train/loss_vlb_step=0.0034, train/loss_step=0.155, global_step=14143.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 16:  70%|██████▉   | 600/859 [03:50<01:39,  2.61it/s, loss=0.143, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00185, train/loss_step=0.135, global_step=14343.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 16:  93%|█████████▎| 800/859 [05:24<00:23,  2.47it/s, loss=0.143, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00185, train/loss_step=0.135, global_step=14343.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 16:  93%|█████████▎| 800/859 [05:24<00:23,  2.47it/s, loss=0.141, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00276, train/loss_step=0.145, global_step=14543.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 16: 100%|██████████| 859/859 [05:44<00:00,  2.50it/s, loss=0.141, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00276, train/loss_step=0.145, global_step=14543.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 16: 100%|██████████| 859/859 [05:44<00:00,  2.50it/s, loss=0.143, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00265, train/loss_step=0.152, global_step=14602.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 16:   0%|          | 0/859 [00:00<00:00, 25731.93it/s, loss=0.143, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00265, train/loss_step=0.152, global_step=14602.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 17:   0%|          | 0/859 [00:00<00:00, 4096.00it/s, loss=0.143, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00265, train/loss_step=0.152, global_step=14602.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142] 
Epoch 17:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.143, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00265, train/loss_step=0.152, global_step=14602.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 17:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.141, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00102, train/loss_step=0.134, global_step=14802.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 17:  47%|████▋     | 400/859 [02:44<03:07,  2.44it/s, loss=0.141, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00102, train/loss_step=0.134, global_step=14802.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 17:  47%|████▋     | 400/859 [02:44<03:07,  2.44it/s, loss=0.144, v_num=38, loss_step=0.156, train/loss_simple_step=0.156, train/loss_vlb_step=0.00286, train/loss_step=0.156, global_step=1.5e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142] 
Epoch 17:  70%|██████▉   | 600/859 [03:50<01:39,  2.60it/s, loss=0.144, v_num=38, loss_step=0.156, train/loss_simple_step=0.156, train/loss_vlb_step=0.00286, train/loss_step=0.156, global_step=1.5e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 17:  70%|██████▉   | 600/859 [03:50<01:39,  2.60it/s, loss=0.144, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00223, train/loss_step=0.139, global_step=15202.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 17:  93%|█████████▎| 800/859 [04:57<00:21,  2.69it/s, loss=0.144, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00223, train/loss_step=0.139, global_step=15202.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 17:  93%|█████████▎| 800/859 [04:57<00:21,  2.69it/s, loss=0.144, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00175, train/loss_step=0.136, global_step=15402.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 17: 100%|██████████| 859/859 [05:17<00:00,  2.71it/s, loss=0.144, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00175, train/loss_step=0.136, global_step=15402.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 17: 100%|██████████| 859/859 [05:17<00:00,  2.71it/s, loss=0.139, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00367, train/loss_step=0.142, global_step=15461.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 17:   0%|          | 0/859 [00:00<00:00, 21959.71it/s, loss=0.139, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00367, train/loss_step=0.142, global_step=15461.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 18:   0%|          | 0/859 [00:00<00:00, 1963.63it/s, loss=0.139, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00367, train/loss_step=0.142, global_step=15461.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 18:  23%|██▎       | 200/859 [01:38<05:23,  2.04it/s, loss=0.139, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00367, train/loss_step=0.142, global_step=15461.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 18:  23%|██▎       | 200/859 [01:38<05:23,  2.04it/s, loss=0.14, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00328, train/loss_step=0.150, global_step=15661.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00259, train/loss_epoch=0.143] 
Epoch 18:  47%|████▋     | 400/859 [02:45<03:09,  2.42it/s, loss=0.14, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00328, train/loss_step=0.150, global_step=15661.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00259, train/loss_epoch=0.143]
Epoch 18:  47%|████▋     | 400/859 [02:45<03:09,  2.42it/s, loss=0.145, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00178, train/loss_step=0.142, global_step=15861.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00259, train/loss_epoch=0.143]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 18:  70%|██████▉   | 600/859 [04:20<01:52,  2.31it/s, loss=0.145, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00178, train/loss_step=0.142, global_step=15861.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00259, train/loss_epoch=0.143]
Epoch 18:  70%|██████▉   | 600/859 [04:20<01:52,  2.31it/s, loss=0.141, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00108, train/loss_step=0.138, global_step=16061.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00259, train/loss_epoch=0.143]
Epoch 18:  93%|█████████▎| 800/859 [05:27<00:24,  2.45it/s, loss=0.141, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00108, train/loss_step=0.138, global_step=16061.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00259, train/loss_epoch=0.143]
Epoch 18:  93%|█████████▎| 800/859 [05:27<00:24,  2.45it/s, loss=0.142, v_num=38, loss_step=0.163, train/loss_simple_step=0.163, train/loss_vlb_step=0.00174, train/loss_step=0.163, global_step=16261.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00259, train/loss_epoch=0.143]
Epoch 18: 100%|██████████| 859/859 [05:46<00:00,  2.48it/s, loss=0.142, v_num=38, loss_step=0.163, train/loss_simple_step=0.163, train/loss_vlb_step=0.00174, train/loss_step=0.163, global_step=16261.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00259, train/loss_epoch=0.143]
Epoch 18: 100%|██████████| 859/859 [05:46<00:00,  2.48it/s, loss=0.141, v_num=38, loss_step=0.159, train/loss_simple_step=0.159, train/loss_vlb_step=0.0035, train/loss_step=0.159, global_step=16320.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00259, train/loss_epoch=0.143] 
Epoch 18:   0%|          | 0/859 [00:00<00:00, 25890.77it/s, loss=0.141, v_num=38, loss_step=0.159, train/loss_simple_step=0.159, train/loss_vlb_step=0.0035, train/loss_step=0.159, global_step=16320.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00259, train/loss_epoch=0.143]
Epoch 19:   0%|          | 0/859 [00:00<00:00, 2403.61it/s, loss=0.141, v_num=38, loss_step=0.159, train/loss_simple_step=0.159, train/loss_vlb_step=0.0035, train/loss_step=0.159, global_step=16320.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00259, train/loss_epoch=0.143] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 19:  23%|██▎       | 200/859 [01:38<05:22,  2.04it/s, loss=0.141, v_num=38, loss_step=0.159, train/loss_simple_step=0.159, train/loss_vlb_step=0.0035, train/loss_step=0.159, global_step=16320.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00259, train/loss_epoch=0.143]
Epoch 19:  23%|██▎       | 200/859 [01:38<05:22,  2.04it/s, loss=0.144, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.0028, train/loss_step=0.152, global_step=16520.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.143]
Epoch 19:  47%|████▋     | 400/859 [02:45<03:08,  2.43it/s, loss=0.144, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.0028, train/loss_step=0.152, global_step=16520.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.143]
Epoch 19:  47%|████▋     | 400/859 [02:45<03:08,  2.43it/s, loss=0.14, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.0014, train/loss_step=0.140, global_step=16720.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.143] 
Epoch 19:  70%|██████▉   | 600/859 [03:51<01:39,  2.60it/s, loss=0.14, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.0014, train/loss_step=0.140, global_step=16720.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.143]
Epoch 19:  70%|██████▉   | 600/859 [03:51<01:39,  2.60it/s, loss=0.138, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00152, train/loss_step=0.149, global_step=16920.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.143]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 19:  93%|█████████▎| 800/859 [05:27<00:24,  2.45it/s, loss=0.138, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00152, train/loss_step=0.149, global_step=16920.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.143]
Epoch 19:  93%|█████████▎| 800/859 [05:27<00:24,  2.45it/s, loss=0.14, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00264, train/loss_step=0.134, global_step=17120.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.143] 
Epoch 19: 100%|██████████| 859/859 [05:47<00:00,  2.48it/s, loss=0.14, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00264, train/loss_step=0.134, global_step=17120.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.143]
Epoch 19: 100%|██████████| 859/859 [05:47<00:00,  2.48it/s, loss=0.139, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00254, train/loss_step=0.151, global_step=17179.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.143]
Epoch 19:   0%|          | 0/859 [00:00<00:00, 25731.93it/s, loss=0.139, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00254, train/loss_step=0.151, global_step=17179.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.143]
Epoch 20:   0%|          | 0/859 [00:00<00:00, 4760.84it/s, loss=0.139, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00254, train/loss_step=0.151, global_step=17179.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.143] 
Epoch 20:  23%|██▎       | 200/859 [01:06<03:38,  3.02it/s, loss=0.139, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00254, train/loss_step=0.151, global_step=17179.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.143]
Epoch 20:  23%|██▎       | 200/859 [01:06<03:38,  3.02it/s, loss=0.145, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00288, train/loss_step=0.150, global_step=17379.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00245, train/loss_epoch=0.143]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 20:  47%|████▋     | 400/859 [02:42<03:05,  2.47it/s, loss=0.145, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00288, train/loss_step=0.150, global_step=17379.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00245, train/loss_epoch=0.143]
Epoch 20:  47%|████▋     | 400/859 [02:42<03:05,  2.47it/s, loss=0.141, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00303, train/loss_step=0.149, global_step=17579.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00245, train/loss_epoch=0.143]
Epoch 20:  70%|██████▉   | 600/859 [03:48<01:38,  2.63it/s, loss=0.141, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00303, train/loss_step=0.149, global_step=17579.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00245, train/loss_epoch=0.143]
Epoch 20:  70%|██████▉   | 600/859 [03:48<01:38,  2.63it/s, loss=0.142, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00318, train/loss_step=0.144, global_step=17779.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00245, train/loss_epoch=0.143]
Epoch 20:  93%|█████████▎| 800/859 [04:55<00:21,  2.71it/s, loss=0.142, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00318, train/loss_step=0.144, global_step=17779.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00245, train/loss_epoch=0.143]
Epoch 20:  93%|█████████▎| 800/859 [04:55<00:21,  2.71it/s, loss=0.145, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00386, train/loss_step=0.136, global_step=1.8e+4, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00245, train/loss_epoch=0.143] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 20: 100%|██████████| 859/859 [05:43<00:00,  2.50it/s, loss=0.145, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00386, train/loss_step=0.136, global_step=1.8e+4, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00245, train/loss_epoch=0.143]
Epoch 20: 100%|██████████| 859/859 [05:43<00:00,  2.50it/s, loss=0.143, v_num=38, loss_step=0.156, train/loss_simple_step=0.156, train/loss_vlb_step=0.00358, train/loss_step=0.156, global_step=1.8e+4, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00245, train/loss_epoch=0.143]
Epoch 20:   0%|          | 0/859 [00:00<00:00, 24672.38it/s, loss=0.143, v_num=38, loss_step=0.156, train/loss_simple_step=0.156, train/loss_vlb_step=0.00358, train/loss_step=0.156, global_step=1.8e+4, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00245, train/loss_epoch=0.143]
Epoch 21:   0%|          | 0/859 [00:00<00:00, 2095.06it/s, loss=0.143, v_num=38, loss_step=0.156, train/loss_simple_step=0.156, train/loss_vlb_step=0.00358, train/loss_step=0.156, global_step=1.8e+4, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00245, train/loss_epoch=0.143] 
Epoch 21:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.143, v_num=38, loss_step=0.156, train/loss_simple_step=0.156, train/loss_vlb_step=0.00358, train/loss_step=0.156, global_step=1.8e+4, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00245, train/loss_epoch=0.143]
Epoch 21:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.143, v_num=38, loss_step=0.113, train/loss_simple_step=0.113, train/loss_vlb_step=0.00183, train/loss_step=0.113, global_step=18238.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 21:  47%|████▋     | 400/859 [02:12<02:32,  3.02it/s, loss=0.143, v_num=38, loss_step=0.113, train/loss_simple_step=0.113, train/loss_vlb_step=0.00183, train/loss_step=0.113, global_step=18238.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 21:  47%|████▋     | 400/859 [02:12<02:32,  3.02it/s, loss=0.143, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00231, train/loss_step=0.137, global_step=18438.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 21:  70%|██████▉   | 600/859 [03:48<01:38,  2.63it/s, loss=0.143, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00231, train/loss_step=0.137, global_step=18438.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 21:  70%|██████▉   | 600/859 [03:48<01:38,  2.63it/s, loss=0.139, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00177, train/loss_step=0.137, global_step=18638.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 21:  93%|█████████▎| 800/859 [04:54<00:21,  2.72it/s, loss=0.139, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00177, train/loss_step=0.137, global_step=18638.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 21:  93%|█████████▎| 800/859 [04:54<00:21,  2.72it/s, loss=0.142, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00187, train/loss_step=0.151, global_step=18838.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 21: 100%|██████████| 859/859 [05:14<00:00,  2.74it/s, loss=0.142, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00187, train/loss_step=0.151, global_step=18838.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 21: 100%|██████████| 859/859 [05:14<00:00,  2.74it/s, loss=0.145, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00218, train/loss_step=0.133, global_step=18897.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 21:   0%|          | 0/859 [00:00<00:00, 24105.20it/s, loss=0.145, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00218, train/loss_step=0.133, global_step=18897.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 22:   0%|          | 0/859 [00:00<00:00, 3331.46it/s, loss=0.145, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00218, train/loss_step=0.133, global_step=18897.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 22:  23%|██▎       | 200/859 [01:37<05:20,  2.06it/s, loss=0.145, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00218, train/loss_step=0.133, global_step=18897.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 22:  23%|██▎       | 200/859 [01:37<05:20,  2.06it/s, loss=0.143, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00231, train/loss_step=0.139, global_step=19097.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 22:  47%|████▋     | 400/859 [02:44<03:08,  2.44it/s, loss=0.143, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00231, train/loss_step=0.139, global_step=19097.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 22:  47%|████▋     | 400/859 [02:44<03:08,  2.44it/s, loss=0.142, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00251, train/loss_step=0.143, global_step=19297.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 22:  70%|██████▉   | 600/859 [03:51<01:39,  2.60it/s, loss=0.142, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00251, train/loss_step=0.143, global_step=19297.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 22:  70%|██████▉   | 600/859 [03:51<01:39,  2.60it/s, loss=0.143, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00266, train/loss_step=0.143, global_step=19497.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 22:  93%|█████████▎| 800/859 [05:28<00:24,  2.44it/s, loss=0.143, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00266, train/loss_step=0.143, global_step=19497.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 22:  93%|█████████▎| 800/859 [05:28<00:24,  2.44it/s, loss=0.147, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00255, train/loss_step=0.131, global_step=19697.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 22: 100%|██████████| 859/859 [05:48<00:00,  2.47it/s, loss=0.147, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00255, train/loss_step=0.131, global_step=19697.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 22: 100%|██████████| 859/859 [05:48<00:00,  2.47it/s, loss=0.145, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00363, train/loss_step=0.152, global_step=19756.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 22:   0%|          | 0/859 [00:00<00:00, 23431.87it/s, loss=0.145, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00363, train/loss_step=0.152, global_step=19756.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 23:   0%|          | 0/859 [00:00<00:00, 2467.24it/s, loss=0.145, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00363, train/loss_step=0.152, global_step=19756.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143] 
Epoch 23:  23%|██▎       | 200/859 [01:06<03:39,  3.00it/s, loss=0.145, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00363, train/loss_step=0.152, global_step=19756.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 23:  23%|██▎       | 200/859 [01:06<03:39,  3.00it/s, loss=0.139, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.003, train/loss_step=0.139, global_step=2e+4, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]     pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 23:  47%|████▋     | 400/859 [02:43<03:07,  2.45it/s, loss=0.139, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.003, train/loss_step=0.139, global_step=2e+4, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 23:  47%|████▋     | 400/859 [02:43<03:07,  2.45it/s, loss=0.144, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00192, train/loss_step=0.141, global_step=20156.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 23:  70%|██████▉   | 600/859 [03:50<01:39,  2.61it/s, loss=0.144, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00192, train/loss_step=0.141, global_step=20156.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 23:  70%|██████▉   | 600/859 [03:50<01:39,  2.61it/s, loss=0.143, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00275, train/loss_step=0.141, global_step=20356.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 23:  93%|█████████▎| 800/859 [05:27<00:24,  2.44it/s, loss=0.143, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00275, train/loss_step=0.141, global_step=20356.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 23:  93%|█████████▎| 800/859 [05:27<00:24,  2.44it/s, loss=0.147, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.00248, train/loss_step=0.153, global_step=20556.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 23:   0%|          | 0/859 [00:00<00:00, 22671.91it/s, loss=0.147, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.00248, train/loss_step=0.153, global_step=20556.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 24:   0%|          | 0/859 [00:00<00:00, 2400.86it/s, loss=0.147, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.00248, train/loss_step=0.153, global_step=20556.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143] 
Epoch 24:  23%|██▎       | 200/859 [01:06<03:38,  3.01it/s, loss=0.147, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.00248, train/loss_step=0.153, global_step=20556.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 24:  23%|██▎       | 200/859 [01:06<03:38,  3.01it/s, loss=0.145, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00201, train/loss_step=0.135, global_step=20812.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.143]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 24:  47%|████▋     | 400/859 [02:43<03:07,  2.45it/s, loss=0.145, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00201, train/loss_step=0.135, global_step=20812.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.143]
Epoch 24:  47%|████▋     | 400/859 [02:43<03:07,  2.45it/s, loss=0.144, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00206, train/loss_step=0.130, global_step=2.1e+4, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.143] 
Epoch 24:  70%|██████▉   | 600/859 [03:50<01:39,  2.61it/s, loss=0.144, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00206, train/loss_step=0.130, global_step=2.1e+4, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.143]
Epoch 24:  70%|██████▉   | 600/859 [03:50<01:39,  2.61it/s, loss=0.144, v_num=38, loss_step=0.166, train/loss_simple_step=0.166, train/loss_vlb_step=0.00321, train/loss_step=0.166, global_step=21212.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.143]
Epoch 24:  93%|█████████▎| 800/859 [04:56<00:21,  2.70it/s, loss=0.144, v_num=38, loss_step=0.166, train/loss_simple_step=0.166, train/loss_vlb_step=0.00321, train/loss_step=0.166, global_step=21212.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.143]
Epoch 24:  93%|█████████▎| 800/859 [04:56<00:21,  2.70it/s, loss=0.142, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00231, train/loss_step=0.139, global_step=21412.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.143]
Epoch 24: 100%|██████████| 859/859 [05:16<00:00,  2.71it/s, loss=0.142, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00231, train/loss_step=0.139, global_step=21412.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.143]
Epoch 24: 100%|██████████| 859/859 [05:16<00:00,  2.71it/s, loss=0.144, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00219, train/loss_step=0.136, global_step=21471.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.143]
Epoch 24:   0%|          | 0/859 [00:00<00:00, 23301.69it/s, loss=0.144, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00219, train/loss_step=0.136, global_step=21471.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.143]
Epoch 25:   0%|          | 0/859 [00:00<00:00, 2185.67it/s, loss=0.144, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00219, train/loss_step=0.136, global_step=21471.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.143] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 25:  23%|██▎       | 200/859 [01:37<05:20,  2.05it/s, loss=0.144, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00219, train/loss_step=0.136, global_step=21471.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.143]
Epoch 25:  23%|██▎       | 200/859 [01:37<05:20,  2.05it/s, loss=0.141, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00334, train/loss_step=0.138, global_step=21671.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 25:  47%|████▋     | 400/859 [02:44<03:08,  2.44it/s, loss=0.141, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00334, train/loss_step=0.138, global_step=21671.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 25:  47%|████▋     | 400/859 [02:44<03:08,  2.44it/s, loss=0.143, v_num=38, loss_step=0.158, train/loss_simple_step=0.158, train/loss_vlb_step=0.00306, train/loss_step=0.158, global_step=21871.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 25:  70%|██████▉   | 600/859 [04:23<01:53,  2.28it/s, loss=0.143, v_num=38, loss_step=0.158, train/loss_simple_step=0.158, train/loss_vlb_step=0.00306, train/loss_step=0.158, global_step=21871.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 25:  70%|██████▉   | 600/859 [04:23<01:53,  2.28it/s, loss=0.146, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00181, train/loss_step=0.139, global_step=22071.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 25:  93%|█████████▎| 800/859 [05:30<00:24,  2.42it/s, loss=0.146, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00181, train/loss_step=0.139, global_step=22071.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 25:  93%|█████████▎| 800/859 [05:30<00:24,  2.42it/s, loss=0.143, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00237, train/loss_step=0.143, global_step=22271.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 25: 100%|██████████| 859/859 [05:50<00:00,  2.46it/s, loss=0.143, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00237, train/loss_step=0.143, global_step=22271.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 25: 100%|██████████| 859/859 [05:50<00:00,  2.46it/s, loss=0.145, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00371, train/loss_step=0.132, global_step=22330.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 25:   0%|          | 0/859 [00:00<00:00, 22192.08it/s, loss=0.145, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00371, train/loss_step=0.132, global_step=22330.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 26:   0%|          | 0/859 [00:00<00:00, 1694.67it/s, loss=0.145, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00371, train/loss_step=0.132, global_step=22330.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 26:  23%|██▎       | 200/859 [01:38<05:22,  2.04it/s, loss=0.145, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00371, train/loss_step=0.132, global_step=22330.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.143]
Epoch 26:  23%|██▎       | 200/859 [01:38<05:22,  2.04it/s, loss=0.145, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00122, train/loss_step=0.135, global_step=22530.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 26:  47%|████▋     | 400/859 [02:45<03:08,  2.43it/s, loss=0.145, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00122, train/loss_step=0.135, global_step=22530.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 26:  47%|████▋     | 400/859 [02:45<03:08,  2.43it/s, loss=0.14, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00195, train/loss_step=0.140, global_step=22730.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142] 
Epoch 26:  70%|██████▉   | 600/859 [03:51<01:39,  2.59it/s, loss=0.14, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00195, train/loss_step=0.140, global_step=22730.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 26:  70%|██████▉   | 600/859 [03:51<01:39,  2.59it/s, loss=0.143, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00518, train/loss_step=0.146, global_step=22930.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 26:  93%|█████████▎| 800/859 [05:29<00:24,  2.43it/s, loss=0.143, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00518, train/loss_step=0.146, global_step=22930.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 26:  93%|█████████▎| 800/859 [05:29<00:24,  2.43it/s, loss=0.143, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00234, train/loss_step=0.147, global_step=23130.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 26: 100%|██████████| 859/859 [05:48<00:00,  2.47it/s, loss=0.143, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00234, train/loss_step=0.147, global_step=23130.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 26: 100%|██████████| 859/859 [05:48<00:00,  2.47it/s, loss=0.139, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00226, train/loss_step=0.138, global_step=23189.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 26:   0%|          | 0/859 [00:00<00:00, 22192.08it/s, loss=0.139, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00226, train/loss_step=0.138, global_step=23189.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 27:   0%|          | 0/859 [00:00<00:00, 2003.01it/s, loss=0.139, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00226, train/loss_step=0.138, global_step=23189.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142] 
Epoch 27:  23%|██▎       | 200/859 [01:06<03:38,  3.01it/s, loss=0.139, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00226, train/loss_step=0.138, global_step=23189.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 27:  23%|██▎       | 200/859 [01:06<03:38,  3.01it/s, loss=0.144, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00407, train/loss_step=0.136, global_step=23389.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 27:  47%|████▋     | 400/859 [02:45<03:09,  2.42it/s, loss=0.144, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00407, train/loss_step=0.136, global_step=23389.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 27:  47%|████▋     | 400/859 [02:45<03:09,  2.42it/s, loss=0.144, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00328, train/loss_step=0.141, global_step=23589.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 27:  70%|██████▉   | 600/859 [03:52<01:40,  2.59it/s, loss=0.144, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00328, train/loss_step=0.141, global_step=23589.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 27:  70%|██████▉   | 600/859 [03:52<01:40,  2.59it/s, loss=0.145, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00342, train/loss_step=0.143, global_step=23789.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 27:  93%|█████████▎| 800/859 [04:59<00:22,  2.68it/s, loss=0.145, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00342, train/loss_step=0.143, global_step=23789.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 27:  93%|█████████▎| 800/859 [04:59<00:22,  2.68it/s, loss=0.141, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00253, train/loss_step=0.139, global_step=2.4e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 27: 100%|██████████| 859/859 [05:49<00:00,  2.46it/s, loss=0.141, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00253, train/loss_step=0.139, global_step=2.4e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 27: 100%|██████████| 859/859 [05:49<00:00,  2.46it/s, loss=0.142, v_num=38, loss_step=0.156, train/loss_simple_step=0.156, train/loss_vlb_step=0.00328, train/loss_step=0.156, global_step=2.4e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 27:   0%|          | 0/859 [00:00<00:00, 23045.63it/s, loss=0.142, v_num=38, loss_step=0.156, train/loss_simple_step=0.156, train/loss_vlb_step=0.00328, train/loss_step=0.156, global_step=2.4e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 28:   0%|          | 0/859 [00:00<00:00, 3606.45it/s, loss=0.142, v_num=38, loss_step=0.156, train/loss_simple_step=0.156, train/loss_vlb_step=0.00328, train/loss_step=0.156, global_step=2.4e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142] 
Epoch 28:  23%|██▎       | 200/859 [01:06<03:39,  3.01it/s, loss=0.142, v_num=38, loss_step=0.156, train/loss_simple_step=0.156, train/loss_vlb_step=0.00328, train/loss_step=0.156, global_step=2.4e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 28:  23%|██▎       | 200/859 [01:06<03:39,  3.01it/s, loss=0.14, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00334, train/loss_step=0.130, global_step=24248.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]
Epoch 28:  47%|████▋     | 400/859 [02:13<02:33,  2.99it/s, loss=0.14, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00334, train/loss_step=0.130, global_step=24248.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]
Epoch 28:  47%|████▋     | 400/859 [02:13<02:33,  2.99it/s, loss=0.141, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00274, train/loss_step=0.140, global_step=24448.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 28:  70%|██████▉   | 600/859 [03:50<01:39,  2.61it/s, loss=0.141, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00274, train/loss_step=0.140, global_step=24448.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]
Epoch 28:  70%|██████▉   | 600/859 [03:50<01:39,  2.61it/s, loss=0.141, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00184, train/loss_step=0.136, global_step=24648.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]
Epoch 28:  93%|█████████▎| 800/859 [04:57<00:21,  2.69it/s, loss=0.141, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00184, train/loss_step=0.136, global_step=24648.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]
Epoch 28:  93%|█████████▎| 800/859 [04:57<00:21,  2.69it/s, loss=0.142, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00156, train/loss_step=0.150, global_step=24848.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]
Epoch 28: 100%|██████████| 859/859 [05:17<00:00,  2.71it/s, loss=0.142, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00156, train/loss_step=0.150, global_step=24848.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]
Epoch 28: 100%|██████████| 859/859 [05:17<00:00,  2.71it/s, loss=0.142, v_num=38, loss_step=0.155, train/loss_simple_step=0.155, train/loss_vlb_step=0.00284, train/loss_step=0.155, global_step=24907.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]
Epoch 28:   0%|          | 0/859 [00:00<00:00, 21845.33it/s, loss=0.142, v_num=38, loss_step=0.155, train/loss_simple_step=0.155, train/loss_vlb_step=0.00284, train/loss_step=0.155, global_step=24907.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]
Epoch 29:   0%|          | 0/859 [00:00<00:00, 1602.10it/s, loss=0.142, v_num=38, loss_step=0.155, train/loss_simple_step=0.155, train/loss_vlb_step=0.00284, train/loss_step=0.155, global_step=24907.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 29:  23%|██▎       | 200/859 [01:37<05:18,  2.07it/s, loss=0.142, v_num=38, loss_step=0.155, train/loss_simple_step=0.155, train/loss_vlb_step=0.00284, train/loss_step=0.155, global_step=24907.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]
Epoch 29:  23%|██▎       | 200/859 [01:37<05:18,  2.07it/s, loss=0.143, v_num=38, loss_step=0.122, train/loss_simple_step=0.122, train/loss_vlb_step=0.00125, train/loss_step=0.122, global_step=25107.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 29:  47%|████▋     | 400/859 [02:43<03:07,  2.45it/s, loss=0.143, v_num=38, loss_step=0.122, train/loss_simple_step=0.122, train/loss_vlb_step=0.00125, train/loss_step=0.122, global_step=25107.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 29:  47%|████▋     | 400/859 [02:43<03:07,  2.45it/s, loss=0.146, v_num=38, loss_step=0.128, train/loss_simple_step=0.128, train/loss_vlb_step=0.00406, train/loss_step=0.128, global_step=25307.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 29:  70%|██████▉   | 600/859 [04:21<01:52,  2.30it/s, loss=0.146, v_num=38, loss_step=0.128, train/loss_simple_step=0.128, train/loss_vlb_step=0.00406, train/loss_step=0.128, global_step=25307.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 29:  70%|██████▉   | 600/859 [04:21<01:52,  2.30it/s, loss=0.139, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00205, train/loss_step=0.144, global_step=25507.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 29:  93%|█████████▎| 800/859 [05:27<00:24,  2.45it/s, loss=0.139, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00205, train/loss_step=0.144, global_step=25507.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 29:  93%|█████████▎| 800/859 [05:27<00:24,  2.45it/s, loss=0.141, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00235, train/loss_step=0.147, global_step=25707.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 29: 100%|██████████| 859/859 [05:47<00:00,  2.48it/s, loss=0.141, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00235, train/loss_step=0.147, global_step=25707.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 29: 100%|██████████| 859/859 [05:47<00:00,  2.48it/s, loss=0.142, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00342, train/loss_step=0.150, global_step=25766.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 29:   0%|          | 0/859 [00:00<00:00, 24244.53it/s, loss=0.142, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00342, train/loss_step=0.150, global_step=25766.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 30:   0%|          | 0/859 [00:00<00:00, 2157.56it/s, loss=0.142, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00342, train/loss_step=0.150, global_step=25766.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142] 
Epoch 30:  23%|██▎       | 200/859 [01:06<03:38,  3.02it/s, loss=0.142, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00342, train/loss_step=0.150, global_step=25766.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 30:  23%|██▎       | 200/859 [01:06<03:38,  3.02it/s, loss=0.142, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00234, train/loss_step=0.141, global_step=2.6e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 30:  47%|████▋     | 400/859 [02:41<03:04,  2.48it/s, loss=0.142, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00234, train/loss_step=0.141, global_step=2.6e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 30:  47%|████▋     | 400/859 [02:41<03:04,  2.48it/s, loss=0.142, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.000992, train/loss_step=0.131, global_step=26166.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 30:  70%|██████▉   | 600/859 [03:47<01:38,  2.64it/s, loss=0.142, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.000992, train/loss_step=0.131, global_step=26166.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 30:  70%|██████▉   | 600/859 [03:47<01:38,  2.64it/s, loss=0.143, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00301, train/loss_step=0.135, global_step=26366.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 30:  93%|█████████▎| 800/859 [05:24<00:23,  2.47it/s, loss=0.143, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00301, train/loss_step=0.135, global_step=26366.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 30:  93%|█████████▎| 800/859 [05:24<00:23,  2.47it/s, loss=0.145, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00173, train/loss_step=0.149, global_step=26566.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 30: 100%|██████████| 859/859 [05:44<00:00,  2.50it/s, loss=0.145, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00173, train/loss_step=0.149, global_step=26566.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 30: 100%|██████████| 859/859 [05:44<00:00,  2.50it/s, loss=0.142, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00305, train/loss_step=0.146, global_step=26625.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 30:   0%|          | 0/859 [00:00<00:00, 24105.20it/s, loss=0.142, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00305, train/loss_step=0.146, global_step=26625.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 31:   0%|          | 0/859 [00:00<00:00, 2018.43it/s, loss=0.142, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00305, train/loss_step=0.146, global_step=26625.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142] 
Epoch 31:  23%|██▎       | 200/859 [01:06<03:38,  3.02it/s, loss=0.142, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00305, train/loss_step=0.146, global_step=26625.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 31:  23%|██▎       | 200/859 [01:06<03:38,  3.02it/s, loss=0.141, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00229, train/loss_step=0.137, global_step=26825.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 31:  47%|████▋     | 400/859 [02:42<03:05,  2.47it/s, loss=0.141, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00229, train/loss_step=0.137, global_step=26825.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 31:  47%|████▋     | 400/859 [02:42<03:05,  2.47it/s, loss=0.142, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.0027, train/loss_step=0.144, global_step=2.7e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]  
Epoch 31:  70%|██████▉   | 600/859 [03:48<01:38,  2.63it/s, loss=0.142, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.0027, train/loss_step=0.144, global_step=2.7e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 31:  70%|██████▉   | 600/859 [03:48<01:38,  2.63it/s, loss=0.144, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00312, train/loss_step=0.144, global_step=27225.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 31:  93%|█████████▎| 800/859 [04:54<00:21,  2.72it/s, loss=0.144, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00312, train/loss_step=0.144, global_step=27225.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 31:  93%|█████████▎| 800/859 [04:54<00:21,  2.72it/s, loss=0.141, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00229, train/loss_step=0.135, global_step=27425.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 31: 100%|██████████| 859/859 [05:14<00:00,  2.74it/s, loss=0.141, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00229, train/loss_step=0.135, global_step=27425.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 31: 100%|██████████| 859/859 [05:14<00:00,  2.74it/s, loss=0.142, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00132, train/loss_step=0.151, global_step=27484.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 31:   0%|          | 0/859 [00:00<00:00, 28339.89it/s, loss=0.142, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00132, train/loss_step=0.151, global_step=27484.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 32:   0%|          | 0/859 [00:00<00:00, 4364.52it/s, loss=0.142, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00132, train/loss_step=0.151, global_step=27484.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 32:  23%|██▎       | 200/859 [01:32<05:02,  2.18it/s, loss=0.142, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00132, train/loss_step=0.151, global_step=27484.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 32:  23%|██▎       | 200/859 [01:32<05:02,  2.18it/s, loss=0.145, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00256, train/loss_step=0.134, global_step=27684.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]
Epoch 32:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.145, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00256, train/loss_step=0.134, global_step=27684.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]
Epoch 32:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.142, v_num=38, loss_step=0.154, train/loss_simple_step=0.154, train/loss_vlb_step=0.00301, train/loss_step=0.154, global_step=27884.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 32:  70%|██████▉   | 600/859 [04:10<01:48,  2.40it/s, loss=0.142, v_num=38, loss_step=0.154, train/loss_simple_step=0.154, train/loss_vlb_step=0.00301, train/loss_step=0.154, global_step=27884.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]
Epoch 32:  70%|██████▉   | 600/859 [04:10<01:48,  2.40it/s, loss=0.141, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00267, train/loss_step=0.148, global_step=28084.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]
Epoch 32:  93%|█████████▎| 800/859 [05:16<00:23,  2.53it/s, loss=0.141, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00267, train/loss_step=0.148, global_step=28084.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]
Epoch 32:  93%|█████████▎| 800/859 [05:16<00:23,  2.53it/s, loss=0.141, v_num=38, loss_step=0.125, train/loss_simple_step=0.125, train/loss_vlb_step=0.00242, train/loss_step=0.125, global_step=28284.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]
Epoch 32: 100%|██████████| 859/859 [05:36<00:00,  2.56it/s, loss=0.141, v_num=38, loss_step=0.125, train/loss_simple_step=0.125, train/loss_vlb_step=0.00242, train/loss_step=0.125, global_step=28284.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]
Epoch 32: 100%|██████████| 859/859 [05:36<00:00,  2.56it/s, loss=0.144, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00128, train/loss_step=0.130, global_step=28343.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]
Epoch 32:   0%|          | 0/859 [00:00<00:00, 25575.02it/s, loss=0.144, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00128, train/loss_step=0.130, global_step=28343.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]
Epoch 33:   0%|          | 0/859 [00:00<00:00, 3385.23it/s, loss=0.144, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00128, train/loss_step=0.130, global_step=28343.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 33:  23%|██▎       | 200/859 [01:32<05:04,  2.17it/s, loss=0.144, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00128, train/loss_step=0.130, global_step=28343.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.142]
Epoch 33:  23%|██▎       | 200/859 [01:32<05:04,  2.17it/s, loss=0.144, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.00229, train/loss_step=0.153, global_step=28543.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 33:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.144, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.00229, train/loss_step=0.153, global_step=28543.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 33:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.144, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00199, train/loss_step=0.142, global_step=28743.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 33:  70%|██████▉   | 600/859 [03:44<01:36,  2.68it/s, loss=0.144, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00199, train/loss_step=0.142, global_step=28743.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 33:  70%|██████▉   | 600/859 [03:44<01:36,  2.68it/s, loss=0.142, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00113, train/loss_step=0.135, global_step=28943.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 33:  93%|█████████▎| 800/859 [05:17<00:23,  2.52it/s, loss=0.142, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00113, train/loss_step=0.135, global_step=28943.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 33:  93%|█████████▎| 800/859 [05:17<00:23,  2.52it/s, loss=0.144, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.0043, train/loss_step=0.147, global_step=29143.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142] 
Epoch 33: 100%|██████████| 859/859 [05:36<00:00,  2.55it/s, loss=0.144, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.0043, train/loss_step=0.147, global_step=29143.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 33: 100%|██████████| 859/859 [05:36<00:00,  2.55it/s, loss=0.145, v_num=38, loss_step=0.165, train/loss_simple_step=0.165, train/loss_vlb_step=0.00262, train/loss_step=0.165, global_step=29202.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 33:   0%|          | 0/859 [00:00<00:00, 26546.23it/s, loss=0.145, v_num=38, loss_step=0.165, train/loss_simple_step=0.165, train/loss_vlb_step=0.00262, train/loss_step=0.165, global_step=29202.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 34:   0%|          | 0/859 [00:00<00:00, 3631.43it/s, loss=0.145, v_num=38, loss_step=0.165, train/loss_simple_step=0.165, train/loss_vlb_step=0.00262, train/loss_step=0.165, global_step=29202.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142] 
Epoch 34:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.145, v_num=38, loss_step=0.165, train/loss_simple_step=0.165, train/loss_vlb_step=0.00262, train/loss_step=0.165, global_step=29202.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 34:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.142, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00345, train/loss_step=0.152, global_step=29402.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.143]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 34:  47%|████▋     | 400/859 [02:39<03:02,  2.52it/s, loss=0.142, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00345, train/loss_step=0.152, global_step=29402.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.143]
Epoch 34:  47%|████▋     | 400/859 [02:39<03:02,  2.52it/s, loss=0.145, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00143, train/loss_step=0.140, global_step=29602.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.143]
Epoch 34:  70%|██████▉   | 600/859 [03:45<01:37,  2.67it/s, loss=0.145, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00143, train/loss_step=0.140, global_step=29602.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.143]
Epoch 34:  70%|██████▉   | 600/859 [03:45<01:37,  2.67it/s, loss=0.146, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00113, train/loss_step=0.136, global_step=29802.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.143]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 34:  93%|█████████▎| 800/859 [05:17<00:23,  2.52it/s, loss=0.146, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00113, train/loss_step=0.136, global_step=29802.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.143]
Epoch 34:  93%|█████████▎| 800/859 [05:17<00:23,  2.52it/s, loss=0.143, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00196, train/loss_step=0.136, global_step=3e+4, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.143]   
Epoch 34: 100%|██████████| 859/859 [05:37<00:00,  2.55it/s, loss=0.143, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00196, train/loss_step=0.136, global_step=3e+4, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.143]
Epoch 34: 100%|██████████| 859/859 [05:37<00:00,  2.55it/s, loss=0.143, v_num=38, loss_step=0.127, train/loss_simple_step=0.127, train/loss_vlb_step=0.00246, train/loss_step=0.127, global_step=30061.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.143]
Epoch 34:   0%|          | 0/859 [00:00<00:00, 26715.31it/s, loss=0.143, v_num=38, loss_step=0.127, train/loss_simple_step=0.127, train/loss_vlb_step=0.00246, train/loss_step=0.127, global_step=30061.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.143]
Epoch 35:   0%|          | 0/859 [00:00<00:00, 5017.11it/s, loss=0.143, v_num=38, loss_step=0.127, train/loss_simple_step=0.127, train/loss_vlb_step=0.00246, train/loss_step=0.127, global_step=30061.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.143] 
Epoch 35:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.143, v_num=38, loss_step=0.127, train/loss_simple_step=0.127, train/loss_vlb_step=0.00246, train/loss_step=0.127, global_step=30061.0, loss_epoch=0.143, train/loss_simple_epoch=0.143, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.143]
Epoch 35:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.141, v_num=38, loss_step=0.154, train/loss_simple_step=0.154, train/loss_vlb_step=0.0024, train/loss_step=0.154, global_step=30261.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142] 
Epoch 35:  47%|████▋     | 400/859 [02:12<02:31,  3.04it/s, loss=0.141, v_num=38, loss_step=0.154, train/loss_simple_step=0.154, train/loss_vlb_step=0.0024, train/loss_step=0.154, global_step=30261.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142]
Epoch 35:  47%|████▋     | 400/859 [02:12<02:31,  3.04it/s, loss=0.142, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00179, train/loss_step=0.146, global_step=30461.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 35:  70%|██████▉   | 600/859 [03:44<01:36,  2.68it/s, loss=0.142, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00179, train/loss_step=0.146, global_step=30461.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142]
Epoch 35:  70%|██████▉   | 600/859 [03:44<01:36,  2.68it/s, loss=0.143, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00128, train/loss_step=0.138, global_step=30661.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142]
Epoch 35:  93%|█████████▎| 800/859 [04:50<00:21,  2.75it/s, loss=0.143, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00128, train/loss_step=0.138, global_step=30661.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142]
Epoch 35:  93%|█████████▎| 800/859 [04:50<00:21,  2.75it/s, loss=0.14, v_num=38, loss_step=0.128, train/loss_simple_step=0.128, train/loss_vlb_step=0.00118, train/loss_step=0.128, global_step=30861.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142] 
Epoch 35: 100%|██████████| 859/859 [05:10<00:00,  2.77it/s, loss=0.14, v_num=38, loss_step=0.128, train/loss_simple_step=0.128, train/loss_vlb_step=0.00118, train/loss_step=0.128, global_step=30861.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142]
Epoch 35: 100%|██████████| 859/859 [05:10<00:00,  2.77it/s, loss=0.143, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00239, train/loss_step=0.137, global_step=30920.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142]
Epoch 35:   0%|          | 0/859 [00:00<00:00, 27060.03it/s, loss=0.143, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00239, train/loss_step=0.137, global_step=30920.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142]
Epoch 36:   0%|          | 0/859 [00:00<00:00, 2525.17it/s, loss=0.143, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00239, train/loss_step=0.137, global_step=30920.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 36:  23%|██▎       | 200/859 [01:32<05:02,  2.18it/s, loss=0.143, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00239, train/loss_step=0.137, global_step=30920.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142]
Epoch 36:  23%|██▎       | 200/859 [01:32<05:02,  2.18it/s, loss=0.145, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00131, train/loss_step=0.142, global_step=31120.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 36:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.145, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00131, train/loss_step=0.142, global_step=31120.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 36:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.141, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.0037, train/loss_step=0.141, global_step=31320.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 36:  70%|██████▉   | 600/859 [04:11<01:48,  2.39it/s, loss=0.141, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.0037, train/loss_step=0.141, global_step=31320.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 36:  70%|██████▉   | 600/859 [04:11<01:48,  2.39it/s, loss=0.138, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00198, train/loss_step=0.141, global_step=31520.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 36:  93%|█████████▎| 800/859 [05:16<00:23,  2.53it/s, loss=0.138, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00198, train/loss_step=0.141, global_step=31520.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 36:  93%|█████████▎| 800/859 [05:16<00:23,  2.53it/s, loss=0.141, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00234, train/loss_step=0.138, global_step=31720.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 36: 100%|██████████| 859/859 [05:36<00:00,  2.56it/s, loss=0.141, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00234, train/loss_step=0.138, global_step=31720.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 36: 100%|██████████| 859/859 [05:36<00:00,  2.56it/s, loss=0.139, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00294, train/loss_step=0.148, global_step=31779.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 36:   0%|          | 0/859 [00:00<00:00, 26051.58it/s, loss=0.139, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00294, train/loss_step=0.148, global_step=31779.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 37:   0%|          | 0/859 [00:00<00:00, 3530.56it/s, loss=0.139, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00294, train/loss_step=0.148, global_step=31779.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142] 
Epoch 37:  23%|██▎       | 200/859 [01:05<03:36,  3.05it/s, loss=0.139, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00294, train/loss_step=0.148, global_step=31779.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 37:  23%|██▎       | 200/859 [01:05<03:36,  3.05it/s, loss=0.142, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00287, train/loss_step=0.140, global_step=3.2e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 37:  47%|████▋     | 400/859 [02:38<03:00,  2.54it/s, loss=0.142, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00287, train/loss_step=0.140, global_step=3.2e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 37:  47%|████▋     | 400/859 [02:38<03:00,  2.54it/s, loss=0.142, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00365, train/loss_step=0.143, global_step=32179.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 37:  70%|██████▉   | 600/859 [03:43<01:36,  2.68it/s, loss=0.142, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00365, train/loss_step=0.143, global_step=32179.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 37:  70%|██████▉   | 600/859 [03:43<01:36,  2.68it/s, loss=0.144, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00193, train/loss_step=0.137, global_step=32379.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 37:  93%|█████████▎| 800/859 [05:16<00:23,  2.53it/s, loss=0.144, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00193, train/loss_step=0.137, global_step=32379.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 37:  93%|█████████▎| 800/859 [05:16<00:23,  2.53it/s, loss=0.141, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00176, train/loss_step=0.141, global_step=32579.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 37: 100%|██████████| 859/859 [05:36<00:00,  2.56it/s, loss=0.141, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00176, train/loss_step=0.141, global_step=32579.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 37: 100%|██████████| 859/859 [05:36<00:00,  2.56it/s, loss=0.145, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00273, train/loss_step=0.150, global_step=32638.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 37:   0%|          | 0/859 [00:00<00:00, 26886.56it/s, loss=0.145, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00273, train/loss_step=0.150, global_step=32638.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 38:   0%|          | 0/859 [00:00<00:00, 3802.63it/s, loss=0.145, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00273, train/loss_step=0.150, global_step=32638.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142] 
Epoch 38:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.145, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00273, train/loss_step=0.150, global_step=32638.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 38:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.144, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00276, train/loss_step=0.134, global_step=32838.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00262, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 38:  47%|████▋     | 400/859 [02:38<03:01,  2.52it/s, loss=0.144, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00276, train/loss_step=0.134, global_step=32838.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00262, train/loss_epoch=0.142]
Epoch 38:  47%|████▋     | 400/859 [02:38<03:01,  2.52it/s, loss=0.143, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00175, train/loss_step=0.139, global_step=3.3e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00262, train/loss_epoch=0.142] 
Epoch 38:  70%|██████▉   | 600/859 [03:44<01:36,  2.67it/s, loss=0.143, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00175, train/loss_step=0.139, global_step=3.3e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00262, train/loss_epoch=0.142]
Epoch 38:  70%|██████▉   | 600/859 [03:44<01:36,  2.67it/s, loss=0.138, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00362, train/loss_step=0.130, global_step=33238.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00262, train/loss_epoch=0.142]
Epoch 38:  93%|█████████▎| 800/859 [04:50<00:21,  2.75it/s, loss=0.138, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00362, train/loss_step=0.130, global_step=33238.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00262, train/loss_epoch=0.142]
Epoch 38:  93%|█████████▎| 800/859 [04:50<00:21,  2.75it/s, loss=0.139, v_num=38, loss_step=0.155, train/loss_simple_step=0.155, train/loss_vlb_step=0.00271, train/loss_step=0.155, global_step=33438.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00262, train/loss_epoch=0.142]
Epoch 38: 100%|██████████| 859/859 [05:10<00:00,  2.77it/s, loss=0.139, v_num=38, loss_step=0.155, train/loss_simple_step=0.155, train/loss_vlb_step=0.00271, train/loss_step=0.155, global_step=33438.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00262, train/loss_epoch=0.142]
Epoch 38: 100%|██████████| 859/859 [05:10<00:00,  2.77it/s, loss=0.143, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00329, train/loss_step=0.152, global_step=33497.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00262, train/loss_epoch=0.142]
Epoch 38:   0%|          | 0/859 [00:00<00:00, 26715.31it/s, loss=0.143, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00329, train/loss_step=0.152, global_step=33497.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00262, train/loss_epoch=0.142]
Epoch 39:   0%|          | 0/859 [00:00<00:00, 3765.08it/s, loss=0.143, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00329, train/loss_step=0.152, global_step=33497.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00262, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 39:  23%|██▎       | 200/859 [01:32<05:04,  2.16it/s, loss=0.143, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00329, train/loss_step=0.152, global_step=33497.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00262, train/loss_epoch=0.142]
Epoch 39:  23%|██▎       | 200/859 [01:32<05:04,  2.16it/s, loss=0.141, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.0029, train/loss_step=0.148, global_step=33697.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142] 
Epoch 39:  47%|████▋     | 400/859 [02:38<03:01,  2.52it/s, loss=0.141, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.0029, train/loss_step=0.148, global_step=33697.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 39:  47%|████▋     | 400/859 [02:38<03:01,  2.52it/s, loss=0.143, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00503, train/loss_step=0.151, global_step=33897.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 39:  70%|██████▉   | 600/859 [04:11<01:48,  2.39it/s, loss=0.143, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00503, train/loss_step=0.151, global_step=33897.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 39:  70%|██████▉   | 600/859 [04:11<01:48,  2.39it/s, loss=0.139, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00313, train/loss_step=0.150, global_step=34097.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 39:  93%|█████████▎| 800/859 [05:17<00:23,  2.52it/s, loss=0.139, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00313, train/loss_step=0.150, global_step=34097.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 39:  93%|█████████▎| 800/859 [05:17<00:23,  2.52it/s, loss=0.141, v_num=38, loss_step=0.123, train/loss_simple_step=0.123, train/loss_vlb_step=0.00188, train/loss_step=0.123, global_step=34297.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 39: 100%|██████████| 859/859 [05:36<00:00,  2.55it/s, loss=0.141, v_num=38, loss_step=0.123, train/loss_simple_step=0.123, train/loss_vlb_step=0.00188, train/loss_step=0.123, global_step=34297.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 39: 100%|██████████| 859/859 [05:36<00:00,  2.55it/s, loss=0.14, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00152, train/loss_step=0.136, global_step=34356.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142] 
Epoch 39:   0%|          | 0/859 [00:00<00:00, 27962.03it/s, loss=0.14, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00152, train/loss_step=0.136, global_step=34356.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 40:   0%|          | 0/859 [00:00<00:00, 3656.76it/s, loss=0.14, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00152, train/loss_step=0.136, global_step=34356.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 40:  23%|██▎       | 200/859 [01:32<05:04,  2.16it/s, loss=0.14, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00152, train/loss_step=0.136, global_step=34356.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 40:  23%|██▎       | 200/859 [01:32<05:04,  2.16it/s, loss=0.144, v_num=38, loss_step=0.128, train/loss_simple_step=0.128, train/loss_vlb_step=0.00157, train/loss_step=0.128, global_step=34556.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 40:  47%|████▋     | 400/859 [02:39<03:02,  2.52it/s, loss=0.144, v_num=38, loss_step=0.128, train/loss_simple_step=0.128, train/loss_vlb_step=0.00157, train/loss_step=0.128, global_step=34556.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 40:  47%|████▋     | 400/859 [02:39<03:02,  2.52it/s, loss=0.141, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00255, train/loss_step=0.131, global_step=34756.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 40:  70%|██████▉   | 600/859 [03:45<01:37,  2.67it/s, loss=0.141, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00255, train/loss_step=0.131, global_step=34756.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 40:  70%|██████▉   | 600/859 [03:45<01:37,  2.67it/s, loss=0.145, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00216, train/loss_step=0.136, global_step=3.5e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 40:  93%|█████████▎| 800/859 [05:17<00:23,  2.52it/s, loss=0.145, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00216, train/loss_step=0.136, global_step=3.5e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 40:  93%|█████████▎| 800/859 [05:17<00:23,  2.52it/s, loss=0.139, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00276, train/loss_step=0.138, global_step=35156.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 40:   0%|          | 0/859 [00:00<00:00, 26546.23it/s, loss=0.139, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00276, train/loss_step=0.138, global_step=35156.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 41:   0%|          | 0/859 [00:00<00:00, 3894.43it/s, loss=0.139, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00276, train/loss_step=0.138, global_step=35156.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142] 
Epoch 41:  23%|██▎       | 200/859 [01:05<03:36,  3.05it/s, loss=0.139, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00276, train/loss_step=0.138, global_step=35156.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 41:  23%|██▎       | 200/859 [01:05<03:36,  3.05it/s, loss=0.141, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.0016, train/loss_step=0.149, global_step=35413.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 41:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.141, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.0016, train/loss_step=0.149, global_step=35413.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 41:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.14, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00173, train/loss_step=0.133, global_step=35613.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 41:  70%|██████▉   | 600/859 [03:44<01:36,  2.67it/s, loss=0.14, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00173, train/loss_step=0.133, global_step=35613.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 41:  70%|██████▉   | 600/859 [03:44<01:36,  2.67it/s, loss=0.144, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00258, train/loss_step=0.139, global_step=35813.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 41:  93%|█████████▎| 800/859 [05:17<00:23,  2.52it/s, loss=0.144, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00258, train/loss_step=0.139, global_step=35813.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 41:  93%|█████████▎| 800/859 [05:17<00:23,  2.52it/s, loss=0.143, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00177, train/loss_step=0.138, global_step=3.6e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142] 
Epoch 41: 100%|██████████| 859/859 [05:37<00:00,  2.55it/s, loss=0.143, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00177, train/loss_step=0.138, global_step=3.6e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 41: 100%|██████████| 859/859 [05:37<00:00,  2.55it/s, loss=0.137, v_num=38, loss_step=0.128, train/loss_simple_step=0.128, train/loss_vlb_step=0.00168, train/loss_step=0.128, global_step=36072.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 41:   0%|          | 0/859 [00:00<00:00, 23431.87it/s, loss=0.137, v_num=38, loss_step=0.128, train/loss_simple_step=0.128, train/loss_vlb_step=0.00168, train/loss_step=0.128, global_step=36072.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 42:   0%|          | 0/859 [00:00<00:00, 2605.16it/s, loss=0.137, v_num=38, loss_step=0.128, train/loss_simple_step=0.128, train/loss_vlb_step=0.00168, train/loss_step=0.128, global_step=36072.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142] 
Epoch 42:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.137, v_num=38, loss_step=0.128, train/loss_simple_step=0.128, train/loss_vlb_step=0.00168, train/loss_step=0.128, global_step=36072.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 42:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.146, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.00453, train/loss_step=0.153, global_step=36272.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142]
Epoch 42:  47%|████▋     | 400/859 [02:11<02:30,  3.04it/s, loss=0.146, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.00453, train/loss_step=0.153, global_step=36272.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142]
Epoch 42:  47%|████▋     | 400/859 [02:11<02:30,  3.04it/s, loss=0.146, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00279, train/loss_step=0.140, global_step=36472.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 42:  70%|██████▉   | 600/859 [03:44<01:36,  2.68it/s, loss=0.146, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00279, train/loss_step=0.140, global_step=36472.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142]
Epoch 42:  70%|██████▉   | 600/859 [03:44<01:36,  2.68it/s, loss=0.143, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.0019, train/loss_step=0.135, global_step=36672.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142] 
Epoch 42:  93%|█████████▎| 800/859 [04:50<00:21,  2.76it/s, loss=0.143, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.0019, train/loss_step=0.135, global_step=36672.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142]
Epoch 42:  93%|█████████▎| 800/859 [04:50<00:21,  2.76it/s, loss=0.139, v_num=38, loss_step=0.160, train/loss_simple_step=0.160, train/loss_vlb_step=0.00413, train/loss_step=0.160, global_step=36872.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142]
Epoch 42: 100%|██████████| 859/859 [05:09<00:00,  2.78it/s, loss=0.139, v_num=38, loss_step=0.160, train/loss_simple_step=0.160, train/loss_vlb_step=0.00413, train/loss_step=0.160, global_step=36872.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142]
Epoch 42: 100%|██████████| 859/859 [05:09<00:00,  2.78it/s, loss=0.142, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.0019, train/loss_step=0.140, global_step=36931.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142] 
Epoch 42:   0%|          | 0/859 [00:00<00:00, 26546.23it/s, loss=0.142, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.0019, train/loss_step=0.140, global_step=36931.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142]
Epoch 43:   0%|          | 0/859 [00:00<00:00, 4364.52it/s, loss=0.142, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.0019, train/loss_step=0.140, global_step=36931.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 43:  23%|██▎       | 200/859 [01:32<05:02,  2.18it/s, loss=0.142, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.0019, train/loss_step=0.140, global_step=36931.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142]
Epoch 43:  23%|██▎       | 200/859 [01:32<05:02,  2.18it/s, loss=0.142, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00207, train/loss_step=0.142, global_step=37131.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 43:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.142, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00207, train/loss_step=0.142, global_step=37131.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 43:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.137, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00122, train/loss_step=0.133, global_step=37331.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 43:  70%|██████▉   | 600/859 [04:13<01:49,  2.37it/s, loss=0.137, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00122, train/loss_step=0.133, global_step=37331.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 43:  70%|██████▉   | 600/859 [04:13<01:49,  2.37it/s, loss=0.147, v_num=38, loss_step=0.155, train/loss_simple_step=0.155, train/loss_vlb_step=0.00212, train/loss_step=0.155, global_step=37531.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 43:  93%|█████████▎| 800/859 [05:19<00:23,  2.50it/s, loss=0.147, v_num=38, loss_step=0.155, train/loss_simple_step=0.155, train/loss_vlb_step=0.00212, train/loss_step=0.155, global_step=37531.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 43:  93%|█████████▎| 800/859 [05:19<00:23,  2.50it/s, loss=0.143, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00313, train/loss_step=0.138, global_step=37731.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 43: 100%|██████████| 859/859 [05:39<00:00,  2.53it/s, loss=0.143, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00313, train/loss_step=0.138, global_step=37731.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 43: 100%|██████████| 859/859 [05:39<00:00,  2.53it/s, loss=0.144, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00468, train/loss_step=0.149, global_step=37790.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 43:   0%|          | 0/859 [00:00<00:00, 26886.56it/s, loss=0.144, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00468, train/loss_step=0.149, global_step=37790.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 44:   0%|          | 0/859 [00:00<00:00, 3775.25it/s, loss=0.144, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00468, train/loss_step=0.149, global_step=37790.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142] 
Epoch 44:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.144, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00468, train/loss_step=0.149, global_step=37790.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 44:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.147, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.0016, train/loss_step=0.143, global_step=3.8e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]   pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 44:  47%|████▋     | 400/859 [02:41<03:04,  2.49it/s, loss=0.147, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.0016, train/loss_step=0.143, global_step=3.8e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 44:  47%|████▋     | 400/859 [02:41<03:04,  2.49it/s, loss=0.141, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.0036, train/loss_step=0.131, global_step=38190.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 44:  70%|██████▉   | 600/859 [03:47<01:38,  2.64it/s, loss=0.141, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.0036, train/loss_step=0.131, global_step=38190.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 44:  70%|██████▉   | 600/859 [03:47<01:38,  2.64it/s, loss=0.141, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00214, train/loss_step=0.140, global_step=38390.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 44:  93%|█████████▎| 800/859 [05:22<00:23,  2.48it/s, loss=0.141, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00214, train/loss_step=0.140, global_step=38390.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 44:  93%|█████████▎| 800/859 [05:22<00:23,  2.48it/s, loss=0.145, v_num=38, loss_step=0.166, train/loss_simple_step=0.166, train/loss_vlb_step=0.00328, train/loss_step=0.166, global_step=38590.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 44: 100%|██████████| 859/859 [05:42<00:00,  2.51it/s, loss=0.145, v_num=38, loss_step=0.166, train/loss_simple_step=0.166, train/loss_vlb_step=0.00328, train/loss_step=0.166, global_step=38590.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 44: 100%|██████████| 859/859 [05:42<00:00,  2.51it/s, loss=0.144, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00357, train/loss_step=0.141, global_step=38649.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 44:   0%|          | 0/859 [00:00<00:00, 25420.02it/s, loss=0.144, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00357, train/loss_step=0.141, global_step=38649.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 45:   0%|          | 0/859 [00:00<00:00, 5159.05it/s, loss=0.144, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00357, train/loss_step=0.141, global_step=38649.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142] 
Epoch 45:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.144, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00357, train/loss_step=0.141, global_step=38649.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 45:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.14, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00252, train/loss_step=0.139, global_step=38849.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 45:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.14, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00252, train/loss_step=0.139, global_step=38849.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]
Epoch 45:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.143, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00301, train/loss_step=0.132, global_step=3.9e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]
Epoch 45:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.143, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00301, train/loss_step=0.132, global_step=3.9e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]
Epoch 45:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.14, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00315, train/loss_step=0.148, global_step=39249.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]
Epoch 45:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.14, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00315, train/loss_step=0.148, global_step=39249.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]
Epoch 45:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.144, v_num=38, loss_step=0.163, train/loss_simple_step=0.163, train/loss_vlb_step=0.00193, train/loss_step=0.163, global_step=39449.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 45: 100%|██████████| 859/859 [05:42<00:00,  2.51it/s, loss=0.144, v_num=38, loss_step=0.163, train/loss_simple_step=0.163, train/loss_vlb_step=0.00193, train/loss_step=0.163, global_step=39449.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]
Epoch 45: 100%|██████████| 859/859 [05:42<00:00,  2.51it/s, loss=0.141, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00421, train/loss_step=0.145, global_step=39508.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]
Epoch 45:   0%|          | 0/859 [00:00<00:00, 26051.58it/s, loss=0.141, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00421, train/loss_step=0.145, global_step=39508.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]
Epoch 46:   0%|          | 0/859 [00:00<00:00, 2646.25it/s, loss=0.141, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00421, train/loss_step=0.145, global_step=39508.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142] 
Epoch 46:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.141, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00421, train/loss_step=0.145, global_step=39508.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]
Epoch 46:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.143, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00504, train/loss_step=0.151, global_step=39708.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 46:  47%|████▋     | 400/859 [02:12<02:32,  3.02it/s, loss=0.143, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00504, train/loss_step=0.151, global_step=39708.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 46:  47%|████▋     | 400/859 [02:12<02:32,  3.02it/s, loss=0.141, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00497, train/loss_step=0.140, global_step=39908.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 46:  70%|██████▉   | 600/859 [03:50<01:39,  2.61it/s, loss=0.141, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00497, train/loss_step=0.140, global_step=39908.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 46:  70%|██████▉   | 600/859 [03:50<01:39,  2.61it/s, loss=0.142, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.0025, train/loss_step=0.141, global_step=40108.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142] 
Epoch 46:  93%|█████████▎| 800/859 [04:56<00:21,  2.70it/s, loss=0.142, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.0025, train/loss_step=0.141, global_step=40108.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 46:  93%|█████████▎| 800/859 [04:56<00:21,  2.70it/s, loss=0.141, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00243, train/loss_step=0.147, global_step=40308.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 46: 100%|██████████| 859/859 [05:16<00:00,  2.72it/s, loss=0.141, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00243, train/loss_step=0.147, global_step=40308.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 46: 100%|██████████| 859/859 [05:16<00:00,  2.72it/s, loss=0.143, v_num=38, loss_step=0.164, train/loss_simple_step=0.164, train/loss_vlb_step=0.00189, train/loss_step=0.164, global_step=40367.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 46:   0%|          | 0/859 [00:00<00:00, 23831.27it/s, loss=0.143, v_num=38, loss_step=0.164, train/loss_simple_step=0.164, train/loss_vlb_step=0.00189, train/loss_step=0.164, global_step=40367.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 47:   0%|          | 0/859 [00:00<00:00, 4194.30it/s, loss=0.143, v_num=38, loss_step=0.164, train/loss_simple_step=0.164, train/loss_vlb_step=0.00189, train/loss_step=0.164, global_step=40367.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 47:  23%|██▎       | 200/859 [01:36<05:16,  2.08it/s, loss=0.143, v_num=38, loss_step=0.164, train/loss_simple_step=0.164, train/loss_vlb_step=0.00189, train/loss_step=0.164, global_step=40367.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 47:  23%|██▎       | 200/859 [01:36<05:16,  2.08it/s, loss=0.14, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00238, train/loss_step=0.147, global_step=40567.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141] 
Epoch 47:  47%|████▋     | 400/859 [02:43<03:06,  2.46it/s, loss=0.14, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00238, train/loss_step=0.147, global_step=40567.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]
Epoch 47:  47%|████▋     | 400/859 [02:43<03:06,  2.46it/s, loss=0.14, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00215, train/loss_step=0.130, global_step=40767.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]
Epoch 47:  70%|██████▉   | 600/859 [03:49<01:39,  2.61it/s, loss=0.14, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00215, train/loss_step=0.130, global_step=40767.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]
Epoch 47:  70%|██████▉   | 600/859 [03:49<01:39,  2.61it/s, loss=0.143, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.00184, train/loss_step=0.153, global_step=4.1e+4, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 47:  93%|█████████▎| 800/859 [05:24<00:23,  2.47it/s, loss=0.143, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.00184, train/loss_step=0.153, global_step=4.1e+4, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]
Epoch 47:  93%|█████████▎| 800/859 [05:24<00:23,  2.47it/s, loss=0.139, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00135, train/loss_step=0.135, global_step=41167.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]
Epoch 47: 100%|██████████| 859/859 [05:43<00:00,  2.50it/s, loss=0.139, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00135, train/loss_step=0.135, global_step=41167.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]
Epoch 47: 100%|██████████| 859/859 [05:43<00:00,  2.50it/s, loss=0.141, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00133, train/loss_step=0.130, global_step=41226.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]
Epoch 47:   0%|          | 0/859 [00:00<00:00, 24818.37it/s, loss=0.141, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00133, train/loss_step=0.130, global_step=41226.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]
Epoch 48:   0%|          | 0/859 [00:00<00:00, 2790.62it/s, loss=0.141, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00133, train/loss_step=0.130, global_step=41226.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141] 
Epoch 48:  23%|██▎       | 200/859 [01:06<03:37,  3.04it/s, loss=0.141, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00133, train/loss_step=0.130, global_step=41226.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]
Epoch 48:  23%|██▎       | 200/859 [01:06<03:37,  3.04it/s, loss=0.142, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00197, train/loss_step=0.139, global_step=41426.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 48:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.142, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00197, train/loss_step=0.139, global_step=41426.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 48:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.143, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00293, train/loss_step=0.148, global_step=41626.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 48:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.143, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00293, train/loss_step=0.148, global_step=41626.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 48:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.144, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00388, train/loss_step=0.145, global_step=41826.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 48:  93%|█████████▎| 800/859 [05:20<00:23,  2.50it/s, loss=0.144, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00388, train/loss_step=0.145, global_step=41826.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 48:  93%|█████████▎| 800/859 [05:20<00:23,  2.50it/s, loss=0.142, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00408, train/loss_step=0.152, global_step=4.2e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142] 
Epoch 48: 100%|██████████| 859/859 [05:40<00:00,  2.53it/s, loss=0.142, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00408, train/loss_step=0.152, global_step=4.2e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 48: 100%|██████████| 859/859 [05:40<00:00,  2.53it/s, loss=0.141, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00208, train/loss_step=0.144, global_step=42085.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 48:   0%|          | 0/859 [00:00<00:00, 24966.10it/s, loss=0.141, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00208, train/loss_step=0.144, global_step=42085.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 49:   0%|          | 0/859 [00:00<00:00, 3026.19it/s, loss=0.141, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00208, train/loss_step=0.144, global_step=42085.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142] 
Epoch 49:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.141, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00208, train/loss_step=0.144, global_step=42085.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 49:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.144, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00208, train/loss_step=0.140, global_step=42285.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142] 
Epoch 49:  47%|████▋     | 400/859 [02:12<02:31,  3.02it/s, loss=0.144, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00208, train/loss_step=0.140, global_step=42285.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 49:  47%|████▋     | 400/859 [02:12<02:31,  3.02it/s, loss=0.142, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00275, train/loss_step=0.137, global_step=42485.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 49:  70%|██████▉   | 600/859 [03:46<01:37,  2.66it/s, loss=0.142, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00275, train/loss_step=0.137, global_step=42485.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 49:  70%|██████▉   | 600/859 [03:46<01:37,  2.66it/s, loss=0.141, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00196, train/loss_step=0.147, global_step=42685.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 49:  93%|█████████▎| 800/859 [04:52<00:21,  2.74it/s, loss=0.141, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00196, train/loss_step=0.147, global_step=42685.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 49:  93%|█████████▎| 800/859 [04:52<00:21,  2.74it/s, loss=0.14, v_num=38, loss_step=0.125, train/loss_simple_step=0.125, train/loss_vlb_step=0.00196, train/loss_step=0.125, global_step=42885.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142] 
Epoch 49: 100%|██████████| 859/859 [05:12<00:00,  2.76it/s, loss=0.14, v_num=38, loss_step=0.125, train/loss_simple_step=0.125, train/loss_vlb_step=0.00196, train/loss_step=0.125, global_step=42885.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 49: 100%|██████████| 859/859 [05:12<00:00,  2.76it/s, loss=0.137, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00309, train/loss_step=0.137, global_step=42944.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 49:   0%|          | 0/859 [00:00<00:00, 24385.49it/s, loss=0.137, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00309, train/loss_step=0.137, global_step=42944.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 50:   0%|          | 0/859 [00:00<00:00, 3894.43it/s, loss=0.137, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00309, train/loss_step=0.137, global_step=42944.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 50:  23%|██▎       | 200/859 [01:34<05:10,  2.12it/s, loss=0.137, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00309, train/loss_step=0.137, global_step=42944.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 50:  23%|██▎       | 200/859 [01:34<05:10,  2.12it/s, loss=0.139, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00259, train/loss_step=0.130, global_step=43144.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 50:  47%|████▋     | 400/859 [02:40<03:04,  2.49it/s, loss=0.139, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00259, train/loss_step=0.130, global_step=43144.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 50:  47%|████▋     | 400/859 [02:40<03:04,  2.49it/s, loss=0.144, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00236, train/loss_step=0.151, global_step=43344.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 50:  70%|██████▉   | 600/859 [04:15<01:50,  2.35it/s, loss=0.144, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00236, train/loss_step=0.151, global_step=43344.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 50:  70%|██████▉   | 600/859 [04:15<01:50,  2.35it/s, loss=0.14, v_num=38, loss_step=0.157, train/loss_simple_step=0.157, train/loss_vlb_step=0.00323, train/loss_step=0.157, global_step=43544.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142] 
Epoch 50:  93%|█████████▎| 800/859 [05:22<00:23,  2.49it/s, loss=0.14, v_num=38, loss_step=0.157, train/loss_simple_step=0.157, train/loss_vlb_step=0.00323, train/loss_step=0.157, global_step=43544.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 50:  93%|█████████▎| 800/859 [05:22<00:23,  2.49it/s, loss=0.14, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00183, train/loss_step=0.138, global_step=43744.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 50: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.14, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00183, train/loss_step=0.138, global_step=43744.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 50: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.142, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00202, train/loss_step=0.139, global_step=43803.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 50:   0%|          | 0/859 [00:00<00:00, 25890.77it/s, loss=0.142, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00202, train/loss_step=0.139, global_step=43803.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 51:   0%|          | 0/859 [00:00<00:00, 5548.02it/s, loss=0.142, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00202, train/loss_step=0.139, global_step=43803.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 51:  23%|██▎       | 200/859 [01:35<05:12,  2.11it/s, loss=0.142, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00202, train/loss_step=0.139, global_step=43803.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 51:  23%|██▎       | 200/859 [01:35<05:12,  2.11it/s, loss=0.143, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00261, train/loss_step=0.148, global_step=4.4e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142] 
Epoch 51:  47%|████▋     | 400/859 [02:41<03:04,  2.48it/s, loss=0.143, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00261, train/loss_step=0.148, global_step=4.4e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 51:  47%|████▋     | 400/859 [02:41<03:04,  2.48it/s, loss=0.142, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00315, train/loss_step=0.147, global_step=44203.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 51:  70%|██████▉   | 600/859 [03:47<01:38,  2.64it/s, loss=0.142, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00315, train/loss_step=0.147, global_step=44203.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 51:  70%|██████▉   | 600/859 [03:47<01:38,  2.64it/s, loss=0.142, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00332, train/loss_step=0.143, global_step=44403.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 51:  93%|█████████▎| 800/859 [05:22<00:23,  2.49it/s, loss=0.142, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00332, train/loss_step=0.143, global_step=44403.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 51:  93%|█████████▎| 800/859 [05:22<00:23,  2.49it/s, loss=0.148, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00268, train/loss_step=0.152, global_step=44603.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 51: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.148, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00268, train/loss_step=0.152, global_step=44603.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 51: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.145, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00176, train/loss_step=0.152, global_step=44662.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 51:   0%|          | 0/859 [00:00<00:00, 26886.56it/s, loss=0.145, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00176, train/loss_step=0.152, global_step=44662.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 52:   0%|          | 0/859 [00:00<00:00, 2781.37it/s, loss=0.145, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00176, train/loss_step=0.152, global_step=44662.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142] 
Epoch 52:  23%|██▎       | 200/859 [01:06<03:38,  3.02it/s, loss=0.145, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00176, train/loss_step=0.152, global_step=44662.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 52:  23%|██▎       | 200/859 [01:06<03:38,  3.02it/s, loss=0.142, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00251, train/loss_step=0.140, global_step=44862.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 52:  47%|████▋     | 400/859 [02:41<03:04,  2.49it/s, loss=0.142, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00251, train/loss_step=0.140, global_step=44862.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 52:  47%|████▋     | 400/859 [02:41<03:04,  2.49it/s, loss=0.142, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00386, train/loss_step=0.144, global_step=45062.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 52:  70%|██████▉   | 600/859 [03:47<01:37,  2.65it/s, loss=0.142, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00386, train/loss_step=0.144, global_step=45062.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 52:  70%|██████▉   | 600/859 [03:47<01:37,  2.65it/s, loss=0.14, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00122, train/loss_step=0.134, global_step=45262.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142] 
Epoch 52:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.14, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00122, train/loss_step=0.134, global_step=45262.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 52:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.14, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00142, train/loss_step=0.132, global_step=45462.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 52: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.14, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00142, train/loss_step=0.132, global_step=45462.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 52: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.143, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00314, train/loss_step=0.145, global_step=45521.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 52:   0%|          | 0/859 [00:00<00:00, 25731.93it/s, loss=0.143, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00314, train/loss_step=0.145, global_step=45521.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 53:   0%|          | 0/859 [00:00<00:00, 3572.66it/s, loss=0.143, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00314, train/loss_step=0.145, global_step=45521.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142] 
Epoch 53:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.143, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00314, train/loss_step=0.145, global_step=45521.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 53:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.138, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00209, train/loss_step=0.147, global_step=45721.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 53:  47%|████▋     | 400/859 [02:12<02:32,  3.02it/s, loss=0.138, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00209, train/loss_step=0.147, global_step=45721.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 53:  47%|████▋     | 400/859 [02:12<02:32,  3.02it/s, loss=0.144, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00292, train/loss_step=0.133, global_step=45921.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 53:  70%|██████▉   | 600/859 [03:47<01:37,  2.65it/s, loss=0.144, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00292, train/loss_step=0.133, global_step=45921.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 53:  70%|██████▉   | 600/859 [03:47<01:37,  2.65it/s, loss=0.14, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00218, train/loss_step=0.141, global_step=46121.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141] 
Epoch 53:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.14, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00218, train/loss_step=0.141, global_step=46121.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 53:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.141, v_num=38, loss_step=0.161, train/loss_simple_step=0.161, train/loss_vlb_step=0.00529, train/loss_step=0.161, global_step=46321.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 53: 100%|██████████| 859/859 [05:12<00:00,  2.75it/s, loss=0.141, v_num=38, loss_step=0.161, train/loss_simple_step=0.161, train/loss_vlb_step=0.00529, train/loss_step=0.161, global_step=46321.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 53: 100%|██████████| 859/859 [05:12<00:00,  2.75it/s, loss=0.141, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00292, train/loss_step=0.145, global_step=46380.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 53:   0%|          | 0/859 [00:00<00:00, 25115.59it/s, loss=0.141, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00292, train/loss_step=0.145, global_step=46380.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 54:   0%|          | 0/859 [00:00<00:00, 4723.32it/s, loss=0.141, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00292, train/loss_step=0.145, global_step=46380.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 54:  23%|██▎       | 200/859 [01:34<05:09,  2.13it/s, loss=0.141, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00292, train/loss_step=0.145, global_step=46380.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 54:  23%|██▎       | 200/859 [01:34<05:09,  2.13it/s, loss=0.143, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00207, train/loss_step=0.139, global_step=46580.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142] 
Epoch 54:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.143, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00207, train/loss_step=0.139, global_step=46580.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 54:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.138, v_num=38, loss_step=0.116, train/loss_simple_step=0.116, train/loss_vlb_step=0.00273, train/loss_step=0.116, global_step=46780.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 54:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.138, v_num=38, loss_step=0.116, train/loss_simple_step=0.116, train/loss_vlb_step=0.00273, train/loss_step=0.116, global_step=46780.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 54:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.143, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.0016, train/loss_step=0.134, global_step=4.7e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]  pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 54:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.143, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.0016, train/loss_step=0.134, global_step=4.7e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 54:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.142, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00171, train/loss_step=0.130, global_step=47180.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 54: 100%|██████████| 859/859 [05:40<00:00,  2.52it/s, loss=0.142, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00171, train/loss_step=0.130, global_step=47180.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 54: 100%|██████████| 859/859 [05:40<00:00,  2.52it/s, loss=0.142, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.000974, train/loss_step=0.132, global_step=47239.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 54:   0%|          | 0/859 [00:00<00:00, 25890.77it/s, loss=0.142, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.000974, train/loss_step=0.132, global_step=47239.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 55:   0%|          | 0/859 [00:00<00:00, 2727.12it/s, loss=0.142, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.000974, train/loss_step=0.132, global_step=47239.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142] 
Epoch 55:  23%|██▎       | 200/859 [01:06<03:37,  3.02it/s, loss=0.142, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.000974, train/loss_step=0.132, global_step=47239.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 55:  23%|██▎       | 200/859 [01:06<03:37,  3.02it/s, loss=0.143, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00249, train/loss_step=0.143, global_step=47439.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 55:  47%|████▋     | 400/859 [02:40<03:04,  2.49it/s, loss=0.143, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00249, train/loss_step=0.143, global_step=47439.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 55:  47%|████▋     | 400/859 [02:40<03:04,  2.49it/s, loss=0.142, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00265, train/loss_step=0.138, global_step=47639.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 55:  70%|██████▉   | 600/859 [03:47<01:38,  2.64it/s, loss=0.142, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00265, train/loss_step=0.138, global_step=47639.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 55:  70%|██████▉   | 600/859 [03:47<01:38,  2.64it/s, loss=0.139, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.0022, train/loss_step=0.139, global_step=47839.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 55:  93%|█████████▎| 800/859 [05:22<00:23,  2.49it/s, loss=0.139, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.0022, train/loss_step=0.139, global_step=47839.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 55:  93%|█████████▎| 800/859 [05:22<00:23,  2.49it/s, loss=0.14, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00127, train/loss_step=0.145, global_step=4.8e+4, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141] 
Epoch 55: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.14, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00127, train/loss_step=0.145, global_step=4.8e+4, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 55: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.145, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00106, train/loss_step=0.134, global_step=48098.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 55:   0%|          | 0/859 [00:00<00:00, 26051.58it/s, loss=0.145, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00106, train/loss_step=0.134, global_step=48098.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 56:   0%|          | 0/859 [00:00<00:00, 3551.49it/s, loss=0.145, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00106, train/loss_step=0.134, global_step=48098.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141] 
Epoch 56:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.145, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00106, train/loss_step=0.134, global_step=48098.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 56:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.143, v_num=38, loss_step=0.124, train/loss_simple_step=0.124, train/loss_vlb_step=0.00126, train/loss_step=0.124, global_step=48298.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 56:  47%|████▋     | 400/859 [02:12<02:31,  3.02it/s, loss=0.143, v_num=38, loss_step=0.124, train/loss_simple_step=0.124, train/loss_vlb_step=0.00126, train/loss_step=0.124, global_step=48298.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 56:  47%|████▋     | 400/859 [02:12<02:31,  3.02it/s, loss=0.142, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00248, train/loss_step=0.144, global_step=48498.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 56:  70%|██████▉   | 600/859 [03:48<01:38,  2.64it/s, loss=0.142, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00248, train/loss_step=0.144, global_step=48498.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 56:  70%|██████▉   | 600/859 [03:48<01:38,  2.64it/s, loss=0.139, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00288, train/loss_step=0.132, global_step=48698.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 56:  93%|█████████▎| 800/859 [04:54<00:21,  2.72it/s, loss=0.139, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00288, train/loss_step=0.132, global_step=48698.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 56:  93%|█████████▎| 800/859 [04:54<00:21,  2.72it/s, loss=0.143, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00339, train/loss_step=0.131, global_step=48898.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 56: 100%|██████████| 859/859 [05:13<00:00,  2.74it/s, loss=0.143, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00339, train/loss_step=0.131, global_step=48898.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 56: 100%|██████████| 859/859 [05:13<00:00,  2.74it/s, loss=0.142, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00371, train/loss_step=0.144, global_step=4.9e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142] 
Epoch 56:   0%|          | 0/859 [00:00<00:00, 24244.53it/s, loss=0.142, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00371, train/loss_step=0.144, global_step=4.9e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 57:   0%|          | 0/859 [00:00<00:00, 2172.09it/s, loss=0.142, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00371, train/loss_step=0.144, global_step=4.9e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 57:  23%|██▎       | 200/859 [01:34<05:09,  2.13it/s, loss=0.142, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00371, train/loss_step=0.144, global_step=4.9e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 57:  23%|██▎       | 200/859 [01:34<05:09,  2.13it/s, loss=0.143, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00293, train/loss_step=0.140, global_step=49157.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 57:  47%|████▋     | 400/859 [02:40<03:04,  2.49it/s, loss=0.143, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00293, train/loss_step=0.140, global_step=49157.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 57:  47%|████▋     | 400/859 [02:40<03:04,  2.49it/s, loss=0.143, v_num=38, loss_step=0.158, train/loss_simple_step=0.158, train/loss_vlb_step=0.0018, train/loss_step=0.158, global_step=49357.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 57:  70%|██████▉   | 600/859 [04:15<01:50,  2.35it/s, loss=0.143, v_num=38, loss_step=0.158, train/loss_simple_step=0.158, train/loss_vlb_step=0.0018, train/loss_step=0.158, global_step=49357.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 57:  70%|██████▉   | 600/859 [04:15<01:50,  2.35it/s, loss=0.142, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.00182, train/loss_step=0.153, global_step=49557.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 57:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.142, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.00182, train/loss_step=0.153, global_step=49557.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 57:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.145, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00472, train/loss_step=0.148, global_step=49757.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 57: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.145, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00472, train/loss_step=0.148, global_step=49757.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 57: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.141, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00361, train/loss_step=0.141, global_step=49816.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 57:   0%|          | 0/859 [00:00<00:00, 25731.93it/s, loss=0.141, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00361, train/loss_step=0.141, global_step=49816.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 58:   0%|          | 0/859 [00:00<00:00, 4116.10it/s, loss=0.141, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00361, train/loss_step=0.141, global_step=49816.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 58:  23%|██▎       | 200/859 [01:34<05:10,  2.12it/s, loss=0.141, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00361, train/loss_step=0.141, global_step=49816.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 58:  23%|██▎       | 200/859 [01:34<05:10,  2.12it/s, loss=0.141, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.001, train/loss_step=0.136, global_step=5e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]      
Epoch 58:  47%|████▋     | 400/859 [02:40<03:04,  2.49it/s, loss=0.141, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.001, train/loss_step=0.136, global_step=5e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 58:  47%|████▋     | 400/859 [02:40<03:04,  2.49it/s, loss=0.143, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00438, train/loss_step=0.145, global_step=50216.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 58:  70%|██████▉   | 600/859 [03:47<01:37,  2.64it/s, loss=0.143, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00438, train/loss_step=0.145, global_step=50216.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 58:  70%|██████▉   | 600/859 [03:47<01:37,  2.64it/s, loss=0.141, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00185, train/loss_step=0.132, global_step=50416.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 58:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.141, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00185, train/loss_step=0.132, global_step=50416.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 58:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.146, v_num=38, loss_step=0.179, train/loss_simple_step=0.179, train/loss_vlb_step=0.0025, train/loss_step=0.179, global_step=50616.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142] 
Epoch 58: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.146, v_num=38, loss_step=0.179, train/loss_simple_step=0.179, train/loss_vlb_step=0.0025, train/loss_step=0.179, global_step=50616.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 58: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.138, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00164, train/loss_step=0.146, global_step=50675.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 58:   0%|          | 0/859 [00:00<00:00, 25731.93it/s, loss=0.138, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00164, train/loss_step=0.146, global_step=50675.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 59:   0%|          | 0/859 [00:00<00:00, 4843.31it/s, loss=0.138, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00164, train/loss_step=0.146, global_step=50675.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142] 
Epoch 59:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.138, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00164, train/loss_step=0.146, global_step=50675.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 59:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.146, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.0017, train/loss_step=0.145, global_step=50875.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 59:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.146, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.0017, train/loss_step=0.145, global_step=50875.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 59:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.143, v_num=38, loss_step=0.127, train/loss_simple_step=0.127, train/loss_vlb_step=0.00116, train/loss_step=0.127, global_step=51075.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 59:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.143, v_num=38, loss_step=0.127, train/loss_simple_step=0.127, train/loss_vlb_step=0.00116, train/loss_step=0.127, global_step=51075.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 59:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.142, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.00222, train/loss_step=0.153, global_step=51275.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 59:  93%|█████████▎| 800/859 [04:52<00:21,  2.74it/s, loss=0.142, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.00222, train/loss_step=0.153, global_step=51275.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 59:  93%|█████████▎| 800/859 [04:52<00:21,  2.74it/s, loss=0.138, v_num=38, loss_step=0.127, train/loss_simple_step=0.127, train/loss_vlb_step=0.00235, train/loss_step=0.127, global_step=51475.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 59: 100%|██████████| 859/859 [05:40<00:00,  2.53it/s, loss=0.138, v_num=38, loss_step=0.127, train/loss_simple_step=0.127, train/loss_vlb_step=0.00235, train/loss_step=0.127, global_step=51475.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 59: 100%|██████████| 859/859 [05:40<00:00,  2.53it/s, loss=0.143, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00302, train/loss_step=0.143, global_step=51534.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 59:   0%|          | 0/859 [00:00<00:00, 26051.58it/s, loss=0.143, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00302, train/loss_step=0.143, global_step=51534.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 60:   0%|          | 0/859 [00:00<00:00, 4140.48it/s, loss=0.143, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00302, train/loss_step=0.143, global_step=51534.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142] 
Epoch 60:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.143, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00302, train/loss_step=0.143, global_step=51534.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 60:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.145, v_num=38, loss_step=0.125, train/loss_simple_step=0.125, train/loss_vlb_step=0.00116, train/loss_step=0.125, global_step=51734.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141] 
Epoch 60:  47%|████▋     | 400/859 [02:12<02:31,  3.02it/s, loss=0.145, v_num=38, loss_step=0.125, train/loss_simple_step=0.125, train/loss_vlb_step=0.00116, train/loss_step=0.125, global_step=51734.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 60:  47%|████▋     | 400/859 [02:12<02:31,  3.02it/s, loss=0.138, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.0022, train/loss_step=0.134, global_step=51934.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 60:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.138, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.0022, train/loss_step=0.134, global_step=51934.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 60:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.139, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00234, train/loss_step=0.137, global_step=52134.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 60:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.139, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00234, train/loss_step=0.137, global_step=52134.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 60:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.142, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.0022, train/loss_step=0.139, global_step=52334.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141] 
Epoch 60: 100%|██████████| 859/859 [05:12<00:00,  2.75it/s, loss=0.142, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.0022, train/loss_step=0.139, global_step=52334.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 60: 100%|██████████| 859/859 [05:12<00:00,  2.75it/s, loss=0.144, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00293, train/loss_step=0.145, global_step=52393.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 60:   0%|          | 0/859 [00:00<00:00, 26214.40it/s, loss=0.144, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00293, train/loss_step=0.145, global_step=52393.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 61:   0%|          | 0/859 [00:00<00:00, 3387.97it/s, loss=0.144, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00293, train/loss_step=0.145, global_step=52393.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 61:  23%|██▎       | 200/859 [01:34<05:09,  2.13it/s, loss=0.144, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00293, train/loss_step=0.145, global_step=52393.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 61:  23%|██▎       | 200/859 [01:34<05:09,  2.13it/s, loss=0.14, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00331, train/loss_step=0.134, global_step=52593.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00261, train/loss_epoch=0.142]
Epoch 61:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.14, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00331, train/loss_step=0.134, global_step=52593.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00261, train/loss_epoch=0.142]
Epoch 61:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.142, v_num=38, loss_step=0.126, train/loss_simple_step=0.126, train/loss_vlb_step=0.00202, train/loss_step=0.126, global_step=52793.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00261, train/loss_epoch=0.142]
Epoch 61:  70%|██████▉   | 600/859 [03:47<01:37,  2.65it/s, loss=0.142, v_num=38, loss_step=0.126, train/loss_simple_step=0.126, train/loss_vlb_step=0.00202, train/loss_step=0.126, global_step=52793.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00261, train/loss_epoch=0.142]
Epoch 61:  70%|██████▉   | 600/859 [03:47<01:37,  2.65it/s, loss=0.14, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00113, train/loss_step=0.130, global_step=5.3e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00261, train/loss_epoch=0.142]  pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 61:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.14, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00113, train/loss_step=0.130, global_step=5.3e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00261, train/loss_epoch=0.142]
Epoch 61:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.141, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00224, train/loss_step=0.131, global_step=53193.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00261, train/loss_epoch=0.142]
Epoch 61: 100%|██████████| 859/859 [05:40<00:00,  2.52it/s, loss=0.141, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00224, train/loss_step=0.131, global_step=53193.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00261, train/loss_epoch=0.142]
Epoch 61: 100%|██████████| 859/859 [05:40<00:00,  2.52it/s, loss=0.14, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00301, train/loss_step=0.141, global_step=53252.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00261, train/loss_epoch=0.142] 
Epoch 61:   0%|          | 0/859 [00:00<00:00, 26715.31it/s, loss=0.14, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00301, train/loss_step=0.141, global_step=53252.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00261, train/loss_epoch=0.142]
Epoch 62:   0%|          | 0/859 [00:00<00:00, 3672.77it/s, loss=0.14, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00301, train/loss_step=0.141, global_step=53252.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00261, train/loss_epoch=0.142] 
Epoch 62:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.14, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00301, train/loss_step=0.141, global_step=53252.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00261, train/loss_epoch=0.142]
Epoch 62:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.144, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00178, train/loss_step=0.137, global_step=53452.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 62:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.144, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00178, train/loss_step=0.137, global_step=53452.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 62:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.143, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00312, train/loss_step=0.141, global_step=53652.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 62:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.143, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00312, train/loss_step=0.141, global_step=53652.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 62:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.143, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00237, train/loss_step=0.144, global_step=53852.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 62:  93%|█████████▎| 800/859 [05:20<00:23,  2.50it/s, loss=0.143, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00237, train/loss_step=0.144, global_step=53852.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 62:  93%|█████████▎| 800/859 [05:20<00:23,  2.50it/s, loss=0.143, v_num=38, loss_step=0.165, train/loss_simple_step=0.165, train/loss_vlb_step=0.00186, train/loss_step=0.165, global_step=54052.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 62: 100%|██████████| 859/859 [05:40<00:00,  2.53it/s, loss=0.143, v_num=38, loss_step=0.165, train/loss_simple_step=0.165, train/loss_vlb_step=0.00186, train/loss_step=0.165, global_step=54052.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 62: 100%|██████████| 859/859 [05:40<00:00,  2.53it/s, loss=0.14, v_num=38, loss_step=0.129, train/loss_simple_step=0.129, train/loss_vlb_step=0.00211, train/loss_step=0.129, global_step=54111.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142] 
Epoch 62:   0%|          | 0/859 [00:00<00:00, 25731.93it/s, loss=0.14, v_num=38, loss_step=0.129, train/loss_simple_step=0.129, train/loss_vlb_step=0.00211, train/loss_step=0.129, global_step=54111.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 63:   0%|          | 0/859 [00:00<00:00, 3163.13it/s, loss=0.14, v_num=38, loss_step=0.129, train/loss_simple_step=0.129, train/loss_vlb_step=0.00211, train/loss_step=0.129, global_step=54111.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142] 
Epoch 63:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.14, v_num=38, loss_step=0.129, train/loss_simple_step=0.129, train/loss_vlb_step=0.00211, train/loss_step=0.129, global_step=54111.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 63:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.143, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00149, train/loss_step=0.135, global_step=54311.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 63:  47%|████▋     | 400/859 [02:40<03:03,  2.49it/s, loss=0.143, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00149, train/loss_step=0.135, global_step=54311.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 63:  47%|████▋     | 400/859 [02:40<03:03,  2.49it/s, loss=0.138, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00197, train/loss_step=0.137, global_step=54511.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 63:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.138, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00197, train/loss_step=0.137, global_step=54511.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 63:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.145, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00361, train/loss_step=0.148, global_step=54711.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 63:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.145, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00361, train/loss_step=0.148, global_step=54711.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 63:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.14, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00116, train/loss_step=0.132, global_step=54911.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142] 
Epoch 63: 100%|██████████| 859/859 [05:12<00:00,  2.75it/s, loss=0.14, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00116, train/loss_step=0.132, global_step=54911.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 63: 100%|██████████| 859/859 [05:12<00:00,  2.75it/s, loss=0.143, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00309, train/loss_step=0.142, global_step=5.5e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 63:   0%|          | 0/859 [00:00<00:00, 25575.02it/s, loss=0.143, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00309, train/loss_step=0.142, global_step=5.5e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 64:   0%|          | 0/859 [00:00<00:00, 3504.01it/s, loss=0.143, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00309, train/loss_step=0.142, global_step=5.5e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 64:  23%|██▎       | 200/859 [01:33<05:08,  2.14it/s, loss=0.143, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00309, train/loss_step=0.142, global_step=5.5e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 64:  23%|██▎       | 200/859 [01:33<05:08,  2.14it/s, loss=0.142, v_num=38, loss_step=0.160, train/loss_simple_step=0.160, train/loss_vlb_step=0.00247, train/loss_step=0.160, global_step=55170.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 64:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.142, v_num=38, loss_step=0.160, train/loss_simple_step=0.160, train/loss_vlb_step=0.00247, train/loss_step=0.160, global_step=55170.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 64:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.137, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00255, train/loss_step=0.137, global_step=55370.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 64:  70%|██████▉   | 600/859 [04:14<01:49,  2.36it/s, loss=0.137, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00255, train/loss_step=0.137, global_step=55370.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 64:  70%|██████▉   | 600/859 [04:14<01:49,  2.36it/s, loss=0.141, v_num=38, loss_step=0.158, train/loss_simple_step=0.158, train/loss_vlb_step=0.00221, train/loss_step=0.158, global_step=55570.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 64:  93%|█████████▎| 800/859 [05:20<00:23,  2.50it/s, loss=0.141, v_num=38, loss_step=0.158, train/loss_simple_step=0.158, train/loss_vlb_step=0.00221, train/loss_step=0.158, global_step=55570.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 64:  93%|█████████▎| 800/859 [05:20<00:23,  2.50it/s, loss=0.14, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00154, train/loss_step=0.139, global_step=55770.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142] 
Epoch 64: 100%|██████████| 859/859 [05:40<00:00,  2.53it/s, loss=0.14, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00154, train/loss_step=0.139, global_step=55770.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 64: 100%|██████████| 859/859 [05:40<00:00,  2.53it/s, loss=0.141, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00447, train/loss_step=0.143, global_step=55829.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 64:   0%|          | 0/859 [00:00<00:00, 25731.93it/s, loss=0.141, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00447, train/loss_step=0.143, global_step=55829.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 65:   0%|          | 0/859 [00:00<00:00, 4593.98it/s, loss=0.141, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00447, train/loss_step=0.143, global_step=55829.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 65:  23%|██▎       | 200/859 [01:34<05:10,  2.13it/s, loss=0.141, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00447, train/loss_step=0.143, global_step=55829.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 65:  23%|██▎       | 200/859 [01:34<05:10,  2.13it/s, loss=0.138, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00333, train/loss_step=0.142, global_step=5.6e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142] 
Epoch 65:  47%|████▋     | 400/859 [02:40<03:04,  2.49it/s, loss=0.138, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00333, train/loss_step=0.142, global_step=5.6e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 65:  47%|████▋     | 400/859 [02:40<03:04,  2.49it/s, loss=0.145, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00172, train/loss_step=0.143, global_step=56229.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 65:  70%|██████▉   | 600/859 [03:47<01:37,  2.65it/s, loss=0.145, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00172, train/loss_step=0.143, global_step=56229.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 65:  70%|██████▉   | 600/859 [03:47<01:37,  2.65it/s, loss=0.14, v_num=38, loss_step=0.163, train/loss_simple_step=0.163, train/loss_vlb_step=0.00259, train/loss_step=0.163, global_step=56429.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 65:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.14, v_num=38, loss_step=0.163, train/loss_simple_step=0.163, train/loss_vlb_step=0.00259, train/loss_step=0.163, global_step=56429.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 65:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.142, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00225, train/loss_step=0.141, global_step=56629.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 65: 100%|██████████| 859/859 [05:40<00:00,  2.52it/s, loss=0.142, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00225, train/loss_step=0.141, global_step=56629.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 65: 100%|██████████| 859/859 [05:40<00:00,  2.52it/s, loss=0.142, v_num=38, loss_step=0.125, train/loss_simple_step=0.125, train/loss_vlb_step=0.00132, train/loss_step=0.125, global_step=56688.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 65:   0%|          | 0/859 [00:00<00:00, 24818.37it/s, loss=0.142, v_num=38, loss_step=0.125, train/loss_simple_step=0.125, train/loss_vlb_step=0.00132, train/loss_step=0.125, global_step=56688.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 66:   0%|          | 0/859 [00:00<00:00, 4777.11it/s, loss=0.142, v_num=38, loss_step=0.125, train/loss_simple_step=0.125, train/loss_vlb_step=0.00132, train/loss_step=0.125, global_step=56688.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142] 
Epoch 66:  23%|██▎       | 200/859 [01:06<03:38,  3.02it/s, loss=0.142, v_num=38, loss_step=0.125, train/loss_simple_step=0.125, train/loss_vlb_step=0.00132, train/loss_step=0.125, global_step=56688.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 66:  23%|██▎       | 200/859 [01:06<03:38,  3.02it/s, loss=0.144, v_num=38, loss_step=0.161, train/loss_simple_step=0.161, train/loss_vlb_step=0.00205, train/loss_step=0.161, global_step=56888.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 66:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.144, v_num=38, loss_step=0.161, train/loss_simple_step=0.161, train/loss_vlb_step=0.00205, train/loss_step=0.161, global_step=56888.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 66:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.141, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.002, train/loss_step=0.132, global_step=57088.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]  
Epoch 66:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.141, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.002, train/loss_step=0.132, global_step=57088.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 66:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.142, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00344, train/loss_step=0.139, global_step=57288.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 66:  93%|█████████▎| 800/859 [04:52<00:21,  2.74it/s, loss=0.142, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00344, train/loss_step=0.139, global_step=57288.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 66:  93%|█████████▎| 800/859 [04:52<00:21,  2.74it/s, loss=0.142, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00131, train/loss_step=0.142, global_step=57488.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 66: 100%|██████████| 859/859 [05:39<00:00,  2.54it/s, loss=0.142, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00131, train/loss_step=0.142, global_step=57488.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 66: 100%|██████████| 859/859 [05:39<00:00,  2.54it/s, loss=0.143, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00291, train/loss_step=0.136, global_step=57547.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 66:   0%|          | 0/859 [00:00<00:00, 24528.09it/s, loss=0.143, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00291, train/loss_step=0.136, global_step=57547.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 67:   0%|          | 0/859 [00:00<00:00, 4088.02it/s, loss=0.143, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00291, train/loss_step=0.136, global_step=57547.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142] 
Epoch 67:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.143, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00291, train/loss_step=0.136, global_step=57547.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 67:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.138, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00241, train/loss_step=0.132, global_step=57747.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]
Epoch 67:  47%|████▋     | 400/859 [02:12<02:32,  3.02it/s, loss=0.138, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00241, train/loss_step=0.132, global_step=57747.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]
Epoch 67:  47%|████▋     | 400/859 [02:12<02:32,  3.02it/s, loss=0.144, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00304, train/loss_step=0.144, global_step=57947.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 67:  70%|██████▉   | 600/859 [03:47<01:37,  2.64it/s, loss=0.144, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00304, train/loss_step=0.144, global_step=57947.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]
Epoch 67:  70%|██████▉   | 600/859 [03:47<01:37,  2.64it/s, loss=0.142, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00154, train/loss_step=0.142, global_step=58147.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]
Epoch 67:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.142, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00154, train/loss_step=0.142, global_step=58147.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]
Epoch 67:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.141, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00324, train/loss_step=0.145, global_step=58347.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]
Epoch 67: 100%|██████████| 859/859 [05:12<00:00,  2.75it/s, loss=0.141, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00324, train/loss_step=0.145, global_step=58347.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]
Epoch 67: 100%|██████████| 859/859 [05:12<00:00,  2.75it/s, loss=0.143, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00107, train/loss_step=0.135, global_step=58406.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]
Epoch 67:   0%|          | 0/859 [00:00<00:00, 25115.59it/s, loss=0.143, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00107, train/loss_step=0.135, global_step=58406.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]
Epoch 68:   0%|          | 0/859 [00:00<00:00, 2621.44it/s, loss=0.143, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00107, train/loss_step=0.135, global_step=58406.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 68:  23%|██▎       | 200/859 [01:34<05:09,  2.13it/s, loss=0.143, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00107, train/loss_step=0.135, global_step=58406.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]
Epoch 68:  23%|██▎       | 200/859 [01:34<05:09,  2.13it/s, loss=0.141, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00196, train/loss_step=0.141, global_step=58606.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 68:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.141, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00196, train/loss_step=0.141, global_step=58606.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 68:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.14, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00243, train/loss_step=0.131, global_step=58806.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 68:  70%|██████▉   | 600/859 [04:15<01:49,  2.36it/s, loss=0.14, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00243, train/loss_step=0.131, global_step=58806.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 68:  70%|██████▉   | 600/859 [04:15<01:49,  2.36it/s, loss=0.141, v_num=38, loss_step=0.161, train/loss_simple_step=0.161, train/loss_vlb_step=0.00258, train/loss_step=0.161, global_step=5.9e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 68:  93%|█████████▎| 800/859 [05:20<00:23,  2.50it/s, loss=0.141, v_num=38, loss_step=0.161, train/loss_simple_step=0.161, train/loss_vlb_step=0.00258, train/loss_step=0.161, global_step=5.9e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 68:  93%|█████████▎| 800/859 [05:20<00:23,  2.50it/s, loss=0.142, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00281, train/loss_step=0.138, global_step=59206.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 68: 100%|██████████| 859/859 [05:40<00:00,  2.53it/s, loss=0.142, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00281, train/loss_step=0.138, global_step=59206.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 68: 100%|██████████| 859/859 [05:40<00:00,  2.53it/s, loss=0.142, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00121, train/loss_step=0.137, global_step=59265.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 68:   0%|          | 0/859 [00:00<00:00, 27060.03it/s, loss=0.142, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00121, train/loss_step=0.137, global_step=59265.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 69:   0%|          | 0/859 [00:00<00:00, 3199.32it/s, loss=0.142, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00121, train/loss_step=0.137, global_step=59265.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142] 
Epoch 69:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.142, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00121, train/loss_step=0.137, global_step=59265.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 69:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.14, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00346, train/loss_step=0.142, global_step=59465.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 69:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.14, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00346, train/loss_step=0.142, global_step=59465.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 69:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.144, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00138, train/loss_step=0.140, global_step=59665.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 69:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.144, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00138, train/loss_step=0.140, global_step=59665.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 69:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.141, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00282, train/loss_step=0.148, global_step=59865.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 69:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.141, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00282, train/loss_step=0.148, global_step=59865.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 69:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.139, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00112, train/loss_step=0.131, global_step=60065.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 69: 100%|██████████| 859/859 [05:40<00:00,  2.52it/s, loss=0.139, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00112, train/loss_step=0.131, global_step=60065.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 69: 100%|██████████| 859/859 [05:40<00:00,  2.52it/s, loss=0.141, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00298, train/loss_step=0.136, global_step=60124.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 69:   0%|          | 0/859 [00:00<00:00, 26214.40it/s, loss=0.141, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00298, train/loss_step=0.136, global_step=60124.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 70:   0%|          | 0/859 [00:00<00:00, 4021.38it/s, loss=0.141, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00298, train/loss_step=0.136, global_step=60124.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142] 
Epoch 70:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.141, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00298, train/loss_step=0.136, global_step=60124.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 70:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.14, v_num=38, loss_step=0.127, train/loss_simple_step=0.127, train/loss_vlb_step=0.00191, train/loss_step=0.127, global_step=60324.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00244, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 70:  47%|████▋     | 400/859 [02:41<03:04,  2.49it/s, loss=0.14, v_num=38, loss_step=0.127, train/loss_simple_step=0.127, train/loss_vlb_step=0.00191, train/loss_step=0.127, global_step=60324.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00244, train/loss_epoch=0.142]
Epoch 70:  47%|████▋     | 400/859 [02:41<03:04,  2.49it/s, loss=0.142, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00247, train/loss_step=0.139, global_step=60524.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00244, train/loss_epoch=0.142]
Epoch 70:  70%|██████▉   | 600/859 [03:47<01:37,  2.64it/s, loss=0.142, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00247, train/loss_step=0.139, global_step=60524.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00244, train/loss_epoch=0.142]
Epoch 70:  70%|██████▉   | 600/859 [03:47<01:37,  2.64it/s, loss=0.143, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00193, train/loss_step=0.133, global_step=60724.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00244, train/loss_epoch=0.142]
Epoch 70:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.143, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00193, train/loss_step=0.133, global_step=60724.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00244, train/loss_epoch=0.142]
Epoch 70:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.143, v_num=38, loss_step=0.127, train/loss_simple_step=0.127, train/loss_vlb_step=0.00225, train/loss_step=0.127, global_step=60924.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00244, train/loss_epoch=0.142]
Epoch 70: 100%|██████████| 859/859 [05:13<00:00,  2.75it/s, loss=0.143, v_num=38, loss_step=0.127, train/loss_simple_step=0.127, train/loss_vlb_step=0.00225, train/loss_step=0.127, global_step=60924.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00244, train/loss_epoch=0.142]
Epoch 70: 100%|██████████| 859/859 [05:13<00:00,  2.75it/s, loss=0.142, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00256, train/loss_step=0.135, global_step=6.1e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00244, train/loss_epoch=0.142] 
Epoch 70:   0%|          | 0/859 [00:00<00:00, 26886.56it/s, loss=0.142, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00256, train/loss_step=0.135, global_step=6.1e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00244, train/loss_epoch=0.142]
Epoch 71:   0%|          | 0/859 [00:00<00:00, 2452.81it/s, loss=0.142, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00256, train/loss_step=0.135, global_step=6.1e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00244, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 71:  23%|██▎       | 200/859 [01:32<05:03,  2.17it/s, loss=0.142, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00256, train/loss_step=0.135, global_step=6.1e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00244, train/loss_epoch=0.142]
Epoch 71:  23%|██▎       | 200/859 [01:32<05:03,  2.17it/s, loss=0.142, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00247, train/loss_step=0.133, global_step=61183.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 71:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.142, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00247, train/loss_step=0.133, global_step=61183.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 71:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.141, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00147, train/loss_step=0.139, global_step=61383.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 71:  70%|██████▉   | 600/859 [04:11<01:48,  2.39it/s, loss=0.141, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00147, train/loss_step=0.139, global_step=61383.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 71:  70%|██████▉   | 600/859 [04:11<01:48,  2.39it/s, loss=0.139, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00246, train/loss_step=0.142, global_step=61583.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 71:  93%|█████████▎| 800/859 [05:16<00:23,  2.53it/s, loss=0.139, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00246, train/loss_step=0.142, global_step=61583.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 71:  93%|█████████▎| 800/859 [05:16<00:23,  2.53it/s, loss=0.145, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00234, train/loss_step=0.134, global_step=61783.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 71: 100%|██████████| 859/859 [05:36<00:00,  2.56it/s, loss=0.145, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00234, train/loss_step=0.134, global_step=61783.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 71: 100%|██████████| 859/859 [05:36<00:00,  2.56it/s, loss=0.141, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00312, train/loss_step=0.135, global_step=61842.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 71:   0%|          | 0/859 [00:00<00:00, 27060.03it/s, loss=0.141, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00312, train/loss_step=0.135, global_step=61842.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 72:   0%|          | 0/859 [00:00<00:00, 2849.39it/s, loss=0.141, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00312, train/loss_step=0.135, global_step=61842.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 72:  23%|██▎       | 200/859 [01:32<05:04,  2.17it/s, loss=0.141, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00312, train/loss_step=0.135, global_step=61842.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 72:  23%|██▎       | 200/859 [01:32<05:04,  2.17it/s, loss=0.143, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00393, train/loss_step=0.139, global_step=6.2e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142] 
Epoch 72:  47%|████▋     | 400/859 [02:38<03:01,  2.52it/s, loss=0.143, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00393, train/loss_step=0.139, global_step=6.2e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 72:  47%|████▋     | 400/859 [02:38<03:01,  2.52it/s, loss=0.143, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00232, train/loss_step=0.132, global_step=62242.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 72:  70%|██████▉   | 600/859 [03:45<01:36,  2.67it/s, loss=0.143, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00232, train/loss_step=0.132, global_step=62242.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 72:  70%|██████▉   | 600/859 [03:45<01:36,  2.67it/s, loss=0.139, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.0022, train/loss_step=0.147, global_step=62442.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 72:  93%|█████████▎| 800/859 [05:17<00:23,  2.52it/s, loss=0.139, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.0022, train/loss_step=0.147, global_step=62442.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 72:  93%|█████████▎| 800/859 [05:17<00:23,  2.52it/s, loss=0.142, v_num=38, loss_step=0.123, train/loss_simple_step=0.123, train/loss_vlb_step=0.00127, train/loss_step=0.123, global_step=62642.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 72: 100%|██████████| 859/859 [05:37<00:00,  2.55it/s, loss=0.142, v_num=38, loss_step=0.123, train/loss_simple_step=0.123, train/loss_vlb_step=0.00127, train/loss_step=0.123, global_step=62642.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 72: 100%|██████████| 859/859 [05:37<00:00,  2.55it/s, loss=0.142, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00176, train/loss_step=0.131, global_step=62701.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 72:   0%|          | 0/859 [00:00<00:00, 25890.77it/s, loss=0.142, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00176, train/loss_step=0.131, global_step=62701.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 73:   0%|          | 0/859 [00:00<00:00, 3271.69it/s, loss=0.142, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00176, train/loss_step=0.131, global_step=62701.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142] 
Epoch 73:  23%|██▎       | 200/859 [01:05<03:36,  3.05it/s, loss=0.142, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00176, train/loss_step=0.131, global_step=62701.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 73:  23%|██▎       | 200/859 [01:05<03:36,  3.05it/s, loss=0.142, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00351, train/loss_step=0.141, global_step=62901.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 73:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.142, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00351, train/loss_step=0.141, global_step=62901.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142]
Epoch 73:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.142, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00542, train/loss_step=0.147, global_step=63101.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142]
Epoch 73:  70%|██████▉   | 600/859 [03:44<01:36,  2.67it/s, loss=0.142, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00542, train/loss_step=0.147, global_step=63101.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142]
Epoch 73:  70%|██████▉   | 600/859 [03:44<01:36,  2.67it/s, loss=0.139, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.0014, train/loss_step=0.131, global_step=63301.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 73:  93%|█████████▎| 800/859 [05:17<00:23,  2.52it/s, loss=0.139, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.0014, train/loss_step=0.131, global_step=63301.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142]
Epoch 73:  93%|█████████▎| 800/859 [05:17<00:23,  2.52it/s, loss=0.142, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.0014, train/loss_step=0.137, global_step=63501.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142]
Epoch 73: 100%|██████████| 859/859 [05:37<00:00,  2.55it/s, loss=0.142, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.0014, train/loss_step=0.137, global_step=63501.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142]
Epoch 73: 100%|██████████| 859/859 [05:37<00:00,  2.55it/s, loss=0.144, v_num=38, loss_step=0.157, train/loss_simple_step=0.157, train/loss_vlb_step=0.00259, train/loss_step=0.157, global_step=63560.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142]
Epoch 73:   0%|          | 0/859 [00:00<00:00, 27594.11it/s, loss=0.144, v_num=38, loss_step=0.157, train/loss_simple_step=0.157, train/loss_vlb_step=0.00259, train/loss_step=0.157, global_step=63560.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142]
Epoch 74:   0%|          | 0/859 [00:00<00:00, 2725.34it/s, loss=0.144, v_num=38, loss_step=0.157, train/loss_simple_step=0.157, train/loss_vlb_step=0.00259, train/loss_step=0.157, global_step=63560.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142] 
Epoch 74:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.144, v_num=38, loss_step=0.157, train/loss_simple_step=0.157, train/loss_vlb_step=0.00259, train/loss_step=0.157, global_step=63560.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142]
Epoch 74:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.14, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00396, train/loss_step=0.145, global_step=63760.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]  
Epoch 74:  47%|████▋     | 400/859 [02:12<02:31,  3.03it/s, loss=0.14, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00396, train/loss_step=0.145, global_step=63760.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 74:  47%|████▋     | 400/859 [02:12<02:31,  3.03it/s, loss=0.143, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00245, train/loss_step=0.142, global_step=6.4e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 74:  70%|██████▉   | 600/859 [03:45<01:37,  2.67it/s, loss=0.143, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00245, train/loss_step=0.142, global_step=6.4e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 74:  70%|██████▉   | 600/859 [03:45<01:37,  2.67it/s, loss=0.143, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00419, train/loss_step=0.143, global_step=64160.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 74:  93%|█████████▎| 800/859 [04:51<00:21,  2.75it/s, loss=0.143, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00419, train/loss_step=0.143, global_step=64160.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 74:  93%|█████████▎| 800/859 [04:51<00:21,  2.75it/s, loss=0.138, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.0021, train/loss_step=0.143, global_step=64360.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142] 
Epoch 74: 100%|██████████| 859/859 [05:10<00:00,  2.77it/s, loss=0.138, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.0021, train/loss_step=0.143, global_step=64360.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 74: 100%|██████████| 859/859 [05:10<00:00,  2.77it/s, loss=0.139, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00161, train/loss_step=0.144, global_step=64419.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 74:   0%|          | 0/859 [00:00<00:00, 27962.03it/s, loss=0.139, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00161, train/loss_step=0.144, global_step=64419.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 75:   0%|          | 0/859 [00:00<00:00, 3331.46it/s, loss=0.139, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00161, train/loss_step=0.144, global_step=64419.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 75:  23%|██▎       | 200/859 [01:32<05:03,  2.17it/s, loss=0.139, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00161, train/loss_step=0.144, global_step=64419.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 75:  23%|██▎       | 200/859 [01:32<05:03,  2.17it/s, loss=0.143, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00282, train/loss_step=0.133, global_step=64619.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 75:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.143, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00282, train/loss_step=0.133, global_step=64619.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 75:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.143, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00502, train/loss_step=0.133, global_step=64819.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 75:  70%|██████▉   | 600/859 [04:11<01:48,  2.39it/s, loss=0.143, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00502, train/loss_step=0.133, global_step=64819.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 75:  70%|██████▉   | 600/859 [04:11<01:48,  2.39it/s, loss=0.142, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00268, train/loss_step=0.138, global_step=6.5e+4, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141] 
Epoch 75:  93%|█████████▎| 800/859 [05:17<00:23,  2.52it/s, loss=0.142, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00268, train/loss_step=0.138, global_step=6.5e+4, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 75:  93%|█████████▎| 800/859 [05:17<00:23,  2.52it/s, loss=0.142, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00302, train/loss_step=0.130, global_step=65219.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 75: 100%|██████████| 859/859 [05:37<00:00,  2.55it/s, loss=0.142, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00302, train/loss_step=0.130, global_step=65219.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 75: 100%|██████████| 859/859 [05:37<00:00,  2.55it/s, loss=0.145, v_num=38, loss_step=0.165, train/loss_simple_step=0.165, train/loss_vlb_step=0.00226, train/loss_step=0.165, global_step=65278.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 75:   0%|          | 0/859 [00:00<00:00, 26379.27it/s, loss=0.145, v_num=38, loss_step=0.165, train/loss_simple_step=0.165, train/loss_vlb_step=0.00226, train/loss_step=0.165, global_step=65278.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 76:   0%|          | 0/859 [00:00<00:00, 4387.35it/s, loss=0.145, v_num=38, loss_step=0.165, train/loss_simple_step=0.165, train/loss_vlb_step=0.00226, train/loss_step=0.165, global_step=65278.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141] 
Epoch 76:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.145, v_num=38, loss_step=0.165, train/loss_simple_step=0.165, train/loss_vlb_step=0.00226, train/loss_step=0.165, global_step=65278.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 76:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.138, v_num=38, loss_step=0.123, train/loss_simple_step=0.123, train/loss_vlb_step=0.00109, train/loss_step=0.123, global_step=65478.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 76:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.138, v_num=38, loss_step=0.123, train/loss_simple_step=0.123, train/loss_vlb_step=0.00109, train/loss_step=0.123, global_step=65478.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 76:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.142, v_num=38, loss_step=0.159, train/loss_simple_step=0.159, train/loss_vlb_step=0.00235, train/loss_step=0.159, global_step=65678.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 76:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.142, v_num=38, loss_step=0.159, train/loss_simple_step=0.159, train/loss_vlb_step=0.00235, train/loss_step=0.159, global_step=65678.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 76:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.148, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00266, train/loss_step=0.142, global_step=65878.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 76:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.148, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00266, train/loss_step=0.142, global_step=65878.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 76:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.139, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00219, train/loss_step=0.144, global_step=66078.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 76: 100%|██████████| 859/859 [05:40<00:00,  2.52it/s, loss=0.139, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00219, train/loss_step=0.144, global_step=66078.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 76: 100%|██████████| 859/859 [05:40<00:00,  2.52it/s, loss=0.139, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.002, train/loss_step=0.145, global_step=66137.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]  
Epoch 76:   0%|          | 0/859 [00:00<00:00, 25575.02it/s, loss=0.139, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.002, train/loss_step=0.145, global_step=66137.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 77:   0%|          | 0/859 [00:00<00:00, 2504.06it/s, loss=0.139, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.002, train/loss_step=0.145, global_step=66137.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141] 
Epoch 77:  23%|██▎       | 200/859 [01:06<03:38,  3.02it/s, loss=0.139, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.002, train/loss_step=0.145, global_step=66137.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 77:  23%|██▎       | 200/859 [01:06<03:38,  3.02it/s, loss=0.144, v_num=38, loss_step=0.126, train/loss_simple_step=0.126, train/loss_vlb_step=0.00255, train/loss_step=0.126, global_step=66337.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 77:  47%|████▋     | 400/859 [02:40<03:04,  2.49it/s, loss=0.144, v_num=38, loss_step=0.126, train/loss_simple_step=0.126, train/loss_vlb_step=0.00255, train/loss_step=0.126, global_step=66337.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 77:  47%|████▋     | 400/859 [02:40<03:04,  2.49it/s, loss=0.138, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00179, train/loss_step=0.145, global_step=66537.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 77:  70%|██████▉   | 600/859 [03:47<01:37,  2.65it/s, loss=0.138, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00179, train/loss_step=0.145, global_step=66537.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 77:  70%|██████▉   | 600/859 [03:47<01:37,  2.65it/s, loss=0.139, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.0031, train/loss_step=0.148, global_step=66737.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142] 
Epoch 77:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.139, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.0031, train/loss_step=0.148, global_step=66737.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 77:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.145, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.0026, train/loss_step=0.130, global_step=66937.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 77: 100%|██████████| 859/859 [05:13<00:00,  2.75it/s, loss=0.145, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.0026, train/loss_step=0.130, global_step=66937.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 77: 100%|██████████| 859/859 [05:13<00:00,  2.75it/s, loss=0.142, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00255, train/loss_step=0.141, global_step=6.7e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 77:   0%|          | 0/859 [00:00<00:00, 26214.40it/s, loss=0.142, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00255, train/loss_step=0.141, global_step=6.7e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 78:   0%|          | 0/859 [00:00<00:00, 2945.44it/s, loss=0.142, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00255, train/loss_step=0.141, global_step=6.7e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 78:  23%|██▎       | 200/859 [01:34<05:09,  2.13it/s, loss=0.142, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00255, train/loss_step=0.141, global_step=6.7e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 78:  23%|██▎       | 200/859 [01:34<05:09,  2.13it/s, loss=0.142, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00258, train/loss_step=0.142, global_step=67196.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 78:  47%|████▋     | 400/859 [02:40<03:04,  2.49it/s, loss=0.142, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00258, train/loss_step=0.142, global_step=67196.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 78:  47%|████▋     | 400/859 [02:40<03:04,  2.49it/s, loss=0.145, v_num=38, loss_step=0.164, train/loss_simple_step=0.164, train/loss_vlb_step=0.00138, train/loss_step=0.164, global_step=67396.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 78:  70%|██████▉   | 600/859 [04:15<01:50,  2.35it/s, loss=0.145, v_num=38, loss_step=0.164, train/loss_simple_step=0.164, train/loss_vlb_step=0.00138, train/loss_step=0.164, global_step=67396.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 78:  70%|██████▉   | 600/859 [04:15<01:50,  2.35it/s, loss=0.141, v_num=38, loss_step=0.157, train/loss_simple_step=0.157, train/loss_vlb_step=0.00549, train/loss_step=0.157, global_step=67596.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 78:  93%|█████████▎| 800/859 [05:22<00:23,  2.49it/s, loss=0.141, v_num=38, loss_step=0.157, train/loss_simple_step=0.157, train/loss_vlb_step=0.00549, train/loss_step=0.157, global_step=67596.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 78:  93%|█████████▎| 800/859 [05:22<00:23,  2.49it/s, loss=0.146, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00505, train/loss_step=0.150, global_step=67796.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 78: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.146, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00505, train/loss_step=0.150, global_step=67796.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 78: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.142, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00204, train/loss_step=0.145, global_step=67855.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 78:   0%|          | 0/859 [00:00<00:00, 25575.02it/s, loss=0.142, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00204, train/loss_step=0.145, global_step=67855.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 79:   0%|          | 0/859 [00:00<00:00, 4056.39it/s, loss=0.142, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00204, train/loss_step=0.145, global_step=67855.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 79:  23%|██▎       | 200/859 [01:34<05:10,  2.12it/s, loss=0.142, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00204, train/loss_step=0.145, global_step=67855.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 79:  23%|██▎       | 200/859 [01:34<05:10,  2.12it/s, loss=0.14, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00149, train/loss_step=0.138, global_step=68055.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142] 
Epoch 79:  47%|████▋     | 400/859 [02:40<03:04,  2.49it/s, loss=0.14, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00149, train/loss_step=0.138, global_step=68055.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142]
Epoch 79:  47%|████▋     | 400/859 [02:40<03:04,  2.49it/s, loss=0.139, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00169, train/loss_step=0.133, global_step=68255.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142]
Epoch 79:  70%|██████▉   | 600/859 [03:47<01:38,  2.64it/s, loss=0.139, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00169, train/loss_step=0.133, global_step=68255.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142]
Epoch 79:  70%|██████▉   | 600/859 [03:47<01:38,  2.64it/s, loss=0.145, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00267, train/loss_step=0.139, global_step=68455.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 79:  93%|█████████▎| 800/859 [05:22<00:23,  2.49it/s, loss=0.145, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00267, train/loss_step=0.139, global_step=68455.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142]
Epoch 79:  93%|█████████▎| 800/859 [05:22<00:23,  2.49it/s, loss=0.144, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00217, train/loss_step=0.133, global_step=68655.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142]
Epoch 79: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.144, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00217, train/loss_step=0.133, global_step=68655.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142]
Epoch 79: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.143, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.00361, train/loss_step=0.153, global_step=68714.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142]
Epoch 79:   0%|          | 0/859 [00:00<00:00, 26546.23it/s, loss=0.143, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.00361, train/loss_step=0.153, global_step=68714.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142]
Epoch 80:   0%|          | 0/859 [00:00<00:00, 4410.41it/s, loss=0.143, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.00361, train/loss_step=0.153, global_step=68714.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142] 
Epoch 80:  23%|██▎       | 200/859 [01:06<03:38,  3.02it/s, loss=0.143, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.00361, train/loss_step=0.153, global_step=68714.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142]
Epoch 80:  23%|██▎       | 200/859 [01:06<03:38,  3.02it/s, loss=0.146, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00247, train/loss_step=0.141, global_step=68914.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 80:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.146, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00247, train/loss_step=0.141, global_step=68914.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 80:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.14, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00107, train/loss_step=0.130, global_step=69114.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142] 
Epoch 80:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.14, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00107, train/loss_step=0.130, global_step=69114.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 80:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.144, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.00175, train/loss_step=0.153, global_step=69314.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 80:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.144, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.00175, train/loss_step=0.153, global_step=69314.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 80:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.144, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00211, train/loss_step=0.134, global_step=69514.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 80: 100%|██████████| 859/859 [05:40<00:00,  2.52it/s, loss=0.144, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00211, train/loss_step=0.134, global_step=69514.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 80: 100%|██████████| 859/859 [05:40<00:00,  2.52it/s, loss=0.139, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00182, train/loss_step=0.142, global_step=69573.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 80:   0%|          | 0/859 [00:00<00:00, 25731.93it/s, loss=0.139, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00182, train/loss_step=0.142, global_step=69573.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 81:   0%|          | 0/859 [00:00<00:00, 4266.84it/s, loss=0.139, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00182, train/loss_step=0.142, global_step=69573.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142] 
Epoch 81:  23%|██▎       | 200/859 [01:06<03:37,  3.02it/s, loss=0.139, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00182, train/loss_step=0.142, global_step=69573.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 81:  23%|██▎       | 200/859 [01:06<03:37,  3.02it/s, loss=0.141, v_num=38, loss_step=0.163, train/loss_simple_step=0.163, train/loss_vlb_step=0.00435, train/loss_step=0.163, global_step=69773.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.141]
Epoch 81:  47%|████▋     | 400/859 [02:12<02:32,  3.02it/s, loss=0.141, v_num=38, loss_step=0.163, train/loss_simple_step=0.163, train/loss_vlb_step=0.00435, train/loss_step=0.163, global_step=69773.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.141]
Epoch 81:  47%|████▋     | 400/859 [02:12<02:32,  3.02it/s, loss=0.146, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00309, train/loss_step=0.143, global_step=7e+4, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.141]   pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 81:  70%|██████▉   | 600/859 [03:47<01:38,  2.64it/s, loss=0.146, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00309, train/loss_step=0.143, global_step=7e+4, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.141]
Epoch 81:  70%|██████▉   | 600/859 [03:47<01:38,  2.64it/s, loss=0.14, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00301, train/loss_step=0.137, global_step=70173.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.141]
Epoch 81:  93%|█████████▎| 800/859 [04:54<00:21,  2.72it/s, loss=0.14, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00301, train/loss_step=0.137, global_step=70173.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.141]
Epoch 81:  93%|█████████▎| 800/859 [04:54<00:21,  2.72it/s, loss=0.142, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00309, train/loss_step=0.146, global_step=70373.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.141]
Epoch 81: 100%|██████████| 859/859 [05:13<00:00,  2.74it/s, loss=0.142, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00309, train/loss_step=0.146, global_step=70373.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.141]
Epoch 81: 100%|██████████| 859/859 [05:13<00:00,  2.74it/s, loss=0.14, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.0023, train/loss_step=0.136, global_step=70432.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.141]  
Epoch 81:   0%|          | 0/859 [00:00<00:00, 25890.77it/s, loss=0.14, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.0023, train/loss_step=0.136, global_step=70432.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.141]
Epoch 82:   0%|          | 0/859 [00:00<00:00, 3754.97it/s, loss=0.14, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.0023, train/loss_step=0.136, global_step=70432.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.141] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 82:  23%|██▎       | 200/859 [01:34<05:09,  2.13it/s, loss=0.14, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.0023, train/loss_step=0.136, global_step=70432.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.141]
Epoch 82:  23%|██▎       | 200/859 [01:34<05:09,  2.13it/s, loss=0.143, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00224, train/loss_step=0.130, global_step=70632.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 82:  47%|████▋     | 400/859 [02:40<03:04,  2.49it/s, loss=0.143, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00224, train/loss_step=0.130, global_step=70632.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 82:  47%|████▋     | 400/859 [02:40<03:04,  2.49it/s, loss=0.141, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00251, train/loss_step=0.139, global_step=70832.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 82:  70%|██████▉   | 600/859 [04:15<01:50,  2.35it/s, loss=0.141, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00251, train/loss_step=0.139, global_step=70832.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 82:  70%|██████▉   | 600/859 [04:15<01:50,  2.35it/s, loss=0.14, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00234, train/loss_step=0.139, global_step=7.1e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]  
Epoch 82:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.14, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00234, train/loss_step=0.139, global_step=7.1e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 82:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.143, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00389, train/loss_step=0.145, global_step=71232.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 82: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.143, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00389, train/loss_step=0.145, global_step=71232.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 82: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.141, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00278, train/loss_step=0.151, global_step=71291.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 82:   0%|          | 0/859 [00:00<00:00, 25890.77it/s, loss=0.141, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00278, train/loss_step=0.151, global_step=71291.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 83:   0%|          | 0/859 [00:00<00:00, 2663.05it/s, loss=0.141, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00278, train/loss_step=0.151, global_step=71291.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142] 
Epoch 83:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.141, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00278, train/loss_step=0.151, global_step=71291.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 83:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.141, v_num=38, loss_step=0.124, train/loss_simple_step=0.124, train/loss_vlb_step=0.00133, train/loss_step=0.124, global_step=71491.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 83:  47%|████▋     | 400/859 [02:41<03:04,  2.48it/s, loss=0.141, v_num=38, loss_step=0.124, train/loss_simple_step=0.124, train/loss_vlb_step=0.00133, train/loss_step=0.124, global_step=71491.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 83:  47%|████▋     | 400/859 [02:41<03:04,  2.48it/s, loss=0.139, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00347, train/loss_step=0.145, global_step=71691.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 83:  70%|██████▉   | 600/859 [03:47<01:38,  2.64it/s, loss=0.139, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00347, train/loss_step=0.145, global_step=71691.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 83:  70%|██████▉   | 600/859 [03:47<01:38,  2.64it/s, loss=0.14, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.0022, train/loss_step=0.153, global_step=71891.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]  pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 83:  93%|█████████▎| 800/859 [05:20<00:23,  2.50it/s, loss=0.14, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.0022, train/loss_step=0.153, global_step=71891.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 83:  93%|█████████▎| 800/859 [05:20<00:23,  2.50it/s, loss=0.14, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00266, train/loss_step=0.131, global_step=72091.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 83: 100%|██████████| 859/859 [05:39<00:00,  2.53it/s, loss=0.14, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00266, train/loss_step=0.131, global_step=72091.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 83: 100%|██████████| 859/859 [05:39<00:00,  2.53it/s, loss=0.138, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00245, train/loss_step=0.130, global_step=72150.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 83:   0%|          | 0/859 [00:00<00:00, 28149.69it/s, loss=0.138, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00245, train/loss_step=0.130, global_step=72150.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 84:   0%|          | 0/859 [00:00<00:00, 4549.14it/s, loss=0.138, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00245, train/loss_step=0.130, global_step=72150.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142] 
Epoch 84:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.138, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00245, train/loss_step=0.130, global_step=72150.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 84:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.146, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00229, train/loss_step=0.138, global_step=72350.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 84:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.146, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00229, train/loss_step=0.138, global_step=72350.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141]
Epoch 84:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.14, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00483, train/loss_step=0.142, global_step=72550.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141] 
Epoch 84:  70%|██████▉   | 600/859 [03:44<01:36,  2.68it/s, loss=0.14, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00483, train/loss_step=0.142, global_step=72550.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141]
Epoch 84:  70%|██████▉   | 600/859 [03:44<01:36,  2.68it/s, loss=0.143, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00233, train/loss_step=0.132, global_step=72750.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141]
Epoch 84:  93%|█████████▎| 800/859 [04:50<00:21,  2.76it/s, loss=0.143, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00233, train/loss_step=0.132, global_step=72750.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141]
Epoch 84:  93%|█████████▎| 800/859 [04:50<00:21,  2.76it/s, loss=0.138, v_num=38, loss_step=0.129, train/loss_simple_step=0.129, train/loss_vlb_step=0.00152, train/loss_step=0.129, global_step=7.3e+4, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 84: 100%|██████████| 859/859 [05:36<00:00,  2.55it/s, loss=0.138, v_num=38, loss_step=0.129, train/loss_simple_step=0.129, train/loss_vlb_step=0.00152, train/loss_step=0.129, global_step=7.3e+4, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141]
Epoch 84: 100%|██████████| 859/859 [05:36<00:00,  2.55it/s, loss=0.141, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00265, train/loss_step=0.143, global_step=7.3e+4, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141]
Epoch 84:   0%|          | 0/859 [00:00<00:00, 25890.77it/s, loss=0.141, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00265, train/loss_step=0.143, global_step=7.3e+4, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141]
Epoch 85:   0%|          | 0/859 [00:00<00:00, 3640.89it/s, loss=0.141, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00265, train/loss_step=0.143, global_step=7.3e+4, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141] 
Epoch 85:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.141, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00265, train/loss_step=0.143, global_step=7.3e+4, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141]
Epoch 85:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.141, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00221, train/loss_step=0.131, global_step=73209.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 85:  47%|████▋     | 400/859 [02:12<02:31,  3.03it/s, loss=0.141, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00221, train/loss_step=0.131, global_step=73209.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 85:  47%|████▋     | 400/859 [02:12<02:31,  3.03it/s, loss=0.146, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00356, train/loss_step=0.149, global_step=73409.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 85:  70%|██████▉   | 600/859 [03:44<01:36,  2.67it/s, loss=0.146, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00356, train/loss_step=0.149, global_step=73409.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 85:  70%|██████▉   | 600/859 [03:44<01:36,  2.67it/s, loss=0.148, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00312, train/loss_step=0.141, global_step=73609.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 85:  93%|█████████▎| 800/859 [04:50<00:21,  2.75it/s, loss=0.148, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00312, train/loss_step=0.141, global_step=73609.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 85:  93%|█████████▎| 800/859 [04:50<00:21,  2.75it/s, loss=0.142, v_num=38, loss_step=0.164, train/loss_simple_step=0.164, train/loss_vlb_step=0.00354, train/loss_step=0.164, global_step=73809.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 85: 100%|██████████| 859/859 [05:10<00:00,  2.77it/s, loss=0.142, v_num=38, loss_step=0.164, train/loss_simple_step=0.164, train/loss_vlb_step=0.00354, train/loss_step=0.164, global_step=73809.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 85: 100%|██████████| 859/859 [05:10<00:00,  2.77it/s, loss=0.146, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00214, train/loss_step=0.144, global_step=73868.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 85:   0%|          | 0/859 [00:00<00:00, 25890.77it/s, loss=0.146, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00214, train/loss_step=0.144, global_step=73868.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 86:   0%|          | 0/859 [00:00<00:00, 3945.72it/s, loss=0.146, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00214, train/loss_step=0.144, global_step=73868.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 86:  23%|██▎       | 200/859 [01:34<05:08,  2.14it/s, loss=0.146, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00214, train/loss_step=0.144, global_step=73868.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 86:  23%|██▎       | 200/859 [01:34<05:08,  2.14it/s, loss=0.143, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00613, train/loss_step=0.151, global_step=74068.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 86:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.143, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00613, train/loss_step=0.151, global_step=74068.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 86:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.139, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00216, train/loss_step=0.145, global_step=74268.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 86:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.139, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00216, train/loss_step=0.145, global_step=74268.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 86:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.141, v_num=38, loss_step=0.128, train/loss_simple_step=0.128, train/loss_vlb_step=0.00246, train/loss_step=0.128, global_step=74468.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 86:  93%|█████████▎| 800/859 [05:21<00:23,  2.50it/s, loss=0.141, v_num=38, loss_step=0.128, train/loss_simple_step=0.128, train/loss_vlb_step=0.00246, train/loss_step=0.128, global_step=74468.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 86:  93%|█████████▎| 800/859 [05:21<00:23,  2.50it/s, loss=0.14, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00273, train/loss_step=0.138, global_step=74668.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142] 
Epoch 86: 100%|██████████| 859/859 [05:40<00:00,  2.52it/s, loss=0.14, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00273, train/loss_step=0.138, global_step=74668.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 86: 100%|██████████| 859/859 [05:40<00:00,  2.52it/s, loss=0.141, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00289, train/loss_step=0.144, global_step=74727.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 86:   0%|          | 0/859 [00:00<00:00, 26886.56it/s, loss=0.141, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00289, train/loss_step=0.144, global_step=74727.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 87:   0%|          | 0/859 [00:00<00:00, 3344.74it/s, loss=0.141, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00289, train/loss_step=0.144, global_step=74727.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142] 
Epoch 87:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.141, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00289, train/loss_step=0.144, global_step=74727.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 87:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.141, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00132, train/loss_step=0.151, global_step=74927.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 87:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.141, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00132, train/loss_step=0.151, global_step=74927.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 87:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.142, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00208, train/loss_step=0.149, global_step=75127.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 87:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.142, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00208, train/loss_step=0.149, global_step=75127.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 87:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.139, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00203, train/loss_step=0.151, global_step=75327.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 87:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.139, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00203, train/loss_step=0.151, global_step=75327.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 87:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.141, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00309, train/loss_step=0.139, global_step=75527.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 87: 100%|██████████| 859/859 [05:40<00:00,  2.52it/s, loss=0.141, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00309, train/loss_step=0.139, global_step=75527.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 87: 100%|██████████| 859/859 [05:40<00:00,  2.52it/s, loss=0.139, v_num=38, loss_step=0.129, train/loss_simple_step=0.129, train/loss_vlb_step=0.00288, train/loss_step=0.129, global_step=75586.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 87:   0%|          | 0/859 [00:00<00:00, 25575.02it/s, loss=0.139, v_num=38, loss_step=0.129, train/loss_simple_step=0.129, train/loss_vlb_step=0.00288, train/loss_step=0.129, global_step=75586.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 88:   0%|          | 0/859 [00:00<00:00, 3466.37it/s, loss=0.139, v_num=38, loss_step=0.129, train/loss_simple_step=0.129, train/loss_vlb_step=0.00288, train/loss_step=0.129, global_step=75586.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142] 
Epoch 88:  23%|██▎       | 200/859 [01:06<03:38,  3.02it/s, loss=0.139, v_num=38, loss_step=0.129, train/loss_simple_step=0.129, train/loss_vlb_step=0.00288, train/loss_step=0.129, global_step=75586.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 88:  23%|██▎       | 200/859 [01:06<03:38,  3.02it/s, loss=0.144, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.0024, train/loss_step=0.138, global_step=75786.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141] 
Epoch 88:  47%|████▋     | 400/859 [02:12<02:32,  3.02it/s, loss=0.144, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.0024, train/loss_step=0.138, global_step=75786.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]
Epoch 88:  47%|████▋     | 400/859 [02:12<02:32,  3.02it/s, loss=0.141, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00219, train/loss_step=0.137, global_step=7.6e+4, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 88:  70%|██████▉   | 600/859 [03:47<01:37,  2.65it/s, loss=0.141, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00219, train/loss_step=0.137, global_step=7.6e+4, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]
Epoch 88:  70%|██████▉   | 600/859 [03:47<01:37,  2.65it/s, loss=0.143, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00259, train/loss_step=0.144, global_step=76186.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]
Epoch 88:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.143, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00259, train/loss_step=0.144, global_step=76186.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]
Epoch 88:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.142, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00234, train/loss_step=0.144, global_step=76386.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]
Epoch 88: 100%|██████████| 859/859 [05:13<00:00,  2.75it/s, loss=0.142, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00234, train/loss_step=0.144, global_step=76386.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]
Epoch 88: 100%|██████████| 859/859 [05:13<00:00,  2.75it/s, loss=0.142, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00225, train/loss_step=0.134, global_step=76445.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]
Epoch 88:   0%|          | 0/859 [00:00<00:00, 25890.77it/s, loss=0.142, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00225, train/loss_step=0.134, global_step=76445.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]
Epoch 89:   0%|          | 0/859 [00:00<00:00, 2605.16it/s, loss=0.142, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00225, train/loss_step=0.134, global_step=76445.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 89:  23%|██▎       | 200/859 [01:34<05:10,  2.12it/s, loss=0.142, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00225, train/loss_step=0.134, global_step=76445.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]
Epoch 89:  23%|██▎       | 200/859 [01:34<05:10,  2.12it/s, loss=0.141, v_num=38, loss_step=0.125, train/loss_simple_step=0.125, train/loss_vlb_step=0.00127, train/loss_step=0.125, global_step=76645.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 89:  47%|████▋     | 400/859 [02:41<03:04,  2.49it/s, loss=0.141, v_num=38, loss_step=0.125, train/loss_simple_step=0.125, train/loss_vlb_step=0.00127, train/loss_step=0.125, global_step=76645.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 89:  47%|████▋     | 400/859 [02:41<03:04,  2.49it/s, loss=0.142, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.0023, train/loss_step=0.142, global_step=76845.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 89:  70%|██████▉   | 600/859 [04:15<01:50,  2.35it/s, loss=0.142, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.0023, train/loss_step=0.142, global_step=76845.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 89:  70%|██████▉   | 600/859 [04:15<01:50,  2.35it/s, loss=0.137, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00302, train/loss_step=0.132, global_step=7.7e+4, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 89:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.137, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00302, train/loss_step=0.132, global_step=7.7e+4, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 89:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.139, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00337, train/loss_step=0.133, global_step=77245.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 89: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.139, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00337, train/loss_step=0.133, global_step=77245.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 89: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.142, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00263, train/loss_step=0.152, global_step=77304.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 89:   0%|          | 0/859 [00:00<00:00, 25731.93it/s, loss=0.142, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00263, train/loss_step=0.152, global_step=77304.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 90:   0%|          | 0/859 [00:00<00:00, 2238.16it/s, loss=0.142, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00263, train/loss_step=0.152, global_step=77304.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 90:  23%|██▎       | 200/859 [01:34<05:10,  2.13it/s, loss=0.142, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00263, train/loss_step=0.152, global_step=77304.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 90:  23%|██▎       | 200/859 [01:34<05:10,  2.13it/s, loss=0.139, v_num=38, loss_step=0.128, train/loss_simple_step=0.128, train/loss_vlb_step=0.00202, train/loss_step=0.128, global_step=77504.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141]
Epoch 90:  47%|████▋     | 400/859 [02:40<03:04,  2.49it/s, loss=0.139, v_num=38, loss_step=0.128, train/loss_simple_step=0.128, train/loss_vlb_step=0.00202, train/loss_step=0.128, global_step=77504.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141]
Epoch 90:  47%|████▋     | 400/859 [02:40<03:04,  2.49it/s, loss=0.142, v_num=38, loss_step=0.125, train/loss_simple_step=0.125, train/loss_vlb_step=0.00268, train/loss_step=0.125, global_step=77704.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141]
Epoch 90:  70%|██████▉   | 600/859 [03:47<01:37,  2.65it/s, loss=0.142, v_num=38, loss_step=0.125, train/loss_simple_step=0.125, train/loss_vlb_step=0.00268, train/loss_step=0.125, global_step=77704.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141]
Epoch 90:  70%|██████▉   | 600/859 [03:47<01:37,  2.65it/s, loss=0.142, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00139, train/loss_step=0.139, global_step=77904.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 90:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.142, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00139, train/loss_step=0.139, global_step=77904.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141]
Epoch 90:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.141, v_num=38, loss_step=0.125, train/loss_simple_step=0.125, train/loss_vlb_step=0.0014, train/loss_step=0.125, global_step=78104.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141] 
Epoch 90: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.141, v_num=38, loss_step=0.125, train/loss_simple_step=0.125, train/loss_vlb_step=0.0014, train/loss_step=0.125, global_step=78104.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141]
Epoch 90: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.141, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00241, train/loss_step=0.135, global_step=78163.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141]
Epoch 90:   0%|          | 0/859 [00:00<00:00, 25420.02it/s, loss=0.141, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00241, train/loss_step=0.135, global_step=78163.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141]
Epoch 91:   0%|          | 0/859 [00:00<00:00, 3758.34it/s, loss=0.141, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00241, train/loss_step=0.135, global_step=78163.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141] 
Epoch 91:  23%|██▎       | 200/859 [01:06<03:37,  3.04it/s, loss=0.141, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00241, train/loss_step=0.135, global_step=78163.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141]
Epoch 91:  23%|██▎       | 200/859 [01:06<03:37,  3.04it/s, loss=0.141, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00168, train/loss_step=0.144, global_step=78363.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 91:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.141, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00168, train/loss_step=0.144, global_step=78363.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 91:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.142, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00278, train/loss_step=0.137, global_step=78563.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 91:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.142, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00278, train/loss_step=0.137, global_step=78563.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 91:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.141, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00256, train/loss_step=0.132, global_step=78763.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 91:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.141, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00256, train/loss_step=0.132, global_step=78763.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 91:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.145, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00313, train/loss_step=0.143, global_step=7.9e+4, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 91: 100%|██████████| 859/859 [05:40<00:00,  2.52it/s, loss=0.145, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00313, train/loss_step=0.143, global_step=7.9e+4, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 91: 100%|██████████| 859/859 [05:40<00:00,  2.52it/s, loss=0.143, v_num=38, loss_step=0.128, train/loss_simple_step=0.128, train/loss_vlb_step=0.00302, train/loss_step=0.128, global_step=7.9e+4, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 91:   0%|          | 0/859 [00:00<00:00, 26214.40it/s, loss=0.143, v_num=38, loss_step=0.128, train/loss_simple_step=0.128, train/loss_vlb_step=0.00302, train/loss_step=0.128, global_step=7.9e+4, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 92:   0%|          | 0/859 [00:00<00:00, 3486.54it/s, loss=0.143, v_num=38, loss_step=0.128, train/loss_simple_step=0.128, train/loss_vlb_step=0.00302, train/loss_step=0.128, global_step=7.9e+4, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141] 
Epoch 92:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.143, v_num=38, loss_step=0.128, train/loss_simple_step=0.128, train/loss_vlb_step=0.00302, train/loss_step=0.128, global_step=7.9e+4, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 92:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.139, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00174, train/loss_step=0.132, global_step=79222.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.141]
Epoch 92:  47%|████▋     | 400/859 [02:12<02:31,  3.02it/s, loss=0.139, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00174, train/loss_step=0.132, global_step=79222.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.141]
Epoch 92:  47%|████▋     | 400/859 [02:12<02:31,  3.02it/s, loss=0.148, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00132, train/loss_step=0.138, global_step=79422.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 92:  70%|██████▉   | 600/859 [03:47<01:37,  2.65it/s, loss=0.148, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00132, train/loss_step=0.138, global_step=79422.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.141]
Epoch 92:  70%|██████▉   | 600/859 [03:47<01:37,  2.65it/s, loss=0.142, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00182, train/loss_step=0.143, global_step=79622.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.141]
Epoch 92:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.142, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00182, train/loss_step=0.143, global_step=79622.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.141]
Epoch 92:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.14, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00534, train/loss_step=0.141, global_step=79822.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.141] 
Epoch 92: 100%|██████████| 859/859 [05:12<00:00,  2.75it/s, loss=0.14, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00534, train/loss_step=0.141, global_step=79822.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.141]
Epoch 92: 100%|██████████| 859/859 [05:12<00:00,  2.75it/s, loss=0.141, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00156, train/loss_step=0.131, global_step=79881.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.141]
Epoch 92:   0%|          | 0/859 [00:00<00:00, 27235.74it/s, loss=0.141, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00156, train/loss_step=0.131, global_step=79881.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.141]
Epoch 93:   0%|          | 0/859 [00:00<00:00, 2598.70it/s, loss=0.141, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00156, train/loss_step=0.131, global_step=79881.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.141] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 93:  23%|██▎       | 200/859 [01:34<05:09,  2.13it/s, loss=0.141, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00156, train/loss_step=0.131, global_step=79881.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.141]
Epoch 93:  23%|██▎       | 200/859 [01:34<05:09,  2.13it/s, loss=0.144, v_num=38, loss_step=0.157, train/loss_simple_step=0.157, train/loss_vlb_step=0.00389, train/loss_step=0.157, global_step=80081.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 93:  47%|████▋     | 400/859 [02:40<03:04,  2.49it/s, loss=0.144, v_num=38, loss_step=0.157, train/loss_simple_step=0.157, train/loss_vlb_step=0.00389, train/loss_step=0.157, global_step=80081.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 93:  47%|████▋     | 400/859 [02:40<03:04,  2.49it/s, loss=0.144, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00385, train/loss_step=0.145, global_step=80281.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 93:  70%|██████▉   | 600/859 [03:47<01:37,  2.65it/s, loss=0.144, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00385, train/loss_step=0.145, global_step=80281.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 93:  70%|██████▉   | 600/859 [03:47<01:37,  2.65it/s, loss=0.142, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00361, train/loss_step=0.138, global_step=80481.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 93:  93%|█████████▎| 800/859 [05:20<00:23,  2.50it/s, loss=0.142, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00361, train/loss_step=0.138, global_step=80481.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 93:  93%|█████████▎| 800/859 [05:20<00:23,  2.50it/s, loss=0.143, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00226, train/loss_step=0.147, global_step=80681.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 93: 100%|██████████| 859/859 [05:40<00:00,  2.53it/s, loss=0.143, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00226, train/loss_step=0.147, global_step=80681.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 93: 100%|██████████| 859/859 [05:40<00:00,  2.53it/s, loss=0.139, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00232, train/loss_step=0.134, global_step=80740.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 93:   0%|          | 0/859 [00:00<00:00, 27060.03it/s, loss=0.139, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00232, train/loss_step=0.134, global_step=80740.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 94:   0%|          | 0/859 [00:00<00:00, 2671.53it/s, loss=0.139, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00232, train/loss_step=0.134, global_step=80740.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142] 
Epoch 94:  23%|██▎       | 200/859 [01:06<03:36,  3.05it/s, loss=0.139, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00232, train/loss_step=0.134, global_step=80740.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 94:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.141, v_num=38, loss_step=0.164, train/loss_simple_step=0.164, train/loss_vlb_step=0.00353, train/loss_step=0.164, global_step=80940.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 94:  47%|████▋     | 400/859 [02:38<03:01,  2.52it/s, loss=0.141, v_num=38, loss_step=0.164, train/loss_simple_step=0.164, train/loss_vlb_step=0.00353, train/loss_step=0.164, global_step=80940.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 94:  47%|████▋     | 400/859 [02:38<03:01,  2.52it/s, loss=0.139, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00218, train/loss_step=0.135, global_step=81140.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 94:  70%|██████▉   | 600/859 [03:45<01:37,  2.67it/s, loss=0.139, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00218, train/loss_step=0.135, global_step=81140.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 94:  70%|██████▉   | 600/859 [03:45<01:37,  2.67it/s, loss=0.144, v_num=38, loss_step=0.156, train/loss_simple_step=0.156, train/loss_vlb_step=0.00332, train/loss_step=0.156, global_step=81340.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 94:  93%|█████████▎| 800/859 [05:17<00:23,  2.52it/s, loss=0.144, v_num=38, loss_step=0.156, train/loss_simple_step=0.156, train/loss_vlb_step=0.00332, train/loss_step=0.156, global_step=81340.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 94:  93%|█████████▎| 800/859 [05:17<00:23,  2.52it/s, loss=0.138, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00183, train/loss_step=0.135, global_step=81540.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 94: 100%|██████████| 859/859 [05:37<00:00,  2.55it/s, loss=0.138, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00183, train/loss_step=0.135, global_step=81540.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 94: 100%|██████████| 859/859 [05:37<00:00,  2.55it/s, loss=0.144, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00182, train/loss_step=0.142, global_step=81599.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 94:   0%|          | 0/859 [00:00<00:00, 26715.31it/s, loss=0.144, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00182, train/loss_step=0.142, global_step=81599.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 95:   0%|          | 0/859 [00:00<00:00, 3734.91it/s, loss=0.144, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00182, train/loss_step=0.142, global_step=81599.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142] 
Epoch 95:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.144, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00182, train/loss_step=0.142, global_step=81599.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 95:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.14, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00248, train/loss_step=0.143, global_step=81799.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142] 
Epoch 95:  47%|████▋     | 400/859 [02:12<02:31,  3.03it/s, loss=0.14, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00248, train/loss_step=0.143, global_step=81799.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]
Epoch 95:  47%|████▋     | 400/859 [02:12<02:31,  3.03it/s, loss=0.146, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00193, train/loss_step=0.140, global_step=8.2e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 95:  70%|██████▉   | 600/859 [03:45<01:37,  2.67it/s, loss=0.146, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00193, train/loss_step=0.140, global_step=8.2e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]
Epoch 95:  70%|██████▉   | 600/859 [03:45<01:37,  2.67it/s, loss=0.143, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00244, train/loss_step=0.144, global_step=82199.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]
Epoch 95:  93%|█████████▎| 800/859 [04:51<00:21,  2.75it/s, loss=0.143, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00244, train/loss_step=0.144, global_step=82199.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]
Epoch 95:  93%|█████████▎| 800/859 [04:51<00:21,  2.75it/s, loss=0.14, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00237, train/loss_step=0.133, global_step=82399.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142] 
Epoch 95: 100%|██████████| 859/859 [05:10<00:00,  2.77it/s, loss=0.14, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00237, train/loss_step=0.133, global_step=82399.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]
Epoch 95: 100%|██████████| 859/859 [05:10<00:00,  2.77it/s, loss=0.141, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00326, train/loss_step=0.149, global_step=82458.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]
Epoch 95:   0%|          | 0/859 [00:00<00:00, 28926.23it/s, loss=0.141, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00326, train/loss_step=0.149, global_step=82458.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]
Epoch 96:   0%|          | 0/859 [00:00<00:00, 5548.02it/s, loss=0.141, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00326, train/loss_step=0.149, global_step=82458.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 96:  23%|██▎       | 200/859 [01:34<05:09,  2.13it/s, loss=0.141, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00326, train/loss_step=0.149, global_step=82458.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]
Epoch 96:  23%|██▎       | 200/859 [01:34<05:09,  2.13it/s, loss=0.141, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00213, train/loss_step=0.149, global_step=82658.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 96:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.141, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00213, train/loss_step=0.149, global_step=82658.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 96:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.14, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00282, train/loss_step=0.152, global_step=82858.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 96:  70%|██████▉   | 600/859 [04:14<01:49,  2.36it/s, loss=0.14, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00282, train/loss_step=0.152, global_step=82858.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 96:  70%|██████▉   | 600/859 [04:15<01:49,  2.36it/s, loss=0.14, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00351, train/loss_step=0.138, global_step=83058.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 96:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.14, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00351, train/loss_step=0.138, global_step=83058.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 96:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.143, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00379, train/loss_step=0.137, global_step=83258.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 96: 100%|██████████| 859/859 [05:40<00:00,  2.52it/s, loss=0.143, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00379, train/loss_step=0.137, global_step=83258.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 96: 100%|██████████| 859/859 [05:40<00:00,  2.52it/s, loss=0.14, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00488, train/loss_step=0.151, global_step=83317.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141] 
Epoch 96:   0%|          | 0/859 [00:00<00:00, 25575.02it/s, loss=0.14, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00488, train/loss_step=0.151, global_step=83317.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 97:   0%|          | 0/859 [00:00<00:00, 4017.53it/s, loss=0.14, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00488, train/loss_step=0.151, global_step=83317.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 97:  23%|██▎       | 200/859 [01:34<05:10,  2.13it/s, loss=0.14, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00488, train/loss_step=0.151, global_step=83317.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 97:  23%|██▎       | 200/859 [01:34<05:10,  2.13it/s, loss=0.14, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00131, train/loss_step=0.136, global_step=83517.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 97:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.14, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00131, train/loss_step=0.136, global_step=83517.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 97:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.14, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.0042, train/loss_step=0.141, global_step=83717.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142] 
Epoch 97:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.14, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.0042, train/loss_step=0.141, global_step=83717.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 97:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.137, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00243, train/loss_step=0.132, global_step=83917.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 97:  93%|█████████▎| 800/859 [05:21<00:23,  2.50it/s, loss=0.137, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00243, train/loss_step=0.132, global_step=83917.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 97:  93%|█████████▎| 800/859 [05:21<00:23,  2.50it/s, loss=0.144, v_num=38, loss_step=0.173, train/loss_simple_step=0.173, train/loss_vlb_step=0.00273, train/loss_step=0.173, global_step=84117.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 97: 100%|██████████| 859/859 [05:40<00:00,  2.53it/s, loss=0.144, v_num=38, loss_step=0.173, train/loss_simple_step=0.173, train/loss_vlb_step=0.00273, train/loss_step=0.173, global_step=84117.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 97: 100%|██████████| 859/859 [05:40<00:00,  2.53it/s, loss=0.137, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00148, train/loss_step=0.138, global_step=84176.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 97:   0%|          | 0/859 [00:00<00:00, 26214.40it/s, loss=0.137, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00148, train/loss_step=0.138, global_step=84176.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 98:   0%|          | 0/859 [00:00<00:00, 2502.57it/s, loss=0.137, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00148, train/loss_step=0.138, global_step=84176.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142] 
Epoch 98:  23%|██▎       | 200/859 [01:06<03:37,  3.02it/s, loss=0.137, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00148, train/loss_step=0.138, global_step=84176.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 98:  23%|██▎       | 200/859 [01:06<03:37,  3.02it/s, loss=0.141, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00311, train/loss_step=0.152, global_step=84376.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 98:  47%|████▋     | 400/859 [02:41<03:04,  2.49it/s, loss=0.141, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00311, train/loss_step=0.152, global_step=84376.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 98:  47%|████▋     | 400/859 [02:41<03:04,  2.49it/s, loss=0.142, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00147, train/loss_step=0.137, global_step=84576.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 98:  70%|██████▉   | 600/859 [03:47<01:38,  2.64it/s, loss=0.142, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00147, train/loss_step=0.137, global_step=84576.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 98:  70%|██████▉   | 600/859 [03:47<01:38,  2.64it/s, loss=0.142, v_num=38, loss_step=0.160, train/loss_simple_step=0.160, train/loss_vlb_step=0.00213, train/loss_step=0.160, global_step=84776.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 98:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.142, v_num=38, loss_step=0.160, train/loss_simple_step=0.160, train/loss_vlb_step=0.00213, train/loss_step=0.160, global_step=84776.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 98:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.141, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00374, train/loss_step=0.133, global_step=8.5e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 98: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.141, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00374, train/loss_step=0.133, global_step=8.5e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 98: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.14, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00188, train/loss_step=0.143, global_step=8.5e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142] 
Epoch 98:   0%|          | 0/859 [00:00<00:00, 25115.59it/s, loss=0.14, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00188, train/loss_step=0.143, global_step=8.5e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 99:   0%|          | 0/859 [00:00<00:00, 2957.90it/s, loss=0.14, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00188, train/loss_step=0.143, global_step=8.5e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142] 
Epoch 99:  23%|██▎       | 200/859 [01:06<03:37,  3.04it/s, loss=0.14, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00188, train/loss_step=0.143, global_step=8.5e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 99:  23%|██▎       | 200/859 [01:06<03:37,  3.04it/s, loss=0.141, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00153, train/loss_step=0.149, global_step=85235.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 99:  47%|████▋     | 400/859 [02:12<02:31,  3.03it/s, loss=0.141, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00153, train/loss_step=0.149, global_step=85235.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 99:  47%|████▋     | 400/859 [02:12<02:31,  3.03it/s, loss=0.139, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00239, train/loss_step=0.140, global_step=85435.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 99:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.139, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00239, train/loss_step=0.140, global_step=85435.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 99:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.139, v_num=38, loss_step=0.162, train/loss_simple_step=0.162, train/loss_vlb_step=0.00534, train/loss_step=0.162, global_step=85635.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 99:  93%|█████████▎| 800/859 [04:52<00:21,  2.74it/s, loss=0.139, v_num=38, loss_step=0.162, train/loss_simple_step=0.162, train/loss_vlb_step=0.00534, train/loss_step=0.162, global_step=85635.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 99:  93%|█████████▎| 800/859 [04:52<00:21,  2.74it/s, loss=0.146, v_num=38, loss_step=0.163, train/loss_simple_step=0.163, train/loss_vlb_step=0.002, train/loss_step=0.163, global_step=85835.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]  
Epoch 99: 100%|██████████| 859/859 [05:12<00:00,  2.75it/s, loss=0.146, v_num=38, loss_step=0.163, train/loss_simple_step=0.163, train/loss_vlb_step=0.002, train/loss_step=0.163, global_step=85835.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 99: 100%|██████████| 859/859 [05:12<00:00,  2.75it/s, loss=0.142, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.0027, train/loss_step=0.146, global_step=85894.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 99:   0%|          | 0/859 [00:00<00:00, 26379.27it/s, loss=0.142, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.0027, train/loss_step=0.146, global_step=85894.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 100:   0%|          | 0/859 [00:00<00:00, 3751.61it/s, loss=0.142, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.0027, train/loss_step=0.146, global_step=85894.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 100:  23%|██▎       | 200/859 [01:34<05:10,  2.12it/s, loss=0.142, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.0027, train/loss_step=0.146, global_step=85894.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 100:  23%|██▎       | 200/859 [01:34<05:10,  2.12it/s, loss=0.143, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00304, train/loss_step=0.142, global_step=86094.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]
Epoch 100:  47%|████▋     | 400/859 [02:41<03:04,  2.49it/s, loss=0.143, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00304, train/loss_step=0.142, global_step=86094.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]
Epoch 100:  47%|████▋     | 400/859 [02:41<03:04,  2.49it/s, loss=0.142, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00192, train/loss_step=0.138, global_step=86294.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]
Epoch 100:  70%|██████▉   | 600/859 [03:47<01:37,  2.65it/s, loss=0.142, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00192, train/loss_step=0.138, global_step=86294.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]
Epoch 100:  70%|██████▉   | 600/859 [03:47<01:37,  2.65it/s, loss=0.145, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00131, train/loss_step=0.133, global_step=86494.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 100:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.145, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00131, train/loss_step=0.133, global_step=86494.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]
Epoch 100:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.139, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00229, train/loss_step=0.137, global_step=86694.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]
Epoch 100: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.139, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00229, train/loss_step=0.137, global_step=86694.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]
Epoch 100: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.139, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00239, train/loss_step=0.144, global_step=86753.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]
Epoch 100:   0%|          | 0/859 [00:00<00:00, 26715.31it/s, loss=0.139, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00239, train/loss_step=0.144, global_step=86753.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]
Epoch 101:   0%|          | 0/859 [00:00<00:00, 3768.47it/s, loss=0.139, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00239, train/loss_step=0.144, global_step=86753.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142] 
Epoch 101:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.139, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00239, train/loss_step=0.144, global_step=86753.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]
Epoch 101:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.14, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00176, train/loss_step=0.138, global_step=8.7e+4, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.141]  pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 101:  47%|████▋     | 400/859 [02:40<03:03,  2.49it/s, loss=0.14, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00176, train/loss_step=0.138, global_step=8.7e+4, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.141]
Epoch 101:  47%|████▋     | 400/859 [02:40<03:03,  2.49it/s, loss=0.142, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00253, train/loss_step=0.150, global_step=87153.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.141]
Epoch 101:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.142, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00253, train/loss_step=0.150, global_step=87153.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.141]
Epoch 101:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.142, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00314, train/loss_step=0.146, global_step=87353.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 101:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.142, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00314, train/loss_step=0.146, global_step=87353.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.141]
Epoch 101:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.141, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00216, train/loss_step=0.135, global_step=87553.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.141]
Epoch 101: 100%|██████████| 859/859 [05:40<00:00,  2.52it/s, loss=0.141, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00216, train/loss_step=0.135, global_step=87553.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.141]
Epoch 101: 100%|██████████| 859/859 [05:40<00:00,  2.52it/s, loss=0.143, v_num=38, loss_step=0.113, train/loss_simple_step=0.113, train/loss_vlb_step=0.000848, train/loss_step=0.113, global_step=87612.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.141]
Epoch 101:   0%|          | 0/859 [00:00<00:00, 27594.11it/s, loss=0.143, v_num=38, loss_step=0.113, train/loss_simple_step=0.113, train/loss_vlb_step=0.000848, train/loss_step=0.113, global_step=87612.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.141]
Epoch 102:   0%|          | 0/859 [00:00<00:00, 4987.28it/s, loss=0.143, v_num=38, loss_step=0.113, train/loss_simple_step=0.113, train/loss_vlb_step=0.000848, train/loss_step=0.113, global_step=87612.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.141] 
Epoch 102:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.143, v_num=38, loss_step=0.113, train/loss_simple_step=0.113, train/loss_vlb_step=0.000848, train/loss_step=0.113, global_step=87612.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.141]
Epoch 102:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.141, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00131, train/loss_step=0.137, global_step=87812.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 102:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.141, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00131, train/loss_step=0.137, global_step=87812.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 102:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.144, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00129, train/loss_step=0.142, global_step=8.8e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142] 
Epoch 102:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.144, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00129, train/loss_step=0.142, global_step=8.8e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 102:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.144, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00331, train/loss_step=0.139, global_step=88212.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 102:  93%|█████████▎| 800/859 [04:52<00:21,  2.74it/s, loss=0.144, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00331, train/loss_step=0.139, global_step=88212.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 102:  93%|█████████▎| 800/859 [04:52<00:21,  2.74it/s, loss=0.146, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00273, train/loss_step=0.145, global_step=88412.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 102: 100%|██████████| 859/859 [05:12<00:00,  2.75it/s, loss=0.146, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00273, train/loss_step=0.145, global_step=88412.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 102: 100%|██████████| 859/859 [05:12<00:00,  2.75it/s, loss=0.143, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00225, train/loss_step=0.150, global_step=88471.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 102:   0%|          | 0/859 [00:00<00:00, 26214.40it/s, loss=0.143, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00225, train/loss_step=0.150, global_step=88471.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 103:   0%|          | 0/859 [00:00<00:00, 4072.14it/s, loss=0.143, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00225, train/loss_step=0.150, global_step=88471.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 103:  23%|██▎       | 200/859 [01:34<05:09,  2.13it/s, loss=0.143, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00225, train/loss_step=0.150, global_step=88471.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 103:  23%|██▎       | 200/859 [01:34<05:09,  2.13it/s, loss=0.14, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00263, train/loss_step=0.135, global_step=88671.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141] 
Epoch 103:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.14, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00263, train/loss_step=0.135, global_step=88671.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 103:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.142, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00263, train/loss_step=0.135, global_step=88871.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 103:  70%|██████▉   | 600/859 [04:14<01:49,  2.36it/s, loss=0.142, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00263, train/loss_step=0.135, global_step=88871.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 103:  70%|██████▉   | 600/859 [04:14<01:49,  2.36it/s, loss=0.139, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00336, train/loss_step=0.144, global_step=89071.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 103:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.139, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00336, train/loss_step=0.144, global_step=89071.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 103:  93%|█████████▎| 800/859 [05:21<00:23,  2.49it/s, loss=0.138, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00396, train/loss_step=0.134, global_step=89271.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 103: 100%|██████████| 859/859 [05:40<00:00,  2.53it/s, loss=0.138, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00396, train/loss_step=0.134, global_step=89271.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 103: 100%|██████████| 859/859 [05:40<00:00,  2.53it/s, loss=0.145, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00182, train/loss_step=0.139, global_step=89330.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 103:   0%|          | 0/859 [00:00<00:00, 26715.31it/s, loss=0.145, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00182, train/loss_step=0.139, global_step=89330.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 104:   0%|          | 0/859 [00:00<00:00, 3979.42it/s, loss=0.145, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00182, train/loss_step=0.139, global_step=89330.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 104:  23%|██▎       | 200/859 [01:32<05:03,  2.17it/s, loss=0.145, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00182, train/loss_step=0.139, global_step=89330.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 104:  23%|██▎       | 200/859 [01:32<05:03,  2.17it/s, loss=0.14, v_num=38, loss_step=0.155, train/loss_simple_step=0.155, train/loss_vlb_step=0.00411, train/loss_step=0.155, global_step=89530.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]  
Epoch 104:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.14, v_num=38, loss_step=0.155, train/loss_simple_step=0.155, train/loss_vlb_step=0.00411, train/loss_step=0.155, global_step=89530.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 104:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.142, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00296, train/loss_step=0.133, global_step=89730.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 104:  70%|██████▉   | 600/859 [03:44<01:36,  2.68it/s, loss=0.142, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00296, train/loss_step=0.133, global_step=89730.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 104:  70%|██████▉   | 600/859 [03:44<01:36,  2.68it/s, loss=0.141, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00144, train/loss_step=0.139, global_step=89930.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 104:  93%|█████████▎| 800/859 [05:16<00:23,  2.53it/s, loss=0.141, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00144, train/loss_step=0.139, global_step=89930.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 104:  93%|█████████▎| 800/859 [05:16<00:23,  2.53it/s, loss=0.139, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00396, train/loss_step=0.137, global_step=90130.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 104: 100%|██████████| 859/859 [05:36<00:00,  2.56it/s, loss=0.139, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00396, train/loss_step=0.137, global_step=90130.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 104: 100%|██████████| 859/859 [05:36<00:00,  2.56it/s, loss=0.142, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00255, train/loss_step=0.130, global_step=90189.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 104:   0%|          | 0/859 [00:00<00:00, 26546.23it/s, loss=0.142, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00255, train/loss_step=0.130, global_step=90189.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 105:   0%|          | 0/859 [00:00<00:00, 3741.57it/s, loss=0.142, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00255, train/loss_step=0.130, global_step=90189.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141] 
Epoch 105:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.142, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00255, train/loss_step=0.130, global_step=90189.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 105:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.14, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00363, train/loss_step=0.140, global_step=90389.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 105:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.14, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00363, train/loss_step=0.140, global_step=90389.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142]
Epoch 105:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.142, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00259, train/loss_step=0.138, global_step=90589.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142]
Epoch 105:  70%|██████▉   | 600/859 [03:44<01:36,  2.67it/s, loss=0.142, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00259, train/loss_step=0.138, global_step=90589.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142]
Epoch 105:  70%|██████▉   | 600/859 [03:44<01:36,  2.67it/s, loss=0.139, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00227, train/loss_step=0.147, global_step=90789.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142]
Epoch 105:  93%|█████████▎| 800/859 [04:50<00:21,  2.75it/s, loss=0.139, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00227, train/loss_step=0.147, global_step=90789.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142]
Epoch 105:  93%|█████████▎| 800/859 [04:50<00:21,  2.75it/s, loss=0.142, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00181, train/loss_step=0.136, global_step=9.1e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 105: 100%|██████████| 859/859 [05:36<00:00,  2.55it/s, loss=0.142, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00181, train/loss_step=0.136, global_step=9.1e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142]
Epoch 105: 100%|██████████| 859/859 [05:36<00:00,  2.55it/s, loss=0.145, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00124, train/loss_step=0.134, global_step=9.1e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142]
Epoch 105:   0%|          | 0/859 [00:00<00:00, 28339.89it/s, loss=0.145, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00124, train/loss_step=0.134, global_step=9.1e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142]
Epoch 106:   0%|          | 0/859 [00:00<00:00, 3019.66it/s, loss=0.145, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00124, train/loss_step=0.134, global_step=9.1e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142] 
Epoch 106:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.145, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00124, train/loss_step=0.134, global_step=9.1e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.142]
Epoch 106:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.138, v_num=38, loss_step=0.129, train/loss_simple_step=0.129, train/loss_vlb_step=0.00129, train/loss_step=0.129, global_step=91248.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 106:  47%|████▋     | 400/859 [02:12<02:31,  3.03it/s, loss=0.138, v_num=38, loss_step=0.129, train/loss_simple_step=0.129, train/loss_vlb_step=0.00129, train/loss_step=0.129, global_step=91248.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 106:  47%|████▋     | 400/859 [02:12<02:31,  3.03it/s, loss=0.141, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00343, train/loss_step=0.146, global_step=91448.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 106:  70%|██████▉   | 600/859 [03:44<01:36,  2.67it/s, loss=0.141, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00343, train/loss_step=0.146, global_step=91448.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 106:  70%|██████▉   | 600/859 [03:44<01:36,  2.67it/s, loss=0.14, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00386, train/loss_step=0.140, global_step=91648.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141] 
Epoch 106:  93%|█████████▎| 800/859 [04:51<00:21,  2.75it/s, loss=0.14, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00386, train/loss_step=0.140, global_step=91648.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 106:  93%|█████████▎| 800/859 [04:51<00:21,  2.75it/s, loss=0.139, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00177, train/loss_step=0.146, global_step=91848.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 106: 100%|██████████| 859/859 [05:10<00:00,  2.77it/s, loss=0.139, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00177, train/loss_step=0.146, global_step=91848.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 106: 100%|██████████| 859/859 [05:10<00:00,  2.77it/s, loss=0.138, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00187, train/loss_step=0.143, global_step=91907.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 106:   0%|          | 0/859 [00:00<00:00, 27962.03it/s, loss=0.138, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00187, train/loss_step=0.143, global_step=91907.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 107:   0%|          | 0/859 [00:00<00:00, 3010.99it/s, loss=0.138, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00187, train/loss_step=0.143, global_step=91907.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 107:  23%|██▎       | 200/859 [01:32<05:03,  2.17it/s, loss=0.138, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00187, train/loss_step=0.143, global_step=91907.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 107:  23%|██▎       | 200/859 [01:32<05:03,  2.17it/s, loss=0.143, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.0025, train/loss_step=0.133, global_step=92107.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]
Epoch 107:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.143, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.0025, train/loss_step=0.133, global_step=92107.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]
Epoch 107:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.141, v_num=38, loss_step=0.129, train/loss_simple_step=0.129, train/loss_vlb_step=0.00266, train/loss_step=0.129, global_step=92307.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 107:  70%|██████▉   | 600/859 [04:10<01:48,  2.40it/s, loss=0.141, v_num=38, loss_step=0.129, train/loss_simple_step=0.129, train/loss_vlb_step=0.00266, train/loss_step=0.129, global_step=92307.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]
Epoch 107:  70%|██████▉   | 600/859 [04:10<01:48,  2.40it/s, loss=0.142, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00256, train/loss_step=0.141, global_step=92507.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]
Epoch 107:  93%|█████████▎| 800/859 [05:16<00:23,  2.53it/s, loss=0.142, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00256, train/loss_step=0.141, global_step=92507.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]
Epoch 107:  93%|█████████▎| 800/859 [05:16<00:23,  2.53it/s, loss=0.144, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00168, train/loss_step=0.139, global_step=92707.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]
Epoch 107: 100%|██████████| 859/859 [05:36<00:00,  2.56it/s, loss=0.144, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00168, train/loss_step=0.139, global_step=92707.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]
Epoch 107: 100%|██████████| 859/859 [05:36<00:00,  2.56it/s, loss=0.141, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00152, train/loss_step=0.144, global_step=92766.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]
Epoch 107:   0%|          | 0/859 [00:00<00:00, 27594.11it/s, loss=0.141, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00152, train/loss_step=0.144, global_step=92766.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]
Epoch 108:   0%|          | 0/859 [00:00<00:00, 4211.15it/s, loss=0.141, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00152, train/loss_step=0.144, global_step=92766.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142] 
Epoch 108:  23%|██▎       | 200/859 [01:05<03:35,  3.05it/s, loss=0.141, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00152, train/loss_step=0.144, global_step=92766.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.142]
Epoch 108:  23%|██▎       | 200/859 [01:05<03:35,  3.05it/s, loss=0.142, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00421, train/loss_step=0.152, global_step=9.3e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 108:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.142, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00421, train/loss_step=0.152, global_step=9.3e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 108:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.144, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.0032, train/loss_step=0.139, global_step=93166.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 108:  70%|██████▉   | 600/859 [03:44<01:36,  2.68it/s, loss=0.144, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.0032, train/loss_step=0.139, global_step=93166.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 108:  70%|██████▉   | 600/859 [03:44<01:36,  2.68it/s, loss=0.143, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00108, train/loss_step=0.142, global_step=93366.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 108:  93%|█████████▎| 800/859 [05:16<00:23,  2.53it/s, loss=0.143, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00108, train/loss_step=0.142, global_step=93366.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 108:  93%|█████████▎| 800/859 [05:16<00:23,  2.53it/s, loss=0.14, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00293, train/loss_step=0.136, global_step=93566.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142] 
Epoch 108: 100%|██████████| 859/859 [05:36<00:00,  2.56it/s, loss=0.14, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00293, train/loss_step=0.136, global_step=93566.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 108: 100%|██████████| 859/859 [05:36<00:00,  2.56it/s, loss=0.141, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00521, train/loss_step=0.142, global_step=93625.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 108:   0%|          | 0/859 [00:00<00:00, 26715.31it/s, loss=0.141, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00521, train/loss_step=0.142, global_step=93625.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 109:   0%|          | 0/859 [00:00<00:00, 3013.15it/s, loss=0.141, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00521, train/loss_step=0.142, global_step=93625.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142] 
Epoch 109:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.141, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00521, train/loss_step=0.142, global_step=93625.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.142]
Epoch 109:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.142, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.0019, train/loss_step=0.145, global_step=93825.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 109:  47%|████▋     | 400/859 [02:38<03:01,  2.52it/s, loss=0.142, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.0019, train/loss_step=0.145, global_step=93825.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 109:  47%|████▋     | 400/859 [02:38<03:01,  2.52it/s, loss=0.14, v_num=38, loss_step=0.129, train/loss_simple_step=0.129, train/loss_vlb_step=0.00202, train/loss_step=0.129, global_step=9.4e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142] 
Epoch 109:  70%|██████▉   | 600/859 [03:44<01:36,  2.67it/s, loss=0.14, v_num=38, loss_step=0.129, train/loss_simple_step=0.129, train/loss_vlb_step=0.00202, train/loss_step=0.129, global_step=9.4e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 109:  70%|██████▉   | 600/859 [03:44<01:36,  2.67it/s, loss=0.14, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00207, train/loss_step=0.136, global_step=94225.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 109:  93%|█████████▎| 800/859 [04:50<00:21,  2.76it/s, loss=0.14, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00207, train/loss_step=0.136, global_step=94225.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 109:  93%|█████████▎| 800/859 [04:50<00:21,  2.76it/s, loss=0.137, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00324, train/loss_step=0.143, global_step=94425.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 109: 100%|██████████| 859/859 [05:10<00:00,  2.77it/s, loss=0.137, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00324, train/loss_step=0.143, global_step=94425.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 109: 100%|██████████| 859/859 [05:10<00:00,  2.77it/s, loss=0.143, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00231, train/loss_step=0.134, global_step=94484.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 109:   0%|          | 0/859 [00:00<00:00, 27776.85it/s, loss=0.143, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00231, train/loss_step=0.134, global_step=94484.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 110:   0%|          | 0/859 [00:00<00:00, 3802.63it/s, loss=0.143, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00231, train/loss_step=0.134, global_step=94484.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 110:  23%|██▎       | 200/859 [01:32<05:03,  2.17it/s, loss=0.143, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00231, train/loss_step=0.134, global_step=94484.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 110:  23%|██▎       | 200/859 [01:32<05:03,  2.17it/s, loss=0.141, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.0015, train/loss_step=0.144, global_step=94684.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]  
Epoch 110:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.141, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.0015, train/loss_step=0.144, global_step=94684.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 110:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.142, v_num=38, loss_step=0.159, train/loss_simple_step=0.159, train/loss_vlb_step=0.00161, train/loss_step=0.159, global_step=94884.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 110:  70%|██████▉   | 600/859 [04:11<01:48,  2.39it/s, loss=0.142, v_num=38, loss_step=0.159, train/loss_simple_step=0.159, train/loss_vlb_step=0.00161, train/loss_step=0.159, global_step=94884.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 110:  70%|██████▉   | 600/859 [04:11<01:48,  2.39it/s, loss=0.145, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00265, train/loss_step=0.145, global_step=95084.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 110:  93%|█████████▎| 800/859 [05:17<00:23,  2.52it/s, loss=0.145, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00265, train/loss_step=0.145, global_step=95084.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 110:  93%|█████████▎| 800/859 [05:17<00:23,  2.52it/s, loss=0.143, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00411, train/loss_step=0.140, global_step=95284.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 110: 100%|██████████| 859/859 [05:36<00:00,  2.55it/s, loss=0.143, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00411, train/loss_step=0.140, global_step=95284.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 110: 100%|██████████| 859/859 [05:36<00:00,  2.55it/s, loss=0.142, v_num=38, loss_step=0.129, train/loss_simple_step=0.129, train/loss_vlb_step=0.00149, train/loss_step=0.129, global_step=95343.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 110:   0%|          | 0/859 [00:00<00:00, 26546.23it/s, loss=0.142, v_num=38, loss_step=0.129, train/loss_simple_step=0.129, train/loss_vlb_step=0.00149, train/loss_step=0.129, global_step=95343.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 111:   0%|          | 0/859 [00:00<00:00, 2651.27it/s, loss=0.142, v_num=38, loss_step=0.129, train/loss_simple_step=0.129, train/loss_vlb_step=0.00149, train/loss_step=0.129, global_step=95343.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 111:  23%|██▎       | 200/859 [01:32<05:03,  2.17it/s, loss=0.142, v_num=38, loss_step=0.129, train/loss_simple_step=0.129, train/loss_vlb_step=0.00149, train/loss_step=0.129, global_step=95343.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 111:  23%|██▎       | 200/859 [01:32<05:03,  2.17it/s, loss=0.141, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00383, train/loss_step=0.143, global_step=95543.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 111:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.141, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00383, train/loss_step=0.143, global_step=95543.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 111:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.144, v_num=38, loss_step=0.126, train/loss_simple_step=0.126, train/loss_vlb_step=0.00252, train/loss_step=0.126, global_step=95743.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 111:  70%|██████▉   | 600/859 [03:44<01:36,  2.68it/s, loss=0.144, v_num=38, loss_step=0.126, train/loss_simple_step=0.126, train/loss_vlb_step=0.00252, train/loss_step=0.126, global_step=95743.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 111:  70%|██████▉   | 600/859 [03:44<01:36,  2.68it/s, loss=0.14, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00154, train/loss_step=0.138, global_step=95943.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 111:  93%|█████████▎| 800/859 [05:16<00:23,  2.53it/s, loss=0.14, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00154, train/loss_step=0.138, global_step=95943.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 111:  93%|█████████▎| 800/859 [05:16<00:23,  2.53it/s, loss=0.14, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00148, train/loss_step=0.137, global_step=96143.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 111: 100%|██████████| 859/859 [05:36<00:00,  2.56it/s, loss=0.14, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00148, train/loss_step=0.137, global_step=96143.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 111: 100%|██████████| 859/859 [05:36<00:00,  2.56it/s, loss=0.142, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00359, train/loss_step=0.148, global_step=96202.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 111:   0%|          | 0/859 [00:00<00:00, 27594.11it/s, loss=0.142, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00359, train/loss_step=0.148, global_step=96202.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 112:   0%|          | 0/859 [00:00<00:00, 4092.00it/s, loss=0.142, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00359, train/loss_step=0.148, global_step=96202.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141] 
Epoch 112:  23%|██▎       | 200/859 [01:05<03:35,  3.06it/s, loss=0.142, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00359, train/loss_step=0.148, global_step=96202.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 112:  23%|██▎       | 200/859 [01:05<03:35,  3.06it/s, loss=0.141, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00371, train/loss_step=0.144, global_step=96402.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 112:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.141, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00371, train/loss_step=0.144, global_step=96402.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.141]
Epoch 112:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.144, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00128, train/loss_step=0.132, global_step=96602.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.141]
Epoch 112:  70%|██████▉   | 600/859 [03:44<01:36,  2.68it/s, loss=0.144, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00128, train/loss_step=0.132, global_step=96602.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.141]
Epoch 112:  70%|██████▉   | 600/859 [03:44<01:36,  2.68it/s, loss=0.145, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00278, train/loss_step=0.131, global_step=96802.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 112:  93%|█████████▎| 800/859 [05:16<00:23,  2.53it/s, loss=0.145, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00278, train/loss_step=0.131, global_step=96802.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.141]
Epoch 112:  93%|█████████▎| 800/859 [05:16<00:23,  2.53it/s, loss=0.14, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.0032, train/loss_step=0.137, global_step=9.7e+4, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.141]   
Epoch 112: 100%|██████████| 859/859 [05:36<00:00,  2.56it/s, loss=0.14, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.0032, train/loss_step=0.137, global_step=9.7e+4, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.141]
Epoch 112: 100%|██████████| 859/859 [05:36<00:00,  2.56it/s, loss=0.138, v_num=38, loss_step=0.125, train/loss_simple_step=0.125, train/loss_vlb_step=0.00195, train/loss_step=0.125, global_step=97061.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.141]
Epoch 112:   0%|          | 0/859 [00:00<00:00, 28149.69it/s, loss=0.138, v_num=38, loss_step=0.125, train/loss_simple_step=0.125, train/loss_vlb_step=0.00195, train/loss_step=0.125, global_step=97061.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.141]
Epoch 113:   0%|          | 0/859 [00:00<00:00, 3956.89it/s, loss=0.138, v_num=38, loss_step=0.125, train/loss_simple_step=0.125, train/loss_vlb_step=0.00195, train/loss_step=0.125, global_step=97061.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.141] 
Epoch 113:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.138, v_num=38, loss_step=0.125, train/loss_simple_step=0.125, train/loss_vlb_step=0.00195, train/loss_step=0.125, global_step=97061.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.141]
Epoch 113:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.145, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.0029, train/loss_step=0.135, global_step=97261.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141] 
Epoch 113:  47%|████▋     | 400/859 [02:12<02:31,  3.03it/s, loss=0.145, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.0029, train/loss_step=0.135, global_step=97261.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 113:  47%|████▋     | 400/859 [02:12<02:31,  3.03it/s, loss=0.139, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00224, train/loss_step=0.135, global_step=97461.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 113:  70%|██████▉   | 600/859 [03:44<01:36,  2.68it/s, loss=0.139, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00224, train/loss_step=0.135, global_step=97461.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 113:  70%|██████▉   | 600/859 [03:44<01:36,  2.68it/s, loss=0.142, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.00148, train/loss_step=0.153, global_step=97661.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 113:  93%|█████████▎| 800/859 [04:50<00:21,  2.76it/s, loss=0.142, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.00148, train/loss_step=0.153, global_step=97661.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 113:  93%|█████████▎| 800/859 [04:50<00:21,  2.76it/s, loss=0.138, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00145, train/loss_step=0.146, global_step=97861.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 113: 100%|██████████| 859/859 [05:10<00:00,  2.77it/s, loss=0.138, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00145, train/loss_step=0.146, global_step=97861.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 113: 100%|██████████| 859/859 [05:10<00:00,  2.77it/s, loss=0.145, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00294, train/loss_step=0.148, global_step=97920.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 113:   0%|          | 0/859 [00:00<00:00, 27413.75it/s, loss=0.145, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00294, train/loss_step=0.148, global_step=97920.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 114:   0%|          | 0/859 [00:00<00:00, 3912.60it/s, loss=0.145, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00294, train/loss_step=0.148, global_step=97920.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 114:  23%|██▎       | 200/859 [01:32<05:02,  2.18it/s, loss=0.145, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00294, train/loss_step=0.148, global_step=97920.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 114:  23%|██▎       | 200/859 [01:32<05:02,  2.18it/s, loss=0.146, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00309, train/loss_step=0.147, global_step=98120.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]
Epoch 114:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.146, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00309, train/loss_step=0.147, global_step=98120.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]
Epoch 114:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.144, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00125, train/loss_step=0.137, global_step=98320.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 114:  70%|██████▉   | 600/859 [04:11<01:48,  2.39it/s, loss=0.144, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00125, train/loss_step=0.137, global_step=98320.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]
Epoch 114:  70%|██████▉   | 600/859 [04:11<01:48,  2.39it/s, loss=0.143, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00183, train/loss_step=0.138, global_step=98520.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]
Epoch 114:  93%|█████████▎| 800/859 [05:16<00:23,  2.53it/s, loss=0.143, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00183, train/loss_step=0.138, global_step=98520.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]
Epoch 114:  93%|█████████▎| 800/859 [05:16<00:23,  2.53it/s, loss=0.145, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00134, train/loss_step=0.137, global_step=98720.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]
Epoch 114: 100%|██████████| 859/859 [05:36<00:00,  2.56it/s, loss=0.145, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00134, train/loss_step=0.137, global_step=98720.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]
Epoch 114: 100%|██████████| 859/859 [05:36<00:00,  2.56it/s, loss=0.146, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00274, train/loss_step=0.141, global_step=98779.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]
Epoch 114:   0%|          | 0/859 [00:00<00:00, 25266.89it/s, loss=0.146, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00274, train/loss_step=0.141, global_step=98779.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]
Epoch 115:   0%|          | 0/859 [00:00<00:00, 2957.90it/s, loss=0.146, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00274, train/loss_step=0.141, global_step=98779.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141] 
Epoch 115:  23%|██▎       | 200/859 [01:06<03:36,  3.05it/s, loss=0.146, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00274, train/loss_step=0.141, global_step=98779.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]
Epoch 115:  23%|██▎       | 200/859 [01:06<03:36,  3.05it/s, loss=0.138, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00218, train/loss_step=0.147, global_step=9.9e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 115:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.138, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00218, train/loss_step=0.147, global_step=9.9e+4, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 115:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.141, v_num=38, loss_step=0.118, train/loss_simple_step=0.118, train/loss_vlb_step=0.0011, train/loss_step=0.118, global_step=99179.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 115:  70%|██████▉   | 600/859 [03:44<01:36,  2.68it/s, loss=0.141, v_num=38, loss_step=0.118, train/loss_simple_step=0.118, train/loss_vlb_step=0.0011, train/loss_step=0.118, global_step=99179.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 115:  70%|██████▉   | 600/859 [03:44<01:36,  2.68it/s, loss=0.146, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00267, train/loss_step=0.139, global_step=99379.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 115:  93%|█████████▎| 800/859 [05:17<00:23,  2.52it/s, loss=0.146, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00267, train/loss_step=0.139, global_step=99379.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 115:  93%|█████████▎| 800/859 [05:17<00:23,  2.52it/s, loss=0.14, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00221, train/loss_step=0.142, global_step=99579.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142] 
Epoch 115: 100%|██████████| 859/859 [05:36<00:00,  2.55it/s, loss=0.14, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00221, train/loss_step=0.142, global_step=99579.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 115: 100%|██████████| 859/859 [05:36<00:00,  2.55it/s, loss=0.143, v_num=38, loss_step=0.164, train/loss_simple_step=0.164, train/loss_vlb_step=0.00612, train/loss_step=0.164, global_step=99638.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 115:   0%|          | 0/859 [00:00<00:00, 27594.11it/s, loss=0.143, v_num=38, loss_step=0.164, train/loss_simple_step=0.164, train/loss_vlb_step=0.00612, train/loss_step=0.164, global_step=99638.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 116:   0%|          | 0/859 [00:00<00:00, 2902.63it/s, loss=0.143, v_num=38, loss_step=0.164, train/loss_simple_step=0.164, train/loss_vlb_step=0.00612, train/loss_step=0.164, global_step=99638.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142] 
Epoch 116:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.143, v_num=38, loss_step=0.164, train/loss_simple_step=0.164, train/loss_vlb_step=0.00612, train/loss_step=0.164, global_step=99638.0, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 116:  23%|██▎       | 200/859 [01:06<03:36,  3.04it/s, loss=0.141, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00339, train/loss_step=0.149, global_step=99838.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 116:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.141, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00339, train/loss_step=0.149, global_step=99838.0, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 116:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.142, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00138, train/loss_step=0.136, global_step=1e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]   
Epoch 116:  70%|██████▉   | 600/859 [03:44<01:36,  2.68it/s, loss=0.142, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00138, train/loss_step=0.136, global_step=1e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 116:  70%|██████▉   | 600/859 [03:44<01:36,  2.68it/s, loss=0.141, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00166, train/loss_step=0.137, global_step=1e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 116:  93%|█████████▎| 800/859 [04:50<00:21,  2.76it/s, loss=0.141, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00166, train/loss_step=0.137, global_step=1e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 116:  93%|█████████▎| 800/859 [04:50<00:21,  2.76it/s, loss=0.14, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00323, train/loss_step=0.130, global_step=1e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141] 
Epoch 116: 100%|██████████| 859/859 [05:09<00:00,  2.77it/s, loss=0.14, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00323, train/loss_step=0.130, global_step=1e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 116: 100%|██████████| 859/859 [05:09<00:00,  2.77it/s, loss=0.141, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.003, train/loss_step=0.153, global_step=1e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141] 
Epoch 116:   0%|          | 0/859 [00:00<00:00, 27060.03it/s, loss=0.141, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.003, train/loss_step=0.153, global_step=1e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 117:   0%|          | 0/859 [00:00<00:00, 4301.85it/s, loss=0.141, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.003, train/loss_step=0.153, global_step=1e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 117:  23%|██▎       | 200/859 [01:32<05:03,  2.17it/s, loss=0.141, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.003, train/loss_step=0.153, global_step=1e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 117:  23%|██▎       | 200/859 [01:32<05:03,  2.17it/s, loss=0.14, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00241, train/loss_step=0.145, global_step=1.01e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 117:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.14, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00241, train/loss_step=0.145, global_step=1.01e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 117:  47%|████▋     | 400/859 [02:38<03:01,  2.53it/s, loss=0.139, v_num=38, loss_step=0.158, train/loss_simple_step=0.158, train/loss_vlb_step=0.00282, train/loss_step=0.158, global_step=1.01e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 117:  70%|██████▉   | 600/859 [04:13<01:49,  2.37it/s, loss=0.139, v_num=38, loss_step=0.158, train/loss_simple_step=0.158, train/loss_vlb_step=0.00282, train/loss_step=0.158, global_step=1.01e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 117:  70%|██████▉   | 600/859 [04:13<01:49,  2.37it/s, loss=0.14, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00365, train/loss_step=0.139, global_step=1.01e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142] 
Epoch 117:  93%|█████████▎| 800/859 [05:19<00:23,  2.51it/s, loss=0.14, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00365, train/loss_step=0.139, global_step=1.01e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 117:  93%|█████████▎| 800/859 [05:19<00:23,  2.51it/s, loss=0.14, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00143, train/loss_step=0.135, global_step=1.01e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 117: 100%|██████████| 859/859 [05:39<00:00,  2.53it/s, loss=0.14, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00143, train/loss_step=0.135, global_step=1.01e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 117: 100%|██████████| 859/859 [05:39<00:00,  2.53it/s, loss=0.142, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.00253, train/loss_step=0.153, global_step=1.01e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 117:   0%|          | 0/859 [00:00<00:00, 26214.40it/s, loss=0.142, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.00253, train/loss_step=0.153, global_step=1.01e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 118:   0%|          | 0/859 [00:00<00:00, 3983.19it/s, loss=0.142, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.00253, train/loss_step=0.153, global_step=1.01e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 118:  23%|██▎       | 200/859 [01:35<05:12,  2.11it/s, loss=0.142, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.00253, train/loss_step=0.153, global_step=1.01e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 118:  23%|██▎       | 200/859 [01:35<05:12,  2.11it/s, loss=0.139, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00199, train/loss_step=0.134, global_step=1.02e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 118:  47%|████▋     | 400/859 [02:41<03:05,  2.48it/s, loss=0.139, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00199, train/loss_step=0.134, global_step=1.02e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 118:  47%|████▋     | 400/859 [02:41<03:05,  2.48it/s, loss=0.142, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00265, train/loss_step=0.146, global_step=1.02e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 118:  70%|██████▉   | 600/859 [03:48<01:38,  2.64it/s, loss=0.142, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00265, train/loss_step=0.146, global_step=1.02e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 118:  70%|██████▉   | 600/859 [03:48<01:38,  2.64it/s, loss=0.138, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00135, train/loss_step=0.147, global_step=1.02e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 118:  93%|█████████▎| 800/859 [05:22<00:23,  2.48it/s, loss=0.138, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00135, train/loss_step=0.147, global_step=1.02e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 118:  93%|█████████▎| 800/859 [05:22<00:23,  2.48it/s, loss=0.145, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00217, train/loss_step=0.136, global_step=1.02e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 118: 100%|██████████| 859/859 [05:42<00:00,  2.51it/s, loss=0.145, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00217, train/loss_step=0.136, global_step=1.02e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 118: 100%|██████████| 859/859 [05:42<00:00,  2.51it/s, loss=0.141, v_num=38, loss_step=0.126, train/loss_simple_step=0.126, train/loss_vlb_step=0.00102, train/loss_step=0.126, global_step=1.02e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 118:   0%|          | 0/859 [00:00<00:00, 25890.77it/s, loss=0.141, v_num=38, loss_step=0.126, train/loss_simple_step=0.126, train/loss_vlb_step=0.00102, train/loss_step=0.126, global_step=1.02e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 119:   0%|          | 0/859 [00:00<00:00, 3711.77it/s, loss=0.141, v_num=38, loss_step=0.126, train/loss_simple_step=0.126, train/loss_vlb_step=0.00102, train/loss_step=0.126, global_step=1.02e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141] 
Epoch 119:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.141, v_num=38, loss_step=0.126, train/loss_simple_step=0.126, train/loss_vlb_step=0.00102, train/loss_step=0.126, global_step=1.02e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 119:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.144, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.0034, train/loss_step=0.144, global_step=1.02e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 119:  47%|████▋     | 400/859 [02:41<03:04,  2.49it/s, loss=0.144, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.0034, train/loss_step=0.144, global_step=1.02e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 119:  47%|████▋     | 400/859 [02:41<03:04,  2.49it/s, loss=0.141, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00396, train/loss_step=0.151, global_step=1.03e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 119:  70%|██████▉   | 600/859 [03:47<01:38,  2.64it/s, loss=0.141, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00396, train/loss_step=0.151, global_step=1.03e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 119:  70%|██████▉   | 600/859 [03:47<01:38,  2.64it/s, loss=0.146, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00468, train/loss_step=0.142, global_step=1.03e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 119:  93%|█████████▎| 800/859 [05:22<00:23,  2.48it/s, loss=0.146, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00468, train/loss_step=0.142, global_step=1.03e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 119:  93%|█████████▎| 800/859 [05:22<00:23,  2.48it/s, loss=0.141, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00384, train/loss_step=0.146, global_step=1.03e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 119: 100%|██████████| 859/859 [05:42<00:00,  2.51it/s, loss=0.141, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00384, train/loss_step=0.146, global_step=1.03e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 119: 100%|██████████| 859/859 [05:42<00:00,  2.51it/s, loss=0.143, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00127, train/loss_step=0.140, global_step=1.03e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 119:   0%|          | 0/859 [00:00<00:00, 26546.23it/s, loss=0.143, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00127, train/loss_step=0.140, global_step=1.03e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 120:   0%|          | 0/859 [00:00<00:00, 3539.50it/s, loss=0.143, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00127, train/loss_step=0.140, global_step=1.03e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141] 
Epoch 120:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.143, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00127, train/loss_step=0.140, global_step=1.03e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 120:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.14, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00158, train/loss_step=0.144, global_step=1.03e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]  
Epoch 120:  47%|████▋     | 400/859 [02:12<02:31,  3.02it/s, loss=0.14, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00158, train/loss_step=0.144, global_step=1.03e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 120:  47%|████▋     | 400/859 [02:12<02:31,  3.02it/s, loss=0.143, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00172, train/loss_step=0.134, global_step=1.03e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 120:  70%|██████▉   | 600/859 [03:45<01:37,  2.66it/s, loss=0.143, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00172, train/loss_step=0.134, global_step=1.03e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 120:  70%|██████▉   | 600/859 [03:45<01:37,  2.66it/s, loss=0.144, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00322, train/loss_step=0.150, global_step=1.04e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 120:  93%|█████████▎| 800/859 [04:52<00:21,  2.74it/s, loss=0.144, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00322, train/loss_step=0.150, global_step=1.04e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 120:  93%|█████████▎| 800/859 [04:52<00:21,  2.74it/s, loss=0.139, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00181, train/loss_step=0.139, global_step=1.04e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 120: 100%|██████████| 859/859 [05:12<00:00,  2.75it/s, loss=0.139, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00181, train/loss_step=0.139, global_step=1.04e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 120: 100%|██████████| 859/859 [05:12<00:00,  2.75it/s, loss=0.144, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00225, train/loss_step=0.143, global_step=1.04e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 120:   0%|          | 0/859 [00:00<00:00, 22919.69it/s, loss=0.144, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00225, train/loss_step=0.143, global_step=1.04e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 121:   0%|          | 0/859 [00:00<00:00, 3184.74it/s, loss=0.144, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00225, train/loss_step=0.143, global_step=1.04e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 121:  23%|██▎       | 200/859 [01:35<05:12,  2.11it/s, loss=0.144, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00225, train/loss_step=0.143, global_step=1.04e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 121:  23%|██▎       | 200/859 [01:35<05:12,  2.11it/s, loss=0.141, v_num=38, loss_step=0.157, train/loss_simple_step=0.157, train/loss_vlb_step=0.0031, train/loss_step=0.157, global_step=1.04e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 121:  47%|████▋     | 400/859 [02:42<03:05,  2.47it/s, loss=0.141, v_num=38, loss_step=0.157, train/loss_simple_step=0.157, train/loss_vlb_step=0.0031, train/loss_step=0.157, global_step=1.04e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 121:  47%|████▋     | 400/859 [02:42<03:05,  2.47it/s, loss=0.145, v_num=38, loss_step=0.158, train/loss_simple_step=0.158, train/loss_vlb_step=0.0012, train/loss_step=0.158, global_step=1.04e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 121:  70%|██████▉   | 600/859 [04:18<01:51,  2.32it/s, loss=0.145, v_num=38, loss_step=0.158, train/loss_simple_step=0.158, train/loss_vlb_step=0.0012, train/loss_step=0.158, global_step=1.04e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 121:  70%|██████▉   | 600/859 [04:18<01:51,  2.32it/s, loss=0.14, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.0037, train/loss_step=0.148, global_step=1.05e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142] 
Epoch 121:  93%|█████████▎| 800/859 [05:25<00:23,  2.46it/s, loss=0.14, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.0037, train/loss_step=0.148, global_step=1.05e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 121:  93%|█████████▎| 800/859 [05:25<00:23,  2.46it/s, loss=0.141, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.0027, train/loss_step=0.135, global_step=1.05e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 121: 100%|██████████| 859/859 [05:45<00:00,  2.49it/s, loss=0.141, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.0027, train/loss_step=0.135, global_step=1.05e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 121: 100%|██████████| 859/859 [05:45<00:00,  2.49it/s, loss=0.142, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00226, train/loss_step=0.131, global_step=1.05e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 121:   0%|          | 0/859 [00:00<00:00, 26214.40it/s, loss=0.142, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00226, train/loss_step=0.131, global_step=1.05e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 122:   0%|          | 0/859 [00:00<00:00, 4161.02it/s, loss=0.142, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00226, train/loss_step=0.131, global_step=1.05e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142] 
Epoch 122:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.142, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00226, train/loss_step=0.131, global_step=1.05e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 122:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.136, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00153, train/loss_step=0.139, global_step=1.05e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 122:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.136, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00153, train/loss_step=0.139, global_step=1.05e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 122:  47%|████▋     | 400/859 [02:40<03:03,  2.50it/s, loss=0.139, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00131, train/loss_step=0.142, global_step=1.05e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 122:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.139, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00131, train/loss_step=0.142, global_step=1.05e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 122:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.139, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00156, train/loss_step=0.138, global_step=1.05e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 122:  93%|█████████▎| 800/859 [05:21<00:23,  2.50it/s, loss=0.139, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00156, train/loss_step=0.138, global_step=1.05e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 122:  93%|█████████▎| 800/859 [05:21<00:23,  2.50it/s, loss=0.143, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00301, train/loss_step=0.146, global_step=1.06e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 122: 100%|██████████| 859/859 [05:40<00:00,  2.53it/s, loss=0.143, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00301, train/loss_step=0.146, global_step=1.06e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 122: 100%|██████████| 859/859 [05:40<00:00,  2.53it/s, loss=0.138, v_num=38, loss_step=0.127, train/loss_simple_step=0.127, train/loss_vlb_step=0.00374, train/loss_step=0.127, global_step=1.06e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 122:   0%|          | 0/859 [00:00<00:00, 26214.40it/s, loss=0.138, v_num=38, loss_step=0.127, train/loss_simple_step=0.127, train/loss_vlb_step=0.00374, train/loss_step=0.127, global_step=1.06e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 123:   0%|          | 0/859 [00:00<00:00, 2560.63it/s, loss=0.138, v_num=38, loss_step=0.127, train/loss_simple_step=0.127, train/loss_vlb_step=0.00374, train/loss_step=0.127, global_step=1.06e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141] 
Epoch 123:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.138, v_num=38, loss_step=0.127, train/loss_simple_step=0.127, train/loss_vlb_step=0.00374, train/loss_step=0.127, global_step=1.06e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 123:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.141, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00187, train/loss_step=0.139, global_step=1.06e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 123:  47%|████▋     | 400/859 [02:40<03:04,  2.49it/s, loss=0.141, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00187, train/loss_step=0.139, global_step=1.06e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 123:  47%|████▋     | 400/859 [02:40<03:04,  2.49it/s, loss=0.14, v_num=38, loss_step=0.125, train/loss_simple_step=0.125, train/loss_vlb_step=0.00233, train/loss_step=0.125, global_step=1.06e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141] 
Epoch 123:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.14, v_num=38, loss_step=0.125, train/loss_simple_step=0.125, train/loss_vlb_step=0.00233, train/loss_step=0.125, global_step=1.06e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 123:  70%|██████▉   | 600/859 [03:46<01:37,  2.65it/s, loss=0.142, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00197, train/loss_step=0.139, global_step=1.06e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 123:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.142, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00197, train/loss_step=0.139, global_step=1.06e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 123:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.142, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00175, train/loss_step=0.130, global_step=1.06e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 123: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.142, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00175, train/loss_step=0.130, global_step=1.06e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 123: 100%|██████████| 859/859 [05:41<00:00,  2.52it/s, loss=0.144, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00409, train/loss_step=0.141, global_step=1.07e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 123:   0%|          | 0/859 [00:00<00:00, 24672.38it/s, loss=0.144, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00409, train/loss_step=0.141, global_step=1.07e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 124:   0%|          | 0/859 [00:00<00:00, 4559.03it/s, loss=0.144, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00409, train/loss_step=0.141, global_step=1.07e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141] 
Epoch 124:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.144, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00409, train/loss_step=0.141, global_step=1.07e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 124:  23%|██▎       | 200/859 [01:06<03:37,  3.03it/s, loss=0.141, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00204, train/loss_step=0.138, global_step=1.07e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 124:  47%|████▋     | 400/859 [02:12<02:31,  3.03it/s, loss=0.141, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00204, train/loss_step=0.138, global_step=1.07e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 124:  47%|████▋     | 400/859 [02:12<02:31,  3.03it/s, loss=0.139, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00267, train/loss_step=0.134, global_step=1.07e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 124:  70%|██████▉   | 600/859 [03:47<01:38,  2.64it/s, loss=0.139, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00267, train/loss_step=0.134, global_step=1.07e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 124:  70%|██████▉   | 600/859 [03:47<01:38,  2.64it/s, loss=0.14, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00321, train/loss_step=0.148, global_step=1.07e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142] 
Epoch 124:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.14, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00321, train/loss_step=0.148, global_step=1.07e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 124:  93%|█████████▎| 800/859 [04:53<00:21,  2.73it/s, loss=0.143, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.0044, train/loss_step=0.142, global_step=1.07e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 124: 100%|██████████| 859/859 [05:13<00:00,  2.75it/s, loss=0.143, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.0044, train/loss_step=0.142, global_step=1.07e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 124: 100%|██████████| 859/859 [05:13<00:00,  2.75it/s, loss=0.142, v_num=38, loss_step=0.161, train/loss_simple_step=0.161, train/loss_vlb_step=0.00265, train/loss_step=0.161, global_step=1.07e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 124:   0%|          | 0/859 [00:00<00:00, 26715.31it/s, loss=0.142, v_num=38, loss_step=0.161, train/loss_simple_step=0.161, train/loss_vlb_step=0.00265, train/loss_step=0.161, global_step=1.07e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 125:   0%|          | 0/859 [00:00<00:00, 3530.56it/s, loss=0.142, v_num=38, loss_step=0.161, train/loss_simple_step=0.161, train/loss_vlb_step=0.00265, train/loss_step=0.161, global_step=1.07e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 125:  23%|██▎       | 200/859 [01:35<05:11,  2.11it/s, loss=0.142, v_num=38, loss_step=0.161, train/loss_simple_step=0.161, train/loss_vlb_step=0.00265, train/loss_step=0.161, global_step=1.07e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00255, train/loss_epoch=0.142]
Epoch 125:  23%|██▎       | 200/859 [01:35<05:11,  2.11it/s, loss=0.141, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00165, train/loss_step=0.144, global_step=1.08e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 125:  47%|████▋     | 400/859 [02:41<03:04,  2.49it/s, loss=0.141, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00165, train/loss_step=0.144, global_step=1.08e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 125:  47%|████▋     | 400/859 [02:41<03:04,  2.49it/s, loss=0.145, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00484, train/loss_step=0.147, global_step=1.08e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 125:  70%|██████▉   | 600/859 [03:47<01:38,  2.64it/s, loss=0.145, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00484, train/loss_step=0.147, global_step=1.08e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 125:  70%|██████▉   | 600/859 [03:47<01:38,  2.64it/s, loss=0.143, v_num=38, loss_step=0.161, train/loss_simple_step=0.161, train/loss_vlb_step=0.00401, train/loss_step=0.161, global_step=1.08e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 125:  93%|█████████▎| 800/859 [05:22<00:23,  2.48it/s, loss=0.143, v_num=38, loss_step=0.161, train/loss_simple_step=0.161, train/loss_vlb_step=0.00401, train/loss_step=0.161, global_step=1.08e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 125:  93%|█████████▎| 800/859 [05:22<00:23,  2.48it/s, loss=0.144, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.000897, train/loss_step=0.142, global_step=1.08e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 125: 100%|██████████| 859/859 [05:41<00:00,  2.51it/s, loss=0.144, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.000897, train/loss_step=0.142, global_step=1.08e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 125: 100%|██████████| 859/859 [05:41<00:00,  2.51it/s, loss=0.143, v_num=38, loss_step=0.159, train/loss_simple_step=0.159, train/loss_vlb_step=0.00381, train/loss_step=0.159, global_step=1.08e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141] 
Epoch 125:   0%|          | 0/859 [00:00<00:00, 24818.37it/s, loss=0.143, v_num=38, loss_step=0.159, train/loss_simple_step=0.159, train/loss_vlb_step=0.00381, train/loss_step=0.159, global_step=1.08e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 126:   0%|          | 0/859 [00:00<00:00, 2349.75it/s, loss=0.143, v_num=38, loss_step=0.159, train/loss_simple_step=0.159, train/loss_vlb_step=0.00381, train/loss_step=0.159, global_step=1.08e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141] 
Epoch 126:  23%|██▎       | 200/859 [01:29<04:53,  2.25it/s, loss=0.143, v_num=38, loss_step=0.159, train/loss_simple_step=0.159, train/loss_vlb_step=0.00381, train/loss_step=0.159, global_step=1.08e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00248, train/loss_epoch=0.141]
Epoch 126:  23%|██▎       | 200/859 [01:29<04:53,  2.25it/s, loss=0.143, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00239, train/loss_step=0.148, global_step=1.08e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 126:  47%|████▋     | 400/859 [03:51<04:24,  1.73it/s, loss=0.143, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00239, train/loss_step=0.148, global_step=1.08e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 126:  47%|████▋     | 400/859 [03:51<04:24,  1.73it/s, loss=0.138, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00228, train/loss_step=0.132, global_step=1.09e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 126:  70%|██████▉   | 600/859 [05:41<02:27,  1.76it/s, loss=0.138, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00228, train/loss_step=0.132, global_step=1.09e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 126:  70%|██████▉   | 600/859 [05:41<02:27,  1.76it/s, loss=0.143, v_num=38, loss_step=0.128, train/loss_simple_step=0.128, train/loss_vlb_step=0.00236, train/loss_step=0.128, global_step=1.09e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 126:  93%|█████████▎| 800/859 [08:11<00:36,  1.63it/s, loss=0.143, v_num=38, loss_step=0.128, train/loss_simple_step=0.128, train/loss_vlb_step=0.00236, train/loss_step=0.128, global_step=1.09e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 126:  93%|█████████▎| 800/859 [08:11<00:36,  1.63it/s, loss=0.137, v_num=38, loss_step=0.129, train/loss_simple_step=0.129, train/loss_vlb_step=0.00271, train/loss_step=0.129, global_step=1.09e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 126: 100%|██████████| 859/859 [08:48<00:00,  1.63it/s, loss=0.137, v_num=38, loss_step=0.129, train/loss_simple_step=0.129, train/loss_vlb_step=0.00271, train/loss_step=0.129, global_step=1.09e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 126: 100%|██████████| 859/859 [08:48<00:00,  1.63it/s, loss=0.144, v_num=38, loss_step=0.127, train/loss_simple_step=0.127, train/loss_vlb_step=0.00163, train/loss_step=0.127, global_step=1.09e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 126:   0%|          | 0/859 [00:00<00:00, 15827.56it/s, loss=0.144, v_num=38, loss_step=0.127, train/loss_simple_step=0.127, train/loss_vlb_step=0.00163, train/loss_step=0.127, global_step=1.09e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 127:   0%|          | 0/859 [00:00<00:00, 1916.96it/s, loss=0.144, v_num=38, loss_step=0.127, train/loss_simple_step=0.127, train/loss_vlb_step=0.00163, train/loss_step=0.127, global_step=1.09e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142] 
Epoch 127:  23%|██▎       | 200/859 [02:04<06:46,  1.62it/s, loss=0.144, v_num=38, loss_step=0.127, train/loss_simple_step=0.127, train/loss_vlb_step=0.00163, train/loss_step=0.127, global_step=1.09e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00258, train/loss_epoch=0.142]
Epoch 127:  23%|██▎       | 200/859 [02:04<06:46,  1.62it/s, loss=0.141, v_num=38, loss_step=0.125, train/loss_simple_step=0.125, train/loss_vlb_step=0.00328, train/loss_step=0.125, global_step=1.09e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141] 
Epoch 127:  47%|████▋     | 400/859 [04:08<04:44,  1.62it/s, loss=0.141, v_num=38, loss_step=0.125, train/loss_simple_step=0.125, train/loss_vlb_step=0.00328, train/loss_step=0.125, global_step=1.09e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 127:  47%|████▋     | 400/859 [04:08<04:44,  1.62it/s, loss=0.145, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00191, train/loss_step=0.134, global_step=1.09e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 127:  70%|██████▉   | 600/859 [06:55<02:58,  1.45it/s, loss=0.145, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.00191, train/loss_step=0.134, global_step=1.09e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 127:  70%|██████▉   | 600/859 [06:55<02:58,  1.45it/s, loss=0.143, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00368, train/loss_step=0.141, global_step=1.1e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141] 
Epoch 127:  93%|█████████▎| 800/859 [08:58<00:39,  1.49it/s, loss=0.143, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00368, train/loss_step=0.141, global_step=1.1e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 127:  93%|█████████▎| 800/859 [08:58<00:39,  1.49it/s, loss=0.144, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00154, train/loss_step=0.132, global_step=1.1e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 127: 100%|██████████| 859/859 [09:34<00:00,  1.50it/s, loss=0.144, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00154, train/loss_step=0.132, global_step=1.1e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 127: 100%|██████████| 859/859 [09:34<00:00,  1.50it/s, loss=0.137, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00246, train/loss_step=0.130, global_step=1.1e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 127:   0%|          | 0/859 [00:00<00:00, 15947.92it/s, loss=0.137, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00246, train/loss_step=0.130, global_step=1.1e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 128:   0%|          | 0/859 [00:00<00:00, 1814.93it/s, loss=0.137, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00246, train/loss_step=0.130, global_step=1.1e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 128:  23%|██▎       | 200/859 [02:47<09:09,  1.20it/s, loss=0.137, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00246, train/loss_step=0.130, global_step=1.1e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 128:  23%|██▎       | 200/859 [02:47<09:09,  1.20it/s, loss=0.142, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00473, train/loss_step=0.146, global_step=1.1e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 128:  47%|████▋     | 400/859 [04:52<05:34,  1.37it/s, loss=0.142, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00473, train/loss_step=0.146, global_step=1.1e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 128:  47%|████▋     | 400/859 [04:52<05:34,  1.37it/s, loss=0.141, v_num=38, loss_step=0.123, train/loss_simple_step=0.123, train/loss_vlb_step=0.00171, train/loss_step=0.123, global_step=1.1e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 128:  70%|██████▉   | 600/859 [07:39<03:18,  1.31it/s, loss=0.141, v_num=38, loss_step=0.123, train/loss_simple_step=0.123, train/loss_vlb_step=0.00171, train/loss_step=0.123, global_step=1.1e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 128:  70%|██████▉   | 600/859 [07:39<03:18,  1.31it/s, loss=0.141, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.0023, train/loss_step=0.143, global_step=1.11e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 128:  93%|█████████▎| 800/859 [09:43<00:43,  1.37it/s, loss=0.141, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.0023, train/loss_step=0.143, global_step=1.11e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 128:  93%|█████████▎| 800/859 [09:43<00:43,  1.37it/s, loss=0.142, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.0013, train/loss_step=0.153, global_step=1.11e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 128: 100%|██████████| 859/859 [10:20<00:00,  1.39it/s, loss=0.142, v_num=38, loss_step=0.153, train/loss_simple_step=0.153, train/loss_vlb_step=0.0013, train/loss_step=0.153, global_step=1.11e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 128: 100%|██████████| 859/859 [10:20<00:00,  1.39it/s, loss=0.144, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00424, train/loss_step=0.141, global_step=1.11e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 128:   0%|          | 0/859 [00:00<00:00, 16384.00it/s, loss=0.144, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00424, train/loss_step=0.141, global_step=1.11e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 129:   0%|          | 0/859 [00:00<00:00, 2095.06it/s, loss=0.144, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00424, train/loss_step=0.141, global_step=1.11e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 129:  23%|██▎       | 200/859 [02:48<09:14,  1.19it/s, loss=0.144, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00424, train/loss_step=0.141, global_step=1.11e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 129:  23%|██▎       | 200/859 [02:48<09:14,  1.19it/s, loss=0.138, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00127, train/loss_step=0.148, global_step=1.11e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.141]
Epoch 129:  47%|████▋     | 400/859 [04:52<05:34,  1.37it/s, loss=0.138, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00127, train/loss_step=0.148, global_step=1.11e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.141]
Epoch 129:  47%|████▋     | 400/859 [04:52<05:34,  1.37it/s, loss=0.14, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00322, train/loss_step=0.136, global_step=1.11e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.141] 
Epoch 129:  70%|██████▉   | 600/859 [06:55<02:59,  1.45it/s, loss=0.14, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00322, train/loss_step=0.136, global_step=1.11e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.141]
Epoch 129:  70%|██████▉   | 600/859 [06:55<02:59,  1.45it/s, loss=0.143, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00396, train/loss_step=0.149, global_step=1.11e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 129:  93%|█████████▎| 800/859 [09:42<00:42,  1.38it/s, loss=0.143, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00396, train/loss_step=0.149, global_step=1.11e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.141]
Epoch 129:  93%|█████████▎| 800/859 [09:42<00:42,  1.38it/s, loss=0.142, v_num=38, loss_step=0.129, train/loss_simple_step=0.129, train/loss_vlb_step=0.00125, train/loss_step=0.129, global_step=1.12e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.141]
Epoch 129: 100%|██████████| 859/859 [10:19<00:00,  1.39it/s, loss=0.142, v_num=38, loss_step=0.129, train/loss_simple_step=0.129, train/loss_vlb_step=0.00125, train/loss_step=0.129, global_step=1.12e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.141]
Epoch 129: 100%|██████████| 859/859 [10:19<00:00,  1.39it/s, loss=0.144, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00285, train/loss_step=0.130, global_step=1.12e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.141]
Epoch 129:   0%|          | 0/859 [00:00<00:00, 17772.47it/s, loss=0.144, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00285, train/loss_step=0.130, global_step=1.12e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.141]
Epoch 130:   0%|          | 0/859 [00:00<00:00, 1277.19it/s, loss=0.144, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00285, train/loss_step=0.130, global_step=1.12e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.141] 
Epoch 130:  23%|██▎       | 200/859 [02:04<06:47,  1.62it/s, loss=0.144, v_num=38, loss_step=0.130, train/loss_simple_step=0.130, train/loss_vlb_step=0.00285, train/loss_step=0.130, global_step=1.12e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00247, train/loss_epoch=0.141]
Epoch 130:  23%|██▎       | 200/859 [02:04<06:47,  1.62it/s, loss=0.142, v_num=38, loss_step=0.126, train/loss_simple_step=0.126, train/loss_vlb_step=0.00237, train/loss_step=0.126, global_step=1.12e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 130:  47%|████▋     | 400/859 [04:49<05:31,  1.38it/s, loss=0.142, v_num=38, loss_step=0.126, train/loss_simple_step=0.126, train/loss_vlb_step=0.00237, train/loss_step=0.126, global_step=1.12e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 130:  47%|████▋     | 400/859 [04:49<05:31,  1.38it/s, loss=0.137, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00179, train/loss_step=0.133, global_step=1.12e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 130:  70%|██████▉   | 600/859 [06:53<02:58,  1.45it/s, loss=0.137, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00179, train/loss_step=0.133, global_step=1.12e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 130:  70%|██████▉   | 600/859 [06:53<02:58,  1.45it/s, loss=0.141, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00105, train/loss_step=0.139, global_step=1.12e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 130:  93%|█████████▎| 800/859 [08:56<00:39,  1.49it/s, loss=0.141, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00105, train/loss_step=0.139, global_step=1.12e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 130:  93%|█████████▎| 800/859 [08:56<00:39,  1.49it/s, loss=0.141, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00161, train/loss_step=0.132, global_step=1.12e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 130: 100%|██████████| 859/859 [10:17<00:00,  1.39it/s, loss=0.141, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00161, train/loss_step=0.132, global_step=1.12e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 130: 100%|██████████| 859/859 [10:17<00:00,  1.39it/s, loss=0.14, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00435, train/loss_step=0.142, global_step=1.13e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142] 
Epoch 130:   0%|          | 0/859 [00:00<00:00, 15768.06it/s, loss=0.14, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00435, train/loss_step=0.142, global_step=1.13e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 131:   0%|          | 0/859 [00:00<00:00, 985.27it/s, loss=0.14, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00435, train/loss_step=0.142, global_step=1.13e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]  
Epoch 131:  23%|██▎       | 200/859 [02:04<06:47,  1.62it/s, loss=0.14, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00435, train/loss_step=0.142, global_step=1.13e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 131:  23%|██▎       | 200/859 [02:04<06:47,  1.62it/s, loss=0.144, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00178, train/loss_step=0.142, global_step=1.13e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 131:  47%|████▋     | 400/859 [04:08<04:44,  1.62it/s, loss=0.144, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00178, train/loss_step=0.142, global_step=1.13e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 131:  47%|████▋     | 400/859 [04:08<04:44,  1.62it/s, loss=0.141, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00137, train/loss_step=0.137, global_step=1.13e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 131:  70%|██████▉   | 600/859 [06:55<02:59,  1.45it/s, loss=0.141, v_num=38, loss_step=0.137, train/loss_simple_step=0.137, train/loss_vlb_step=0.00137, train/loss_step=0.137, global_step=1.13e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 131:  70%|██████▉   | 600/859 [06:55<02:59,  1.45it/s, loss=0.143, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00249, train/loss_step=0.132, global_step=1.13e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 131:  93%|█████████▎| 800/859 [08:59<00:39,  1.48it/s, loss=0.143, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00249, train/loss_step=0.132, global_step=1.13e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 131:  93%|█████████▎| 800/859 [08:59<00:39,  1.48it/s, loss=0.145, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00185, train/loss_step=0.133, global_step=1.13e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 131: 100%|██████████| 859/859 [09:36<00:00,  1.49it/s, loss=0.145, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00185, train/loss_step=0.133, global_step=1.13e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 131: 100%|██████████| 859/859 [09:36<00:00,  1.49it/s, loss=0.143, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.0025, train/loss_step=0.135, global_step=1.13e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142] 
Epoch 131:   0%|          | 0/859 [00:00<00:00, 14122.24it/s, loss=0.143, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.0025, train/loss_step=0.135, global_step=1.13e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 132:   0%|          | 0/859 [00:00<00:00, 892.98it/s, loss=0.143, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.0025, train/loss_step=0.135, global_step=1.13e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]  pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 132:  23%|██▎       | 200/859 [02:47<09:08,  1.20it/s, loss=0.143, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.0025, train/loss_step=0.135, global_step=1.13e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 132:  23%|██▎       | 200/859 [02:47<09:08,  1.20it/s, loss=0.14, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00189, train/loss_step=0.132, global_step=1.14e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 132:  47%|████▋     | 400/859 [04:50<05:32,  1.38it/s, loss=0.14, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00189, train/loss_step=0.132, global_step=1.14e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 132:  47%|████▋     | 400/859 [04:50<05:32,  1.38it/s, loss=0.146, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00326, train/loss_step=0.147, global_step=1.14e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 132:  70%|██████▉   | 600/859 [06:54<02:58,  1.45it/s, loss=0.146, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00326, train/loss_step=0.147, global_step=1.14e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 132:  70%|██████▉   | 600/859 [06:54<02:58,  1.45it/s, loss=0.143, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00168, train/loss_step=0.136, global_step=1.14e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 132:  93%|█████████▎| 800/859 [09:40<00:42,  1.38it/s, loss=0.143, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00168, train/loss_step=0.136, global_step=1.14e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 132:  93%|█████████▎| 800/859 [09:40<00:42,  1.38it/s, loss=0.138, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00171, train/loss_step=0.136, global_step=1.14e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 132: 100%|██████████| 859/859 [10:16<00:00,  1.39it/s, loss=0.138, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00171, train/loss_step=0.136, global_step=1.14e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 132: 100%|██████████| 859/859 [10:16<00:00,  1.39it/s, loss=0.141, v_num=38, loss_step=0.155, train/loss_simple_step=0.155, train/loss_vlb_step=0.00175, train/loss_step=0.155, global_step=1.14e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 132:   0%|          | 0/859 [00:00<00:00, 9198.04it/s, loss=0.141, v_num=38, loss_step=0.155, train/loss_simple_step=0.155, train/loss_vlb_step=0.00175, train/loss_step=0.155, global_step=1.14e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 133:   0%|          | 0/859 [00:00<00:01, 797.85it/s, loss=0.141, v_num=38, loss_step=0.155, train/loss_simple_step=0.155, train/loss_vlb_step=0.00175, train/loss_step=0.155, global_step=1.14e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142] 
Epoch 133:  23%|██▎       | 200/859 [02:03<06:46,  1.62it/s, loss=0.141, v_num=38, loss_step=0.155, train/loss_simple_step=0.155, train/loss_vlb_step=0.00175, train/loss_step=0.155, global_step=1.14e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.142]
Epoch 133:  23%|██▎       | 200/859 [02:03<06:46,  1.62it/s, loss=0.141, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.0015, train/loss_step=0.139, global_step=1.14e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]  pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 133:  47%|████▋     | 400/859 [04:51<05:33,  1.38it/s, loss=0.141, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.0015, train/loss_step=0.139, global_step=1.14e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 133:  47%|████▋     | 400/859 [04:51<05:33,  1.38it/s, loss=0.142, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.0054, train/loss_step=0.145, global_step=1.15e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 133:  70%|██████▉   | 600/859 [06:55<02:59,  1.45it/s, loss=0.142, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.0054, train/loss_step=0.145, global_step=1.15e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 133:  70%|██████▉   | 600/859 [06:55<02:59,  1.45it/s, loss=0.141, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00337, train/loss_step=0.149, global_step=1.15e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 133:  93%|█████████▎| 800/859 [09:44<00:43,  1.37it/s, loss=0.141, v_num=38, loss_step=0.149, train/loss_simple_step=0.149, train/loss_vlb_step=0.00337, train/loss_step=0.149, global_step=1.15e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 133:  93%|█████████▎| 800/859 [09:44<00:43,  1.37it/s, loss=0.144, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00364, train/loss_step=0.141, global_step=1.15e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 133: 100%|██████████| 859/859 [10:20<00:00,  1.39it/s, loss=0.144, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00364, train/loss_step=0.141, global_step=1.15e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 133: 100%|██████████| 859/859 [10:20<00:00,  1.39it/s, loss=0.139, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.0024, train/loss_step=0.143, global_step=1.15e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141] 
Epoch 133:   0%|          | 0/859 [00:00<00:00, 13617.87it/s, loss=0.139, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.0024, train/loss_step=0.143, global_step=1.15e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 134:   0%|          | 0/859 [00:00<00:00, 1029.78it/s, loss=0.139, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.0024, train/loss_step=0.143, global_step=1.15e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141] 
Epoch 134:  23%|██▎       | 200/859 [02:03<06:43,  1.63it/s, loss=0.139, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.0024, train/loss_step=0.143, global_step=1.15e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 134:  23%|██▎       | 200/859 [02:03<06:43,  1.63it/s, loss=0.139, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00155, train/loss_step=0.136, global_step=1.15e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 134:  47%|████▋     | 400/859 [04:50<05:32,  1.38it/s, loss=0.139, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00155, train/loss_step=0.136, global_step=1.15e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]
Epoch 134:  47%|████▋     | 400/859 [04:50<05:32,  1.38it/s, loss=0.142, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00185, train/loss_step=0.147, global_step=1.16e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]
Epoch 134:  70%|██████▉   | 600/859 [06:53<02:58,  1.45it/s, loss=0.142, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00185, train/loss_step=0.147, global_step=1.16e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]
Epoch 134:  70%|██████▉   | 600/859 [06:53<02:58,  1.45it/s, loss=0.142, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00306, train/loss_step=0.151, global_step=1.16e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]
Epoch 134:  93%|█████████▎| 800/859 [08:58<00:39,  1.49it/s, loss=0.142, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00306, train/loss_step=0.151, global_step=1.16e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]
Epoch 134:  93%|█████████▎| 800/859 [08:58<00:39,  1.49it/s, loss=0.142, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00183, train/loss_step=0.139, global_step=1.16e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]
Epoch 134: 100%|██████████| 859/859 [09:35<00:00,  1.49it/s, loss=0.142, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00183, train/loss_step=0.139, global_step=1.16e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]
Epoch 134: 100%|██████████| 859/859 [09:35<00:00,  1.49it/s, loss=0.142, v_num=38, loss_step=0.126, train/loss_simple_step=0.126, train/loss_vlb_step=0.00111, train/loss_step=0.126, global_step=1.16e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]
Epoch 134:   0%|          | 0/859 [00:00<00:00, 21959.71it/s, loss=0.142, v_num=38, loss_step=0.126, train/loss_simple_step=0.126, train/loss_vlb_step=0.00111, train/loss_step=0.126, global_step=1.16e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]
Epoch 135:   0%|          | 0/859 [00:00<00:00, 1885.93it/s, loss=0.142, v_num=38, loss_step=0.126, train/loss_simple_step=0.126, train/loss_vlb_step=0.00111, train/loss_step=0.126, global_step=1.16e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 135:  23%|██▎       | 200/859 [02:47<09:07,  1.20it/s, loss=0.142, v_num=38, loss_step=0.126, train/loss_simple_step=0.126, train/loss_vlb_step=0.00111, train/loss_step=0.126, global_step=1.16e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00257, train/loss_epoch=0.142]
Epoch 135:  23%|██▎       | 200/859 [02:47<09:07,  1.20it/s, loss=0.144, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00255, train/loss_step=0.152, global_step=1.16e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 135:  47%|████▋     | 400/859 [04:51<05:33,  1.38it/s, loss=0.144, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00255, train/loss_step=0.152, global_step=1.16e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 135:  47%|████▋     | 400/859 [04:51<05:33,  1.38it/s, loss=0.141, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00297, train/loss_step=0.150, global_step=1.16e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 135:  70%|██████▉   | 600/859 [07:43<03:19,  1.30it/s, loss=0.141, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.00297, train/loss_step=0.150, global_step=1.16e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 135:  70%|██████▉   | 600/859 [07:43<03:19,  1.30it/s, loss=0.14, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00167, train/loss_step=0.136, global_step=1.17e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141] 
Epoch 135:  93%|█████████▎| 800/859 [09:47<00:43,  1.36it/s, loss=0.14, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00167, train/loss_step=0.136, global_step=1.17e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 135:  93%|█████████▎| 800/859 [09:47<00:43,  1.36it/s, loss=0.141, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00169, train/loss_step=0.147, global_step=1.17e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 135: 100%|██████████| 859/859 [10:24<00:00,  1.38it/s, loss=0.141, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00169, train/loss_step=0.147, global_step=1.17e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 135: 100%|██████████| 859/859 [10:24<00:00,  1.38it/s, loss=0.143, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00213, train/loss_step=0.141, global_step=1.17e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 135:   0%|          | 0/859 [00:00<00:00, 15827.56it/s, loss=0.143, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00213, train/loss_step=0.141, global_step=1.17e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 136:   0%|          | 0/859 [00:00<00:00, 1992.54it/s, loss=0.143, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00213, train/loss_step=0.141, global_step=1.17e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 136:  23%|██▎       | 200/859 [02:51<09:21,  1.17it/s, loss=0.143, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00213, train/loss_step=0.141, global_step=1.17e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 136:  23%|██▎       | 200/859 [02:51<09:21,  1.17it/s, loss=0.144, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00201, train/loss_step=0.147, global_step=1.17e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]
Epoch 136:  47%|████▋     | 400/859 [04:54<05:37,  1.36it/s, loss=0.144, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00201, train/loss_step=0.147, global_step=1.17e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]
Epoch 136:  47%|████▋     | 400/859 [04:54<05:37,  1.36it/s, loss=0.145, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00245, train/loss_step=0.144, global_step=1.17e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]
Epoch 136:  70%|██████▉   | 600/859 [06:58<03:00,  1.44it/s, loss=0.145, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00245, train/loss_step=0.144, global_step=1.17e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]
Epoch 136:  70%|██████▉   | 600/859 [06:58<03:00,  1.44it/s, loss=0.141, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.0023, train/loss_step=0.134, global_step=1.17e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 136:  93%|█████████▎| 800/859 [09:47<00:43,  1.36it/s, loss=0.141, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.0023, train/loss_step=0.134, global_step=1.17e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]
Epoch 136:  93%|█████████▎| 800/859 [09:47<00:43,  1.36it/s, loss=0.139, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00274, train/loss_step=0.139, global_step=1.18e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]
Epoch 136: 100%|██████████| 859/859 [10:24<00:00,  1.38it/s, loss=0.139, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00274, train/loss_step=0.139, global_step=1.18e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]
Epoch 136: 100%|██████████| 859/859 [10:24<00:00,  1.38it/s, loss=0.144, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00275, train/loss_step=0.138, global_step=1.18e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]
Epoch 136:   0%|          | 0/859 [00:00<00:00, 13751.82it/s, loss=0.144, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00275, train/loss_step=0.138, global_step=1.18e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]
Epoch 137:   0%|          | 0/859 [00:00<00:00, 998.88it/s, loss=0.144, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00275, train/loss_step=0.138, global_step=1.18e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]  
Epoch 137:  23%|██▎       | 200/859 [02:04<06:46,  1.62it/s, loss=0.144, v_num=38, loss_step=0.138, train/loss_simple_step=0.138, train/loss_vlb_step=0.00275, train/loss_step=0.138, global_step=1.18e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]
Epoch 137:  23%|██▎       | 200/859 [02:04<06:46,  1.62it/s, loss=0.14, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.0028, train/loss_step=0.150, global_step=1.18e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]  pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 137:  47%|████▋     | 400/859 [04:51<05:33,  1.38it/s, loss=0.14, v_num=38, loss_step=0.150, train/loss_simple_step=0.150, train/loss_vlb_step=0.0028, train/loss_step=0.150, global_step=1.18e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 137:  47%|████▋     | 400/859 [04:51<05:33,  1.38it/s, loss=0.141, v_num=38, loss_step=0.125, train/loss_simple_step=0.125, train/loss_vlb_step=0.00102, train/loss_step=0.125, global_step=1.18e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 137:  70%|██████▉   | 600/859 [06:55<02:59,  1.45it/s, loss=0.141, v_num=38, loss_step=0.125, train/loss_simple_step=0.125, train/loss_vlb_step=0.00102, train/loss_step=0.125, global_step=1.18e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 137:  70%|██████▉   | 600/859 [06:55<02:59,  1.45it/s, loss=0.136, v_num=38, loss_step=0.161, train/loss_simple_step=0.161, train/loss_vlb_step=0.00292, train/loss_step=0.161, global_step=1.18e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 137:  93%|█████████▎| 800/859 [08:59<00:39,  1.48it/s, loss=0.136, v_num=38, loss_step=0.161, train/loss_simple_step=0.161, train/loss_vlb_step=0.00292, train/loss_step=0.161, global_step=1.18e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 137:  93%|█████████▎| 800/859 [08:59<00:39,  1.48it/s, loss=0.142, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00192, train/loss_step=0.135, global_step=1.18e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 137: 100%|██████████| 859/859 [10:18<00:00,  1.39it/s, loss=0.142, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00192, train/loss_step=0.135, global_step=1.18e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 137: 100%|██████████| 859/859 [10:18<00:00,  1.39it/s, loss=0.142, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00224, train/loss_step=0.132, global_step=1.19e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 137:   0%|          | 0/859 [00:00<00:00, 21732.15it/s, loss=0.142, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00224, train/loss_step=0.132, global_step=1.19e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 138:   0%|          | 0/859 [00:00<00:00, 1824.40it/s, loss=0.142, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00224, train/loss_step=0.132, global_step=1.19e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141] 
Epoch 138:  23%|██▎       | 200/859 [02:03<06:46,  1.62it/s, loss=0.142, v_num=38, loss_step=0.132, train/loss_simple_step=0.132, train/loss_vlb_step=0.00224, train/loss_step=0.132, global_step=1.19e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.141]
Epoch 138:  23%|██▎       | 200/859 [02:03<06:46,  1.62it/s, loss=0.14, v_num=38, loss_step=0.154, train/loss_simple_step=0.154, train/loss_vlb_step=0.00467, train/loss_step=0.154, global_step=1.19e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141] 
Epoch 138:  47%|████▋     | 400/859 [04:08<04:44,  1.61it/s, loss=0.14, v_num=38, loss_step=0.154, train/loss_simple_step=0.154, train/loss_vlb_step=0.00467, train/loss_step=0.154, global_step=1.19e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]
Epoch 138:  47%|████▋     | 400/859 [04:08<04:44,  1.61it/s, loss=0.144, v_num=38, loss_step=0.165, train/loss_simple_step=0.165, train/loss_vlb_step=0.00208, train/loss_step=0.165, global_step=1.19e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 138:  70%|██████▉   | 600/859 [06:56<02:59,  1.44it/s, loss=0.144, v_num=38, loss_step=0.165, train/loss_simple_step=0.165, train/loss_vlb_step=0.00208, train/loss_step=0.165, global_step=1.19e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]
Epoch 138:  70%|██████▉   | 600/859 [06:56<02:59,  1.44it/s, loss=0.143, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00334, train/loss_step=0.144, global_step=1.19e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]
Epoch 138:  93%|█████████▎| 800/859 [09:00<00:39,  1.48it/s, loss=0.143, v_num=38, loss_step=0.144, train/loss_simple_step=0.144, train/loss_vlb_step=0.00334, train/loss_step=0.144, global_step=1.19e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]
Epoch 138:  93%|█████████▎| 800/859 [09:00<00:39,  1.48it/s, loss=0.147, v_num=38, loss_step=0.162, train/loss_simple_step=0.162, train/loss_vlb_step=0.0028, train/loss_step=0.162, global_step=1.19e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141] 
Epoch 138: 100%|██████████| 859/859 [09:37<00:00,  1.49it/s, loss=0.147, v_num=38, loss_step=0.162, train/loss_simple_step=0.162, train/loss_vlb_step=0.0028, train/loss_step=0.162, global_step=1.19e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]
Epoch 138: 100%|██████████| 859/859 [09:37<00:00,  1.49it/s, loss=0.146, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00399, train/loss_step=0.151, global_step=1.19e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]
Epoch 138:   0%|          | 0/859 [00:00<00:00, 14716.86it/s, loss=0.146, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00399, train/loss_step=0.151, global_step=1.19e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]
Epoch 139:   0%|          | 0/859 [00:00<00:00, 874.72it/s, loss=0.146, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00399, train/loss_step=0.151, global_step=1.19e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]  pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 139:  23%|██▎       | 200/859 [02:48<09:13,  1.19it/s, loss=0.146, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00399, train/loss_step=0.151, global_step=1.19e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00253, train/loss_epoch=0.141]
Epoch 139:  23%|██▎       | 200/859 [02:48<09:13,  1.19it/s, loss=0.146, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00245, train/loss_step=0.142, global_step=1.2e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142] 
Epoch 139:  47%|████▋     | 400/859 [04:53<05:35,  1.37it/s, loss=0.146, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00245, train/loss_step=0.142, global_step=1.2e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 139:  47%|████▋     | 400/859 [04:53<05:35,  1.37it/s, loss=0.137, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00329, train/loss_step=0.152, global_step=1.2e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 139:  70%|██████▉   | 600/859 [06:56<02:59,  1.44it/s, loss=0.137, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00329, train/loss_step=0.152, global_step=1.2e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 139:  70%|██████▉   | 600/859 [06:56<02:59,  1.44it/s, loss=0.14, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00306, train/loss_step=0.141, global_step=1.2e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 139:  93%|█████████▎| 800/859 [09:45<00:43,  1.37it/s, loss=0.14, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00306, train/loss_step=0.141, global_step=1.2e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 139:  93%|█████████▎| 800/859 [09:45<00:43,  1.37it/s, loss=0.141, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00411, train/loss_step=0.147, global_step=1.2e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 139: 100%|██████████| 859/859 [10:22<00:00,  1.38it/s, loss=0.141, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00411, train/loss_step=0.147, global_step=1.2e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 139: 100%|██████████| 859/859 [10:22<00:00,  1.38it/s, loss=0.142, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00334, train/loss_step=0.133, global_step=1.2e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 139:   0%|          | 0/859 [00:00<00:00, 19328.59it/s, loss=0.142, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00334, train/loss_step=0.133, global_step=1.2e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 140:   0%|          | 0/859 [00:00<00:00, 1250.17it/s, loss=0.142, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00334, train/loss_step=0.133, global_step=1.2e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142] 
Epoch 140:  23%|██▎       | 200/859 [02:03<06:45,  1.63it/s, loss=0.142, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.00334, train/loss_step=0.133, global_step=1.2e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.142]
Epoch 140:  23%|██▎       | 200/859 [02:03<06:45,  1.63it/s, loss=0.143, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00521, train/loss_step=0.142, global_step=1.2e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 140:  47%|████▋     | 400/859 [04:49<05:31,  1.38it/s, loss=0.143, v_num=38, loss_step=0.142, train/loss_simple_step=0.142, train/loss_vlb_step=0.00521, train/loss_step=0.142, global_step=1.2e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 140:  47%|████▋     | 400/859 [04:49<05:31,  1.38it/s, loss=0.141, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00154, train/loss_step=0.152, global_step=1.21e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 140:  70%|██████▉   | 600/859 [06:53<02:58,  1.45it/s, loss=0.141, v_num=38, loss_step=0.152, train/loss_simple_step=0.152, train/loss_vlb_step=0.00154, train/loss_step=0.152, global_step=1.21e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 140:  70%|██████▉   | 600/859 [06:53<02:58,  1.45it/s, loss=0.145, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00351, train/loss_step=0.147, global_step=1.21e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 140:  93%|█████████▎| 800/859 [09:38<00:42,  1.38it/s, loss=0.145, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00351, train/loss_step=0.147, global_step=1.21e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 140:  93%|█████████▎| 800/859 [09:38<00:42,  1.38it/s, loss=0.141, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00213, train/loss_step=0.136, global_step=1.21e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 140: 100%|██████████| 859/859 [10:15<00:00,  1.40it/s, loss=0.141, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00213, train/loss_step=0.136, global_step=1.21e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 140: 100%|██████████| 859/859 [10:15<00:00,  1.40it/s, loss=0.142, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00143, train/loss_step=0.145, global_step=1.21e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 140:   0%|          | 0/859 [00:00<00:00, 16844.59it/s, loss=0.142, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00143, train/loss_step=0.145, global_step=1.21e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 141:   0%|          | 0/859 [00:00<00:00, 1097.70it/s, loss=0.142, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00143, train/loss_step=0.145, global_step=1.21e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141] 
Epoch 141:  23%|██▎       | 200/859 [02:03<06:46,  1.62it/s, loss=0.142, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00143, train/loss_step=0.145, global_step=1.21e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 141:  23%|██▎       | 200/859 [02:03<06:46,  1.62it/s, loss=0.144, v_num=38, loss_step=0.160, train/loss_simple_step=0.160, train/loss_vlb_step=0.00439, train/loss_step=0.160, global_step=1.21e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 141:  47%|████▋     | 400/859 [04:49<05:31,  1.39it/s, loss=0.144, v_num=38, loss_step=0.160, train/loss_simple_step=0.160, train/loss_vlb_step=0.00439, train/loss_step=0.160, global_step=1.21e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.141]
Epoch 141:  47%|████▋     | 400/859 [04:49<05:31,  1.39it/s, loss=0.142, v_num=38, loss_step=0.125, train/loss_simple_step=0.125, train/loss_vlb_step=0.00191, train/loss_step=0.125, global_step=1.22e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.141]
Epoch 141:  70%|██████▉   | 600/859 [06:52<02:57,  1.46it/s, loss=0.142, v_num=38, loss_step=0.125, train/loss_simple_step=0.125, train/loss_vlb_step=0.00191, train/loss_step=0.125, global_step=1.22e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.141]
Epoch 141:  70%|██████▉   | 600/859 [06:52<02:57,  1.46it/s, loss=0.144, v_num=38, loss_step=0.172, train/loss_simple_step=0.172, train/loss_vlb_step=0.00313, train/loss_step=0.172, global_step=1.22e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.141]
Epoch 141:  93%|█████████▎| 800/859 [08:56<00:39,  1.49it/s, loss=0.144, v_num=38, loss_step=0.172, train/loss_simple_step=0.172, train/loss_vlb_step=0.00313, train/loss_step=0.172, global_step=1.22e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.141]
Epoch 141:  93%|█████████▎| 800/859 [08:56<00:39,  1.49it/s, loss=0.14, v_num=38, loss_step=0.175, train/loss_simple_step=0.175, train/loss_vlb_step=0.00248, train/loss_step=0.175, global_step=1.22e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.141] 
Epoch 141: 100%|██████████| 859/859 [09:33<00:00,  1.50it/s, loss=0.14, v_num=38, loss_step=0.175, train/loss_simple_step=0.175, train/loss_vlb_step=0.00248, train/loss_step=0.175, global_step=1.22e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.141]
Epoch 141: 100%|██████████| 859/859 [09:33<00:00,  1.50it/s, loss=0.141, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00485, train/loss_step=0.143, global_step=1.22e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.141]
Epoch 141:   0%|          | 0/859 [00:00<00:00, 18808.54it/s, loss=0.141, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00485, train/loss_step=0.143, global_step=1.22e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.141]
Epoch 142:   0%|          | 0/859 [00:00<00:00, 1395.78it/s, loss=0.141, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00485, train/loss_step=0.143, global_step=1.22e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.141] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 142:  23%|██▎       | 200/859 [02:45<09:01,  1.22it/s, loss=0.141, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00485, train/loss_step=0.143, global_step=1.22e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00256, train/loss_epoch=0.141]
Epoch 142:  23%|██▎       | 200/859 [02:45<09:01,  1.22it/s, loss=0.142, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00201, train/loss_step=0.141, global_step=1.22e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 142:  47%|████▋     | 400/859 [04:49<05:31,  1.39it/s, loss=0.142, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00201, train/loss_step=0.141, global_step=1.22e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 142:  47%|████▋     | 400/859 [04:49<05:31,  1.39it/s, loss=0.143, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00215, train/loss_step=0.141, global_step=1.22e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 142:  70%|██████▉   | 600/859 [07:35<03:16,  1.32it/s, loss=0.143, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00215, train/loss_step=0.141, global_step=1.22e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 142:  70%|██████▉   | 600/859 [07:35<03:16,  1.32it/s, loss=0.14, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.0023, train/loss_step=0.134, global_step=1.23e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]  
Epoch 142:  93%|█████████▎| 800/859 [09:38<00:42,  1.38it/s, loss=0.14, v_num=38, loss_step=0.134, train/loss_simple_step=0.134, train/loss_vlb_step=0.0023, train/loss_step=0.134, global_step=1.23e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 142:  93%|█████████▎| 800/859 [09:38<00:42,  1.38it/s, loss=0.14, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00279, train/loss_step=0.136, global_step=1.23e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 142: 100%|██████████| 859/859 [10:15<00:00,  1.40it/s, loss=0.14, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00279, train/loss_step=0.136, global_step=1.23e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 142: 100%|██████████| 859/859 [10:15<00:00,  1.40it/s, loss=0.142, v_num=38, loss_step=0.171, train/loss_simple_step=0.171, train/loss_vlb_step=0.00272, train/loss_step=0.171, global_step=1.23e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 142:   0%|          | 0/859 [00:00<00:00, 15592.21it/s, loss=0.142, v_num=38, loss_step=0.171, train/loss_simple_step=0.171, train/loss_vlb_step=0.00272, train/loss_step=0.171, global_step=1.23e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 143:   0%|          | 0/859 [00:00<00:00, 1432.48it/s, loss=0.142, v_num=38, loss_step=0.171, train/loss_simple_step=0.171, train/loss_vlb_step=0.00272, train/loss_step=0.171, global_step=1.23e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 143:  23%|██▎       | 200/859 [02:45<09:01,  1.22it/s, loss=0.142, v_num=38, loss_step=0.171, train/loss_simple_step=0.171, train/loss_vlb_step=0.00272, train/loss_step=0.171, global_step=1.23e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00252, train/loss_epoch=0.142]
Epoch 143:  23%|██▎       | 200/859 [02:45<09:01,  1.22it/s, loss=0.14, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00123, train/loss_step=0.141, global_step=1.23e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141] 
Epoch 143:  47%|████▋     | 400/859 [04:49<05:31,  1.39it/s, loss=0.14, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00123, train/loss_step=0.141, global_step=1.23e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]
Epoch 143:  47%|████▋     | 400/859 [04:49<05:31,  1.39it/s, loss=0.14, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00308, train/loss_step=0.141, global_step=1.23e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]
Epoch 143:  70%|██████▉   | 600/859 [06:52<02:57,  1.46it/s, loss=0.14, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00308, train/loss_step=0.141, global_step=1.23e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]
Epoch 143:  70%|██████▉   | 600/859 [06:52<02:57,  1.46it/s, loss=0.139, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00279, train/loss_step=0.140, global_step=1.23e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 143:  93%|█████████▎| 800/859 [09:38<00:42,  1.38it/s, loss=0.139, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00279, train/loss_step=0.140, global_step=1.23e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]
Epoch 143:  93%|█████████▎| 800/859 [09:38<00:42,  1.38it/s, loss=0.139, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00332, train/loss_step=0.136, global_step=1.24e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]
Epoch 143: 100%|██████████| 859/859 [10:15<00:00,  1.40it/s, loss=0.139, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00332, train/loss_step=0.136, global_step=1.24e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]
Epoch 143: 100%|██████████| 859/859 [10:15<00:00,  1.40it/s, loss=0.142, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00384, train/loss_step=0.146, global_step=1.24e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]
Epoch 143:   0%|          | 0/859 [00:00<00:00, 11459.85it/s, loss=0.142, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00384, train/loss_step=0.146, global_step=1.24e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]
Epoch 144:   0%|          | 0/859 [00:00<00:01, 836.52it/s, loss=0.142, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00384, train/loss_step=0.146, global_step=1.24e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]  
Epoch 144:  23%|██▎       | 200/859 [02:03<06:45,  1.62it/s, loss=0.142, v_num=38, loss_step=0.146, train/loss_simple_step=0.146, train/loss_vlb_step=0.00384, train/loss_step=0.146, global_step=1.24e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00246, train/loss_epoch=0.141]
Epoch 144:  23%|██▎       | 200/859 [02:03<06:45,  1.62it/s, loss=0.144, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.000991, train/loss_step=0.140, global_step=1.24e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 144:  47%|████▋     | 400/859 [04:51<05:33,  1.38it/s, loss=0.144, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.000991, train/loss_step=0.140, global_step=1.24e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141]
Epoch 144:  47%|████▋     | 400/859 [04:51<05:33,  1.38it/s, loss=0.142, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00372, train/loss_step=0.136, global_step=1.24e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141] 
Epoch 144:  70%|██████▉   | 600/859 [06:54<02:58,  1.45it/s, loss=0.142, v_num=38, loss_step=0.136, train/loss_simple_step=0.136, train/loss_vlb_step=0.00372, train/loss_step=0.136, global_step=1.24e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141]
Epoch 144:  70%|██████▉   | 600/859 [06:54<02:58,  1.45it/s, loss=0.139, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00162, train/loss_step=0.145, global_step=1.24e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141]
Epoch 144:  93%|█████████▎| 800/859 [08:57<00:39,  1.49it/s, loss=0.139, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00162, train/loss_step=0.145, global_step=1.24e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141]
Epoch 144:  93%|█████████▎| 800/859 [08:57<00:39,  1.49it/s, loss=0.137, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00224, train/loss_step=0.139, global_step=1.24e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 144: 100%|██████████| 859/859 [10:18<00:00,  1.39it/s, loss=0.137, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00224, train/loss_step=0.139, global_step=1.24e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141]
Epoch 144: 100%|██████████| 859/859 [10:18<00:00,  1.39it/s, loss=0.14, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.000901, train/loss_step=0.133, global_step=1.25e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141]
Epoch 144:   0%|          | 0/859 [00:00<00:00, 14563.56it/s, loss=0.14, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.000901, train/loss_step=0.133, global_step=1.25e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141]
Epoch 145:   0%|          | 0/859 [00:00<00:00, 2285.72it/s, loss=0.14, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.000901, train/loss_step=0.133, global_step=1.25e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141] 
Epoch 145:  23%|██▎       | 200/859 [02:03<06:46,  1.62it/s, loss=0.14, v_num=38, loss_step=0.133, train/loss_simple_step=0.133, train/loss_vlb_step=0.000901, train/loss_step=0.133, global_step=1.25e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00254, train/loss_epoch=0.141]
Epoch 145:  23%|██▎       | 200/859 [02:03<06:46,  1.62it/s, loss=0.143, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00316, train/loss_step=0.145, global_step=1.25e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141] 
Epoch 145:  47%|████▋     | 400/859 [04:07<04:43,  1.62it/s, loss=0.143, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00316, train/loss_step=0.145, global_step=1.25e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 145:  47%|████▋     | 400/859 [04:07<04:43,  1.62it/s, loss=0.145, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00272, train/loss_step=0.143, global_step=1.25e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 145:  70%|██████▉   | 600/859 [06:54<02:58,  1.45it/s, loss=0.145, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00272, train/loss_step=0.143, global_step=1.25e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 145:  70%|██████▉   | 600/859 [06:54<02:58,  1.45it/s, loss=0.141, v_num=38, loss_step=0.154, train/loss_simple_step=0.154, train/loss_vlb_step=0.00342, train/loss_step=0.154, global_step=1.25e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 145:  93%|█████████▎| 800/859 [08:57<00:39,  1.49it/s, loss=0.141, v_num=38, loss_step=0.154, train/loss_simple_step=0.154, train/loss_vlb_step=0.00342, train/loss_step=0.154, global_step=1.25e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 145:  93%|█████████▎| 800/859 [08:57<00:39,  1.49it/s, loss=0.14, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00305, train/loss_step=0.141, global_step=1.25e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141] 
Epoch 145: 100%|██████████| 859/859 [09:34<00:00,  1.50it/s, loss=0.14, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00305, train/loss_step=0.141, global_step=1.25e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 145: 100%|██████████| 859/859 [09:34<00:00,  1.50it/s, loss=0.146, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00392, train/loss_step=0.143, global_step=1.25e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 145:   0%|          | 0/859 [00:00<00:00, 19784.45it/s, loss=0.146, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00392, train/loss_step=0.143, global_step=1.25e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 146:   0%|          | 0/859 [00:00<00:00, 2822.55it/s, loss=0.146, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00392, train/loss_step=0.143, global_step=1.25e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 146:  23%|██▎       | 200/859 [02:47<09:09,  1.20it/s, loss=0.146, v_num=38, loss_step=0.143, train/loss_simple_step=0.143, train/loss_vlb_step=0.00392, train/loss_step=0.143, global_step=1.25e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.141]
Epoch 146:  23%|██▎       | 200/859 [02:47<09:09,  1.20it/s, loss=0.145, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00195, train/loss_step=0.148, global_step=1.26e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142]
Epoch 146:  47%|████▋     | 400/859 [04:50<05:32,  1.38it/s, loss=0.145, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00195, train/loss_step=0.148, global_step=1.26e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142]
Epoch 146:  47%|████▋     | 400/859 [04:50<05:32,  1.38it/s, loss=0.139, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00219, train/loss_step=0.148, global_step=1.26e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 146:  70%|██████▉   | 600/859 [07:38<03:17,  1.31it/s, loss=0.139, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00219, train/loss_step=0.148, global_step=1.26e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142]
Epoch 146:  70%|██████▉   | 600/859 [07:38<03:17,  1.31it/s, loss=0.141, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00151, train/loss_step=0.139, global_step=1.26e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142]
Epoch 146:  93%|█████████▎| 800/859 [09:42<00:42,  1.38it/s, loss=0.141, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00151, train/loss_step=0.139, global_step=1.26e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142]
Epoch 146:  93%|█████████▎| 800/859 [09:42<00:42,  1.38it/s, loss=0.143, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00503, train/loss_step=0.147, global_step=1.26e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142]
Epoch 146: 100%|██████████| 859/859 [10:18<00:00,  1.39it/s, loss=0.143, v_num=38, loss_step=0.147, train/loss_simple_step=0.147, train/loss_vlb_step=0.00503, train/loss_step=0.147, global_step=1.26e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142]
Epoch 146: 100%|██████████| 859/859 [10:18<00:00,  1.39it/s, loss=0.141, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00142, train/loss_step=0.135, global_step=1.26e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142]
Epoch 146:   0%|          | 0/859 [00:00<00:00, 18157.16it/s, loss=0.141, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00142, train/loss_step=0.135, global_step=1.26e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142]
Epoch 147:   0%|          | 0/859 [00:00<00:00, 1424.70it/s, loss=0.141, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00142, train/loss_step=0.135, global_step=1.26e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142] 
Epoch 147:  23%|██▎       | 200/859 [02:03<06:44,  1.63it/s, loss=0.141, v_num=38, loss_step=0.135, train/loss_simple_step=0.135, train/loss_vlb_step=0.00142, train/loss_step=0.135, global_step=1.26e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.142]
Epoch 147:  23%|██▎       | 200/859 [02:03<06:44,  1.63it/s, loss=0.146, v_num=38, loss_step=0.175, train/loss_simple_step=0.175, train/loss_vlb_step=0.00311, train/loss_step=0.175, global_step=1.26e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 147:  47%|████▋     | 400/859 [04:51<05:33,  1.38it/s, loss=0.146, v_num=38, loss_step=0.175, train/loss_simple_step=0.175, train/loss_vlb_step=0.00311, train/loss_step=0.175, global_step=1.26e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 147:  47%|████▋     | 400/859 [04:51<05:33,  1.38it/s, loss=0.141, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00284, train/loss_step=0.145, global_step=1.27e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 147:  70%|██████▉   | 600/859 [06:54<02:58,  1.45it/s, loss=0.141, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00284, train/loss_step=0.145, global_step=1.27e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 147:  70%|██████▉   | 600/859 [06:54<02:58,  1.45it/s, loss=0.139, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00201, train/loss_step=0.141, global_step=1.27e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 147:  93%|█████████▎| 800/859 [09:41<00:42,  1.38it/s, loss=0.139, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00201, train/loss_step=0.141, global_step=1.27e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 147:  93%|█████████▎| 800/859 [09:41<00:42,  1.38it/s, loss=0.139, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00395, train/loss_step=0.145, global_step=1.27e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 147: 100%|██████████| 859/859 [10:18<00:00,  1.39it/s, loss=0.139, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.00395, train/loss_step=0.145, global_step=1.27e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 147: 100%|██████████| 859/859 [10:18<00:00,  1.39it/s, loss=0.141, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.0037, train/loss_step=0.145, global_step=1.27e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141] 
Epoch 147:   0%|          | 0/859 [00:00<00:00, 14074.85it/s, loss=0.141, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.0037, train/loss_step=0.145, global_step=1.27e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 148:   0%|          | 0/859 [00:00<00:00, 1465.00it/s, loss=0.141, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.0037, train/loss_step=0.145, global_step=1.27e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141] 
Epoch 148:  23%|██▎       | 200/859 [02:02<06:42,  1.64it/s, loss=0.141, v_num=38, loss_step=0.145, train/loss_simple_step=0.145, train/loss_vlb_step=0.0037, train/loss_step=0.145, global_step=1.27e+5, loss_epoch=0.141, train/loss_simple_epoch=0.141, train/loss_vlb_epoch=0.00249, train/loss_epoch=0.141]
Epoch 148:  23%|██▎       | 200/859 [02:02<06:42,  1.64it/s, loss=0.144, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00263, train/loss_step=0.140, global_step=1.27e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 148:  47%|████▋     | 400/859 [04:51<05:33,  1.38it/s, loss=0.144, v_num=38, loss_step=0.140, train/loss_simple_step=0.140, train/loss_vlb_step=0.00263, train/loss_step=0.140, global_step=1.27e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 148:  47%|████▋     | 400/859 [04:51<05:33,  1.38it/s, loss=0.142, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00163, train/loss_step=0.139, global_step=1.28e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 148:  70%|██████▉   | 600/859 [06:55<02:59,  1.45it/s, loss=0.142, v_num=38, loss_step=0.139, train/loss_simple_step=0.139, train/loss_vlb_step=0.00163, train/loss_step=0.139, global_step=1.28e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 148:  70%|██████▉   | 600/859 [06:55<02:59,  1.45it/s, loss=0.142, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00226, train/loss_step=0.141, global_step=1.28e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 148:  93%|█████████▎| 800/859 [08:59<00:39,  1.48it/s, loss=0.142, v_num=38, loss_step=0.141, train/loss_simple_step=0.141, train/loss_vlb_step=0.00226, train/loss_step=0.141, global_step=1.28e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 148:  93%|█████████▎| 800/859 [08:59<00:39,  1.48it/s, loss=0.142, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00342, train/loss_step=0.151, global_step=1.28e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 148:   0%|          | 0/859 [00:00<00:00, 15363.75it/s, loss=0.142, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00342, train/loss_step=0.151, global_step=1.28e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 149:   0%|          | 0/859 [00:00<00:00, 1760.09it/s, loss=0.142, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00342, train/loss_step=0.151, global_step=1.28e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142] pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 149:  23%|██▎       | 200/859 [02:47<09:08,  1.20it/s, loss=0.142, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.00342, train/loss_step=0.151, global_step=1.28e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.0025, train/loss_epoch=0.142]
Epoch 149:  23%|██▎       | 200/859 [02:47<09:08,  1.20it/s, loss=0.14, v_num=38, loss_step=0.158, train/loss_simple_step=0.158, train/loss_vlb_step=0.00248, train/loss_step=0.158, global_step=1.28e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 149:  47%|████▋     | 400/859 [04:50<05:32,  1.38it/s, loss=0.14, v_num=38, loss_step=0.158, train/loss_simple_step=0.158, train/loss_vlb_step=0.00248, train/loss_step=0.158, global_step=1.28e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 149:  47%|████▋     | 400/859 [04:50<05:32,  1.38it/s, loss=0.14, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00123, train/loss_step=0.131, global_step=1.28e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]pop from empty list
Data shape for DDIM sampling is (8, 3, 14, 14), eta 1.0
Running DDIM Sampling with 500 timesteps

Epoch 149:  70%|██████▉   | 600/859 [07:34<03:15,  1.32it/s, loss=0.14, v_num=38, loss_step=0.131, train/loss_simple_step=0.131, train/loss_vlb_step=0.00123, train/loss_step=0.131, global_step=1.28e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 149:  70%|██████▉   | 600/859 [07:34<03:15,  1.32it/s, loss=0.141, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.0035, train/loss_step=0.151, global_step=1.29e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 149:  93%|█████████▎| 800/859 [09:37<00:42,  1.39it/s, loss=0.141, v_num=38, loss_step=0.151, train/loss_simple_step=0.151, train/loss_vlb_step=0.0035, train/loss_step=0.151, global_step=1.29e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 149:  93%|█████████▎| 800/859 [09:37<00:42,  1.39it/s, loss=0.144, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00431, train/loss_step=0.148, global_step=1.29e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 149: 100%|██████████| 859/859 [10:13<00:00,  1.40it/s, loss=0.144, v_num=38, loss_step=0.148, train/loss_simple_step=0.148, train/loss_vlb_step=0.00431, train/loss_step=0.148, global_step=1.29e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 149: 100%|██████████| 859/859 [10:13<00:00,  1.40it/s, loss=0.142, v_num=38, loss_step=0.125, train/loss_simple_step=0.125, train/loss_vlb_step=0.00178, train/loss_step=0.125, global_step=1.29e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]
Epoch 149: 100%|██████████| 859/859 [10:14<00:00,  1.40it/s, loss=0.142, v_num=38, loss_step=0.125, train/loss_simple_step=0.125, train/loss_vlb_step=0.00178, train/loss_step=0.125, global_step=1.29e+5, loss_epoch=0.142, train/loss_simple_epoch=0.142, train/loss_vlb_epoch=0.00251, train/loss_epoch=0.142]


INFO - dpsgd_lora_sc.py - 2025-01-15 03:35:22,825 - start to generate 60000 samples
INFO - dpsgd_lora_sc.py - 2025-01-15 04:59:22,475 - Output:
Loading model from exp/dp-lora/fmnist_28_eps10.0val_large28-2025-01-14-11-53-01/train/checkpoints/last.ckpt
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 7.11 M params.
making attention of type 'vanilla' with 256 in_channels
Working with z of shape (1, 3, 14, 14) = 588 dimensions.
making attention of type 'vanilla' with 256 in_channels
rendering 6000 examples of class '0' in 200 steps and using s=1.00.
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
rendering 6000 examples of class '1' in 200 steps and using s=1.00.
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
rendering 6000 examples of class '2' in 200 steps and using s=1.00.
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
rendering 6000 examples of class '3' in 200 steps and using s=1.00.
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
rendering 6000 examples of class '4' in 200 steps and using s=1.00.
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
rendering 6000 examples of class '5' in 200 steps and using s=1.00.
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
rendering 6000 examples of class '6' in 200 steps and using s=1.00.
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
rendering 6000 examples of class '7' in 200 steps and using s=1.00.
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
rendering 6000 examples of class '8' in 200 steps and using s=1.00.
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
rendering 6000 examples of class '9' in 200 steps and using s=1.00.
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps
Data shape for DDIM sampling is (1000, 3, 14, 14), eta 1.0
Running DDIM Sampling with 200 timesteps

INFO - dpsgd_lora_sc.py - 2025-01-15 04:59:22,537 - Generation Finished!
INFO - evaluator.py - 2025-01-15 04:59:59,352 - Epoch: 0 Train acc: 46.625454545454545 Val acc: 72.06 Test acc72.07000000000001; Train loss: 0.005430846411531622 Val loss: 0.0007352043390274048
INFO - evaluator.py - 2025-01-15 05:00:32,883 - Epoch: 1 Train acc: 70.39999999999999 Val acc: 77.14 Test acc77.24; Train loss: 0.002953919553756714 Val loss: 0.000595929205417633
INFO - evaluator.py - 2025-01-15 05:01:05,779 - Epoch: 2 Train acc: 74.2 Val acc: 79.54 Test acc79.55; Train loss: 0.0025982301105152475 Val loss: 0.0005395581364631653
INFO - evaluator.py - 2025-01-15 05:01:38,917 - Epoch: 3 Train acc: 76.72545454545454 Val acc: 81.24 Test acc81.06; Train loss: 0.0023462206038561734 Val loss: 0.0005036259114742279
INFO - evaluator.py - 2025-01-15 05:02:11,862 - Epoch: 4 Train acc: 77.95818181818181 Val acc: 81.84 Test acc81.63; Train loss: 0.0022279053070328454 Val loss: 0.0004971497058868408
INFO - evaluator.py - 2025-01-15 05:02:45,068 - Epoch: 5 Train acc: 78.8309090909091 Val acc: 82.17999999999999 Test acc81.98; Train loss: 0.002142728803916411 Val loss: 0.0004887846887111664
INFO - evaluator.py - 2025-01-15 05:03:18,191 - Epoch: 6 Train acc: 79.76727272727273 Val acc: 83.3 Test acc82.94; Train loss: 0.0020541781837289984 Val loss: 0.0004527018189430237
INFO - evaluator.py - 2025-01-15 05:03:51,211 - Epoch: 7 Train acc: 80.35636363636364 Val acc: 83.38 Test acc83.54; Train loss: 0.0019884602216157046 Val loss: 0.0004548503637313843
INFO - evaluator.py - 2025-01-15 05:04:24,482 - Epoch: 8 Train acc: 80.92181818181818 Val acc: 82.3 Test acc82.80999999999999; Train loss: 0.0019244345117699017 Val loss: 0.00048261943459510805
INFO - evaluator.py - 2025-01-15 05:04:57,146 - Epoch: 9 Train acc: 81.57818181818182 Val acc: 82.34 Test acc82.34; Train loss: 0.0018765206970951774 Val loss: 0.0004935732305049896
INFO - evaluator.py - 2025-01-15 05:05:29,915 - Epoch: 10 Train acc: 82.14727272727272 Val acc: 78.08 Test acc77.51; Train loss: 0.0018198807965625417 Val loss: 0.000593372130393982
INFO - evaluator.py - 2025-01-15 05:06:03,046 - Epoch: 11 Train acc: 82.45090909090908 Val acc: 79.56 Test acc79.86999999999999; Train loss: 0.0017755203826860949 Val loss: 0.0005231835961341858
INFO - evaluator.py - 2025-01-15 05:06:36,108 - Epoch: 12 Train acc: 82.89272727272727 Val acc: 78.3 Test acc78.57; Train loss: 0.0017334068309177051 Val loss: 0.0005680046319961548
INFO - evaluator.py - 2025-01-15 05:07:09,644 - Epoch: 13 Train acc: 83.54363636363637 Val acc: 78.22 Test acc77.61; Train loss: 0.0016796472159298984 Val loss: 0.0005909114837646484
INFO - evaluator.py - 2025-01-15 05:07:42,447 - Epoch: 14 Train acc: 83.77818181818182 Val acc: 70.56 Test acc69.28; Train loss: 0.0016303120152516798 Val loss: 0.0007730906963348389
INFO - evaluator.py - 2025-01-15 05:08:15,344 - Epoch: 15 Train acc: 84.35636363636364 Val acc: 69.04 Test acc68.02; Train loss: 0.0015765179135582663 Val loss: 0.0008380581855773926
INFO - evaluator.py - 2025-01-15 05:08:48,372 - Epoch: 16 Train acc: 84.89818181818181 Val acc: 59.06 Test acc60.040000000000006; Train loss: 0.0015307801382108167 Val loss: 0.0012476486921310424
INFO - evaluator.py - 2025-01-15 05:09:21,574 - Epoch: 17 Train acc: 85.44363636363637 Val acc: 73.82 Test acc73.42; Train loss: 0.0014716304080052808 Val loss: 0.0007105894923210144
INFO - evaluator.py - 2025-01-15 05:09:54,416 - Epoch: 18 Train acc: 86.0890909090909 Val acc: 56.00000000000001 Test acc57.28; Train loss: 0.0014116437261754817 Val loss: 0.0016064234495162964
INFO - evaluator.py - 2025-01-15 05:10:27,458 - Epoch: 19 Train acc: 87.02363636363636 Val acc: 64.1 Test acc64.52; Train loss: 0.0013351310475306077 Val loss: 0.0009129389762878418
INFO - evaluator.py - 2025-01-15 05:11:00,366 - Epoch: 20 Train acc: 91.32545454545455 Val acc: 80.02 Test acc80.4; Train loss: 0.0009279769079251723 Val loss: 0.0005873413681983947
INFO - evaluator.py - 2025-01-15 05:11:33,429 - Epoch: 21 Train acc: 93.19272727272727 Val acc: 83.28 Test acc83.32000000000001; Train loss: 0.0007377841441468759 Val loss: 0.0005563498258590699
INFO - evaluator.py - 2025-01-15 05:12:06,472 - Epoch: 22 Train acc: 94.25272727272727 Val acc: 83.98 Test acc83.71; Train loss: 0.0006094082267446952 Val loss: 0.000585763955116272
INFO - evaluator.py - 2025-01-15 05:12:38,987 - Epoch: 23 Train acc: 95.5909090909091 Val acc: 83.22 Test acc83.28; Train loss: 0.00048710425001653756 Val loss: 0.0006853821158409118
INFO - evaluator.py - 2025-01-15 05:13:11,593 - Epoch: 24 Train acc: 96.42181818181818 Val acc: 83.17999999999999 Test acc83.13000000000001; Train loss: 0.00039526689486070113 Val loss: 0.0007701913356781006
INFO - evaluator.py - 2025-01-15 05:13:44,444 - Epoch: 25 Train acc: 97.23818181818183 Val acc: 81.82000000000001 Test acc81.66; Train loss: 0.000298308746076443 Val loss: 0.0009582635402679443
INFO - evaluator.py - 2025-01-15 05:14:16,624 - Epoch: 26 Train acc: 97.68363636363637 Val acc: 83.14 Test acc82.83; Train loss: 0.000250873608446934 Val loss: 0.000889020311832428
INFO - evaluator.py - 2025-01-15 05:14:49,655 - Epoch: 27 Train acc: 98.27454545454546 Val acc: 82.28 Test acc81.95; Train loss: 0.00018864633518863807 Val loss: 0.0010617999911308289
INFO - evaluator.py - 2025-01-15 05:15:22,418 - Epoch: 28 Train acc: 98.54545454545455 Val acc: 80.30000000000001 Test acc79.81; Train loss: 0.00016146844820204105 Val loss: 0.0013719995737075806
INFO - evaluator.py - 2025-01-15 05:15:55,352 - Epoch: 29 Train acc: 98.70727272727274 Val acc: 82.84 Test acc82.36; Train loss: 0.0001416794918223538 Val loss: 0.0011189204692840576
INFO - evaluator.py - 2025-01-15 05:16:27,949 - Epoch: 30 Train acc: 98.9309090909091 Val acc: 82.8 Test acc82.39999999999999; Train loss: 0.00011615585735999047 Val loss: 0.0011978286981582642
INFO - evaluator.py - 2025-01-15 05:17:00,494 - Epoch: 31 Train acc: 99.03454545454545 Val acc: 80.94 Test acc81.47999999999999; Train loss: 0.00010474076936529442 Val loss: 0.001350431251525879
INFO - evaluator.py - 2025-01-15 05:17:33,263 - Epoch: 32 Train acc: 98.94 Val acc: 81.96 Test acc82.28; Train loss: 0.00011508066023445942 Val loss: 0.00121408748626709
INFO - evaluator.py - 2025-01-15 05:18:06,407 - Epoch: 33 Train acc: 99.13272727272727 Val acc: 82.22 Test acc81.89999999999999; Train loss: 9.374880710278045e-05 Val loss: 0.001339072561264038
INFO - evaluator.py - 2025-01-15 05:18:39,217 - Epoch: 34 Train acc: 99.20363636363636 Val acc: 82.58 Test acc81.95; Train loss: 8.990493370643393e-05 Val loss: 0.0014380958795547486
INFO - evaluator.py - 2025-01-15 05:19:12,293 - Epoch: 35 Train acc: 99.36727272727272 Val acc: 82.42 Test acc81.93; Train loss: 6.95474266582592e-05 Val loss: 0.001553827428817749
INFO - evaluator.py - 2025-01-15 05:19:45,217 - Epoch: 36 Train acc: 99.32 Val acc: 82.32000000000001 Test acc81.82000000000001; Train loss: 7.334398517427458e-05 Val loss: 0.001630380654335022
INFO - evaluator.py - 2025-01-15 05:20:18,054 - Epoch: 37 Train acc: 99.13818181818182 Val acc: 82.62 Test acc82.15; Train loss: 9.310811205174435e-05 Val loss: 0.0015852343797683715
INFO - evaluator.py - 2025-01-15 05:20:50,754 - Epoch: 38 Train acc: 99.36727272727272 Val acc: 82.06 Test acc82.0; Train loss: 6.986776581880721e-05 Val loss: 0.0015146004438400269
INFO - evaluator.py - 2025-01-15 05:21:23,872 - Epoch: 39 Train acc: 99.32727272727273 Val acc: 82.14 Test acc81.42; Train loss: 7.510221078356897e-05 Val loss: 0.0015643059968948364
INFO - evaluator.py - 2025-01-15 05:21:56,768 - Epoch: 40 Train acc: 99.76727272727273 Val acc: 82.54 Test acc81.88; Train loss: 2.919551351964897e-05 Val loss: 0.0015498035669326783
INFO - evaluator.py - 2025-01-15 05:22:29,409 - Epoch: 41 Train acc: 99.96363636363637 Val acc: 82.88 Test acc82.19999999999999; Train loss: 1.0052200056485493e-05 Val loss: 0.0015957470893859863
INFO - evaluator.py - 2025-01-15 05:23:02,272 - Epoch: 42 Train acc: 99.9890909090909 Val acc: 83.2 Test acc82.53; Train loss: 5.3423271943095396e-06 Val loss: 0.001646583366394043
INFO - evaluator.py - 2025-01-15 05:23:35,365 - Epoch: 43 Train acc: 99.99818181818182 Val acc: 82.98 Test acc82.16; Train loss: 3.437041898988272e-06 Val loss: 0.0017393627166748047
INFO - evaluator.py - 2025-01-15 05:24:08,019 - Epoch: 44 Train acc: 99.99272727272728 Val acc: 83.02000000000001 Test acc82.28999999999999; Train loss: 3.0935210988073696e-06 Val loss: 0.0018110594749450684
INFO - evaluator.py - 2025-01-15 05:24:40,859 - Epoch: 45 Train acc: 99.99272727272728 Val acc: 82.96 Test acc82.3; Train loss: 2.7343221406970934e-06 Val loss: 0.0018740916728973388
INFO - evaluator.py - 2025-01-15 05:25:13,869 - Epoch: 46 Train acc: 99.99454545454546 Val acc: 82.5 Test acc81.64; Train loss: 2.6981868098532275e-06 Val loss: 0.001982389783859253
INFO - evaluator.py - 2025-01-15 05:25:47,066 - Epoch: 47 Train acc: 99.99818181818182 Val acc: 82.12 Test acc81.52000000000001; Train loss: 1.585059613254006e-06 Val loss: 0.0020675601482391358
INFO - evaluator.py - 2025-01-15 05:26:20,111 - Epoch: 48 Train acc: 99.99818181818182 Val acc: 81.78 Test acc81.2; Train loss: 1.3817592239898989e-06 Val loss: 0.0021562812089920046
INFO - evaluator.py - 2025-01-15 05:26:52,867 - Epoch: 49 Train acc: 99.99818181818182 Val acc: 82.02000000000001 Test acc81.46; Train loss: 1.2344200003677873e-06 Val loss: 0.0022433122634887693
INFO - evaluator.py - 2025-01-15 05:26:52,873 - The best acc of synthetic images on sensitive val and the corresponding acc on test dataset from resnet is 83.98 and 83.71
INFO - evaluator.py - 2025-01-15 05:26:52,873 - The best acc of synthetic images on noisy sensitive val and the corresponding acc on test dataset from resnet is 83.98 and 83.71
INFO - evaluator.py - 2025-01-15 05:26:52,873 - The best acc test dataset from resnet is 83.71
INFO - evaluator.py - 2025-01-15 05:27:39,732 - Epoch: 0 Train acc: 59.65090909090909 Val acc: 76.55999999999999 Test acc76.23; Train loss: 0.003981933696703477 Val loss: 0.0006307835936546326
INFO - evaluator.py - 2025-01-15 05:28:25,326 - Epoch: 1 Train acc: 72.70545454545456 Val acc: 76.98 Test acc77.62; Train loss: 0.0027239754535935143 Val loss: 0.0006018259406089782
INFO - evaluator.py - 2025-01-15 05:29:11,207 - Epoch: 2 Train acc: 75.79636363636364 Val acc: 80.47999999999999 Test acc80.47999999999999; Train loss: 0.002413659839738499 Val loss: 0.0005178500890731812
INFO - evaluator.py - 2025-01-15 05:29:56,501 - Epoch: 3 Train acc: 77.53272727272727 Val acc: 79.78 Test acc80.25; Train loss: 0.0022644761876626446 Val loss: 0.0005273084282875061
INFO - evaluator.py - 2025-01-15 05:30:41,855 - Epoch: 4 Train acc: 78.62727272727273 Val acc: 83.02000000000001 Test acc82.36; Train loss: 0.0021535691803151913 Val loss: 0.0004481765627861023
INFO - evaluator.py - 2025-01-15 05:31:26,956 - Epoch: 5 Train acc: 79.31818181818183 Val acc: 82.64 Test acc82.54; Train loss: 0.002078849539431659 Val loss: 0.0004602540373802185
INFO - evaluator.py - 2025-01-15 05:32:12,074 - Epoch: 6 Train acc: 80.26181818181819 Val acc: 82.88 Test acc82.8; Train loss: 0.0020033826914700593 Val loss: 0.00046359044909477233
INFO - evaluator.py - 2025-01-15 05:32:57,568 - Epoch: 7 Train acc: 80.78545454545456 Val acc: 83.34 Test acc83.32000000000001; Train loss: 0.0019294052758000114 Val loss: 0.0004535118460655212
INFO - evaluator.py - 2025-01-15 05:33:43,232 - Epoch: 8 Train acc: 81.32000000000001 Val acc: 83.72 Test acc83.69; Train loss: 0.0018789282316511327 Val loss: 0.0004317449152469635
INFO - evaluator.py - 2025-01-15 05:34:28,858 - Epoch: 9 Train acc: 81.89090909090909 Val acc: 82.08 Test acc81.93; Train loss: 0.0018344897449016572 Val loss: 0.0004870692729949951
INFO - evaluator.py - 2025-01-15 05:35:14,490 - Epoch: 10 Train acc: 82.38363636363636 Val acc: 83.72 Test acc83.81; Train loss: 0.001770109325647354 Val loss: 0.00044472660422325135
INFO - evaluator.py - 2025-01-15 05:36:00,127 - Epoch: 11 Train acc: 83.05636363636364 Val acc: 81.24 Test acc81.27; Train loss: 0.0017177716786211188 Val loss: 0.0005240795850753784
INFO - evaluator.py - 2025-01-15 05:36:45,772 - Epoch: 12 Train acc: 83.42 Val acc: 82.6 Test acc82.66; Train loss: 0.0016768874195489016 Val loss: 0.0004781154453754425
INFO - evaluator.py - 2025-01-15 05:37:31,287 - Epoch: 13 Train acc: 84.13090909090909 Val acc: 82.86 Test acc82.49; Train loss: 0.0016086895704269409 Val loss: 0.0005013684391975403
INFO - evaluator.py - 2025-01-15 05:38:16,751 - Epoch: 14 Train acc: 84.61636363636363 Val acc: 81.08 Test acc81.43; Train loss: 0.0015563081725077197 Val loss: 0.0005412523567676545
INFO - evaluator.py - 2025-01-15 05:39:02,371 - Epoch: 15 Train acc: 85.03818181818181 Val acc: 73.83999999999999 Test acc75.08; Train loss: 0.0014978913247585296 Val loss: 0.0007593633770942688
INFO - evaluator.py - 2025-01-15 05:39:47,740 - Epoch: 16 Train acc: 85.88 Val acc: 81.42 Test acc81.89999999999999; Train loss: 0.001437316646901044 Val loss: 0.0005424315571784974
INFO - evaluator.py - 2025-01-15 05:40:33,010 - Epoch: 17 Train acc: 86.53454545454545 Val acc: 80.4 Test acc80.54; Train loss: 0.001355086137218909 Val loss: 0.0005702316641807556
INFO - evaluator.py - 2025-01-15 05:41:18,883 - Epoch: 18 Train acc: 87.59818181818181 Val acc: 79.36 Test acc79.95; Train loss: 0.0012722071073272012 Val loss: 0.0005808740973472595
INFO - evaluator.py - 2025-01-15 05:42:04,610 - Epoch: 19 Train acc: 88.07090909090908 Val acc: 81.89999999999999 Test acc82.65; Train loss: 0.0011953280061483384 Val loss: 0.0005443383336067199
INFO - evaluator.py - 2025-01-15 05:42:50,115 - Epoch: 20 Train acc: 91.7 Val acc: 84.16 Test acc84.39; Train loss: 0.0008594693238084967 Val loss: 0.000544357419013977
INFO - evaluator.py - 2025-01-15 05:43:35,417 - Epoch: 21 Train acc: 93.02909090909091 Val acc: 84.1 Test acc84.50999999999999; Train loss: 0.0007177591579881581 Val loss: 0.0006123511075973511
INFO - evaluator.py - 2025-01-15 05:44:21,118 - Epoch: 22 Train acc: 93.99454545454546 Val acc: 83.38 Test acc84.04; Train loss: 0.0006302329542961988 Val loss: 0.0006783779859542847
INFO - evaluator.py - 2025-01-15 05:45:07,077 - Epoch: 23 Train acc: 94.62545454545455 Val acc: 82.54 Test acc82.8; Train loss: 0.0005592632244933735 Val loss: 0.0007856095910072327
INFO - evaluator.py - 2025-01-15 05:45:52,513 - Epoch: 24 Train acc: 95.05818181818182 Val acc: 81.86 Test acc82.06; Train loss: 0.0005089167249473658 Val loss: 0.0008976982116699219
INFO - evaluator.py - 2025-01-15 05:46:37,949 - Epoch: 25 Train acc: 95.60363636363637 Val acc: 82.08 Test acc82.58; Train loss: 0.0004575559403408657 Val loss: 0.0009422828197479248
INFO - evaluator.py - 2025-01-15 05:47:23,152 - Epoch: 26 Train acc: 96.04 Val acc: 81.92 Test acc82.21000000000001; Train loss: 0.0004101533745500174 Val loss: 0.0009522105693817139
INFO - evaluator.py - 2025-01-15 05:48:08,698 - Epoch: 27 Train acc: 96.50363636363636 Val acc: 82.76 Test acc83.28999999999999; Train loss: 0.0003646544845266776 Val loss: 0.0009323364138603211
INFO - evaluator.py - 2025-01-15 05:48:54,454 - Epoch: 28 Train acc: 96.87818181818182 Val acc: 81.89999999999999 Test acc82.49; Train loss: 0.0003221455154093829 Val loss: 0.001071092450618744
INFO - evaluator.py - 2025-01-15 05:49:39,434 - Epoch: 29 Train acc: 97.10545454545455 Val acc: 81.72 Test acc82.44; Train loss: 0.00030229473151266575 Val loss: 0.0011252725839614869
INFO - evaluator.py - 2025-01-15 05:50:24,414 - Epoch: 30 Train acc: 97.43636363636364 Val acc: 81.66 Test acc82.02000000000001; Train loss: 0.0002691358506340872 Val loss: 0.0012609235048294067
INFO - evaluator.py - 2025-01-15 05:51:09,721 - Epoch: 31 Train acc: 97.68727272727273 Val acc: 80.86 Test acc81.3; Train loss: 0.00024695205891674213 Val loss: 0.0013760051727294922
INFO - evaluator.py - 2025-01-15 05:51:55,127 - Epoch: 32 Train acc: 97.99272727272728 Val acc: 82.54 Test acc83.04; Train loss: 0.00021579673164947465 Val loss: 0.0012049782276153565
INFO - evaluator.py - 2025-01-15 05:52:40,101 - Epoch: 33 Train acc: 98.1290909090909 Val acc: 81.56 Test acc81.84; Train loss: 0.00019985118430446494 Val loss: 0.001401459527015686
INFO - evaluator.py - 2025-01-15 05:53:25,526 - Epoch: 34 Train acc: 98.18363636363637 Val acc: 81.82000000000001 Test acc82.21000000000001; Train loss: 0.00019820543116127903 Val loss: 0.001339132332801819
INFO - evaluator.py - 2025-01-15 05:54:10,912 - Epoch: 35 Train acc: 98.2109090909091 Val acc: 82.54 Test acc82.67; Train loss: 0.0001842503696680069 Val loss: 0.0012937087059020995
INFO - evaluator.py - 2025-01-15 05:54:56,155 - Epoch: 36 Train acc: 98.4309090909091 Val acc: 82.74000000000001 Test acc83.12; Train loss: 0.0001691970458254218 Val loss: 0.001319225811958313
INFO - evaluator.py - 2025-01-15 05:55:41,722 - Epoch: 37 Train acc: 98.48727272727272 Val acc: 82.86 Test acc82.99; Train loss: 0.00016144717948680574 Val loss: 0.0014135509729385376
INFO - evaluator.py - 2025-01-15 05:56:27,004 - Epoch: 38 Train acc: 98.59818181818181 Val acc: 81.62 Test acc81.94; Train loss: 0.00015132142879407514 Val loss: 0.0014751510143280028
INFO - evaluator.py - 2025-01-15 05:57:12,029 - Epoch: 39 Train acc: 98.62545454545455 Val acc: 81.0 Test acc81.34; Train loss: 0.00014109564521773294 Val loss: 0.0015906962633132934
INFO - evaluator.py - 2025-01-15 05:57:57,410 - Epoch: 40 Train acc: 99.08727272727272 Val acc: 81.28 Test acc81.81; Train loss: 0.00010299297843805769 Val loss: 0.0015336217403411866
INFO - evaluator.py - 2025-01-15 05:58:42,488 - Epoch: 41 Train acc: 99.22545454545455 Val acc: 81.74 Test acc82.1; Train loss: 8.626018971712752e-05 Val loss: 0.0015219691038131714
INFO - evaluator.py - 2025-01-15 05:59:27,867 - Epoch: 42 Train acc: 99.25454545454545 Val acc: 81.42 Test acc82.03; Train loss: 8.236814970150589e-05 Val loss: 0.0015565752029418946
INFO - evaluator.py - 2025-01-15 06:00:13,148 - Epoch: 43 Train acc: 99.36181818181818 Val acc: 81.44 Test acc81.76; Train loss: 7.659411644563079e-05 Val loss: 0.0015953196763992309
INFO - evaluator.py - 2025-01-15 06:00:58,544 - Epoch: 44 Train acc: 99.48181818181818 Val acc: 82.38 Test acc82.67; Train loss: 6.33679168828001e-05 Val loss: 0.0015517693758010864
INFO - evaluator.py - 2025-01-15 06:01:43,685 - Epoch: 45 Train acc: 99.44363636363637 Val acc: 82.16 Test acc82.54; Train loss: 6.405879276042634e-05 Val loss: 0.0015578788757324219
INFO - evaluator.py - 2025-01-15 06:02:28,849 - Epoch: 46 Train acc: 99.38909090909091 Val acc: 82.26 Test acc82.55; Train loss: 6.567039225377482e-05 Val loss: 0.001562260103225708
INFO - evaluator.py - 2025-01-15 06:03:14,481 - Epoch: 47 Train acc: 99.41272727272728 Val acc: 82.39999999999999 Test acc82.61; Train loss: 6.541588831354272e-05 Val loss: 0.0015525715827941894
INFO - evaluator.py - 2025-01-15 06:03:59,631 - Epoch: 48 Train acc: 99.40181818181819 Val acc: 81.98 Test acc82.15; Train loss: 6.794963435439224e-05 Val loss: 0.0016488784551620483
INFO - evaluator.py - 2025-01-15 06:04:44,916 - Epoch: 49 Train acc: 99.50363636363636 Val acc: 81.86 Test acc82.39999999999999; Train loss: 5.804904223081063e-05 Val loss: 0.0016270665645599365
INFO - evaluator.py - 2025-01-15 06:04:44,920 - The best acc of synthetic images on sensitive val and the corresponding acc on test dataset from wrn is 84.16 and 84.39
INFO - evaluator.py - 2025-01-15 06:04:44,920 - The best acc of synthetic images on noisy sensitive val and the corresponding acc on test dataset from wrn is 84.16 and 84.39
INFO - evaluator.py - 2025-01-15 06:04:44,920 - The best acc test dataset from wrn is 84.50999999999999
INFO - dataset_loader.py - 2025-01-15 08:46:56,275 - delta is reset as 1.6657508770018431e-06
INFO - evaluator.py - 2025-01-15 09:08:46,171 - The FID of synthetic images is 43.66722428186057
INFO - evaluator.py - 2025-01-15 09:08:46,172 - The Inception Score of synthetic images is 3.9836769104003906
INFO - evaluator.py - 2025-01-15 09:08:46,172 - The Precision and Recall of synthetic images is 0.2640833258628845 and 0.534166693687439
INFO - evaluator.py - 2025-01-15 09:08:46,172 - The FLD of synthetic images is 14.863359928131104
INFO - evaluator.py - 2025-01-15 09:08:46,172 - The ImageReward of synthetic images is -1.8956167590219213
INFO - dataset_loader.py - 2025-01-15 10:20:15,890 - delta is reset as 1.6657508770018431e-06
INFO - evaluator.py - 2025-01-15 10:20:52,036 - Epoch: 0 Train acc: 49.10909090909091 Val acc: 72.96000000000001 Test acc72.44; Train loss: 0.005201422676173123 Val loss: 0.0006887053608894348
INFO - evaluator.py - 2025-01-15 10:21:09,510 - Epoch: 1 Train acc: 69.84727272727272 Val acc: 76.62 Test acc76.59; Train loss: 0.0030213806206529793 Val loss: 0.0006813460350036621
INFO - evaluator.py - 2025-01-15 10:21:27,075 - Epoch: 2 Train acc: 74.0 Val acc: 79.2 Test acc79.05; Train loss: 0.0026242287104780025 Val loss: 0.0005473101496696472
INFO - evaluator.py - 2025-01-15 10:21:44,681 - Epoch: 3 Train acc: 76.15636363636364 Val acc: 80.5 Test acc80.88; Train loss: 0.00242243367487734 Val loss: 0.0005105534315109253
INFO - evaluator.py - 2025-01-15 10:22:02,366 - Epoch: 4 Train acc: 77.7690909090909 Val acc: 80.0 Test acc80.39; Train loss: 0.0022531994331966747 Val loss: 0.0005395485281944275
INFO - evaluator.py - 2025-01-15 10:22:20,121 - Epoch: 5 Train acc: 78.50727272727272 Val acc: 79.67999999999999 Test acc80.21000000000001; Train loss: 0.002167636275291443 Val loss: 0.0005241955041885376
INFO - evaluator.py - 2025-01-15 10:22:38,083 - Epoch: 6 Train acc: 79.51090909090908 Val acc: 83.32000000000001 Test acc83.27; Train loss: 0.00208119940161705 Val loss: 0.0004466050386428833
INFO - evaluator.py - 2025-01-15 10:22:55,998 - Epoch: 7 Train acc: 79.94181818181818 Val acc: 81.39999999999999 Test acc81.73; Train loss: 0.0020235635562376544 Val loss: 0.0005037959694862365
INFO - evaluator.py - 2025-01-15 10:23:13,941 - Epoch: 8 Train acc: 80.9890909090909 Val acc: 81.46 Test acc82.12; Train loss: 0.0019438326673074202 Val loss: 0.0004910349607467651
INFO - evaluator.py - 2025-01-15 10:23:31,851 - Epoch: 9 Train acc: 81.49636363636364 Val acc: 79.38 Test acc79.05; Train loss: 0.0018819984246384014 Val loss: 0.0005875040173530579
INFO - evaluator.py - 2025-01-15 10:23:49,744 - Epoch: 10 Train acc: 81.92727272727272 Val acc: 81.89999999999999 Test acc82.02000000000001; Train loss: 0.0018354892600666393 Val loss: 0.000481836462020874
INFO - evaluator.py - 2025-01-15 10:24:07,634 - Epoch: 11 Train acc: 82.40545454545455 Val acc: 81.28 Test acc81.61; Train loss: 0.0017852792355147276 Val loss: 0.0004920269906520844
INFO - evaluator.py - 2025-01-15 10:24:25,515 - Epoch: 12 Train acc: 82.85454545454546 Val acc: 76.62 Test acc75.99000000000001; Train loss: 0.0017488178838383067 Val loss: 0.0006381346225738526
INFO - evaluator.py - 2025-01-15 10:24:43,397 - Epoch: 13 Train acc: 83.51636363636364 Val acc: 82.78 Test acc83.15; Train loss: 0.001686173243414272 Val loss: 0.0004643357872962952
INFO - evaluator.py - 2025-01-15 10:25:01,371 - Epoch: 14 Train acc: 83.82727272727273 Val acc: 79.16 Test acc79.25999999999999; Train loss: 0.0016365983984687111 Val loss: 0.0005819143772125245
INFO - evaluator.py - 2025-01-15 10:25:19,240 - Epoch: 15 Train acc: 84.28 Val acc: 80.62 Test acc80.85; Train loss: 0.001586618420752612 Val loss: 0.0005137393891811371
INFO - evaluator.py - 2025-01-15 10:25:37,087 - Epoch: 16 Train acc: 84.86727272727272 Val acc: 71.8 Test acc72.21; Train loss: 0.001528529836914756 Val loss: 0.000768926990032196
INFO - evaluator.py - 2025-01-15 10:25:54,930 - Epoch: 17 Train acc: 85.5 Val acc: 76.52 Test acc76.33; Train loss: 0.0014697191866961392 Val loss: 0.0006198755979537964
INFO - evaluator.py - 2025-01-15 10:26:12,770 - Epoch: 18 Train acc: 86.17636363636365 Val acc: 74.56 Test acc74.4; Train loss: 0.001409077660874887 Val loss: 0.0007191897034645081
INFO - evaluator.py - 2025-01-15 10:26:30,605 - Epoch: 19 Train acc: 86.75090909090909 Val acc: 76.22 Test acc76.13; Train loss: 0.001345519765127789 Val loss: 0.0006301092505455017
INFO - evaluator.py - 2025-01-15 10:26:48,426 - Epoch: 20 Train acc: 91.37272727272727 Val acc: 82.32000000000001 Test acc82.46; Train loss: 0.0009058110185644843 Val loss: 0.0005628782749176025
INFO - evaluator.py - 2025-01-15 10:27:06,361 - Epoch: 21 Train acc: 93.2709090909091 Val acc: 83.02000000000001 Test acc83.24000000000001; Train loss: 0.00071993015489795 Val loss: 0.0006155459046363831
INFO - evaluator.py - 2025-01-15 10:27:24,179 - Epoch: 22 Train acc: 94.40181818181819 Val acc: 83.28 Test acc83.39999999999999; Train loss: 0.0005977664573626085 Val loss: 0.0006627211570739746
INFO - evaluator.py - 2025-01-15 10:27:41,997 - Epoch: 23 Train acc: 95.73818181818183 Val acc: 79.94 Test acc80.30000000000001; Train loss: 0.00046111744980920446 Val loss: 0.0009504062533378601
INFO - evaluator.py - 2025-01-15 10:27:59,805 - Epoch: 24 Train acc: 96.79272727272728 Val acc: 81.04 Test acc81.54; Train loss: 0.00035442445938560095 Val loss: 0.000944265067577362
INFO - evaluator.py - 2025-01-15 10:28:17,606 - Epoch: 25 Train acc: 97.72909090909091 Val acc: 80.72 Test acc81.12; Train loss: 0.0002626341057771986 Val loss: 0.0010541383743286133
INFO - evaluator.py - 2025-01-15 10:28:35,412 - Epoch: 26 Train acc: 98.16727272727273 Val acc: 80.25999999999999 Test acc80.52; Train loss: 0.00021309512987394225 Val loss: 0.0012440669298171996
INFO - evaluator.py - 2025-01-15 10:28:53,225 - Epoch: 27 Train acc: 98.42909090909092 Val acc: 82.28 Test acc82.37; Train loss: 0.0001702504099431363 Val loss: 0.0011088204622268676
INFO - evaluator.py - 2025-01-15 10:29:11,140 - Epoch: 28 Train acc: 98.6509090909091 Val acc: 79.4 Test acc79.25; Train loss: 0.00015129776433618232 Val loss: 0.0014061060905456544
INFO - evaluator.py - 2025-01-15 10:29:28,934 - Epoch: 29 Train acc: 99.03272727272727 Val acc: 80.42 Test acc80.60000000000001; Train loss: 0.00010491474221714519 Val loss: 0.0012614382982254028
INFO - evaluator.py - 2025-01-15 10:29:46,736 - Epoch: 30 Train acc: 99.04181818181819 Val acc: 82.39999999999999 Test acc82.77; Train loss: 0.00010709286095066505 Val loss: 0.0012391077995300293
INFO - evaluator.py - 2025-01-15 10:30:04,524 - Epoch: 31 Train acc: 98.9 Val acc: 82.24000000000001 Test acc82.54; Train loss: 0.00012193415352905339 Val loss: 0.0013397243738174438
INFO - evaluator.py - 2025-01-15 10:30:22,316 - Epoch: 32 Train acc: 99.29636363636364 Val acc: 82.08 Test acc82.43; Train loss: 7.919242220761423e-05 Val loss: 0.0013950998306274413
INFO - evaluator.py - 2025-01-15 10:30:40,119 - Epoch: 33 Train acc: 99.22909090909091 Val acc: 82.32000000000001 Test acc82.54; Train loss: 8.606837091713467e-05 Val loss: 0.0013811850786209106
INFO - evaluator.py - 2025-01-15 10:30:57,925 - Epoch: 34 Train acc: 99.25454545454545 Val acc: 81.69999999999999 Test acc82.11; Train loss: 8.837465315803209e-05 Val loss: 0.001486241054534912
INFO - evaluator.py - 2025-01-15 10:31:15,712 - Epoch: 35 Train acc: 99.22909090909091 Val acc: 82.44 Test acc82.42; Train loss: 8.371395625343377e-05 Val loss: 0.00154047908782959
INFO - evaluator.py - 2025-01-15 10:31:33,620 - Epoch: 36 Train acc: 99.47272727272727 Val acc: 82.1 Test acc82.06; Train loss: 5.998842305165123e-05 Val loss: 0.0015613648414611817
INFO - evaluator.py - 2025-01-15 10:31:51,405 - Epoch: 37 Train acc: 99.27818181818182 Val acc: 82.76 Test acc82.76; Train loss: 7.94515432451259e-05 Val loss: 0.0015212878942489625
INFO - evaluator.py - 2025-01-15 10:32:09,198 - Epoch: 38 Train acc: 99.34727272727272 Val acc: 81.96 Test acc82.38; Train loss: 7.167915688319639e-05 Val loss: 0.0015781575441360474
INFO - evaluator.py - 2025-01-15 10:32:26,987 - Epoch: 39 Train acc: 99.58545454545454 Val acc: 82.5 Test acc82.77; Train loss: 4.6423484450629487e-05 Val loss: 0.0015943464279174805
INFO - evaluator.py - 2025-01-15 10:32:44,775 - Epoch: 40 Train acc: 99.88545454545455 Val acc: 82.38 Test acc82.92; Train loss: 1.7499199141854082e-05 Val loss: 0.0016567661762237548
INFO - evaluator.py - 2025-01-15 10:33:02,577 - Epoch: 41 Train acc: 99.96909090909091 Val acc: 81.88 Test acc82.26; Train loss: 6.796835164211436e-06 Val loss: 0.0017894559383392335
INFO - evaluator.py - 2025-01-15 10:33:20,370 - Epoch: 42 Train acc: 99.98727272727272 Val acc: 82.02000000000001 Test acc82.16; Train loss: 3.8105874658371745e-06 Val loss: 0.0018503767728805542
INFO - evaluator.py - 2025-01-15 10:33:38,284 - Epoch: 43 Train acc: 99.99818181818182 Val acc: 81.8 Test acc81.94; Train loss: 2.7136150571591728e-06 Val loss: 0.00193055739402771
INFO - evaluator.py - 2025-01-15 10:33:56,069 - Epoch: 44 Train acc: 99.99636363636364 Val acc: 81.84 Test acc81.89999999999999; Train loss: 2.6260827417982825e-06 Val loss: 0.0019736071825027465
INFO - evaluator.py - 2025-01-15 10:34:13,857 - Epoch: 45 Train acc: 99.99818181818182 Val acc: 81.88 Test acc81.86; Train loss: 1.8812897333356722e-06 Val loss: 0.002020765519142151
INFO - evaluator.py - 2025-01-15 10:34:31,634 - Epoch: 46 Train acc: 99.99818181818182 Val acc: 81.84 Test acc81.92; Train loss: 1.7777890076765536e-06 Val loss: 0.0020691715002059937
INFO - evaluator.py - 2025-01-15 10:34:49,413 - Epoch: 47 Train acc: 100.0 Val acc: 81.76 Test acc81.76; Train loss: 1.3113237883027812e-06 Val loss: 0.0021588831424713133
INFO - evaluator.py - 2025-01-15 10:35:07,207 - Epoch: 48 Train acc: 100.0 Val acc: 81.36 Test acc81.44; Train loss: 1.342180013241225e-06 Val loss: 0.002206473970413208
INFO - evaluator.py - 2025-01-15 10:35:24,997 - Epoch: 49 Train acc: 100.0 Val acc: 80.7 Test acc81.12; Train loss: 1.0280276863671712e-06 Val loss: 0.0022914047241210937
INFO - evaluator.py - 2025-01-15 10:35:25,010 - The best acc of synthetic images on sensitive val and the corresponding acc on test dataset from resnet is 83.32000000000001 and 83.27
INFO - evaluator.py - 2025-01-15 10:35:25,010 - The best acc of synthetic images on noisy sensitive val and the corresponding acc on test dataset from resnet is 83.32000000000001 and 83.27
INFO - evaluator.py - 2025-01-15 10:35:25,010 - The best acc test dataset from resnet is 83.39999999999999
INFO - evaluator.py - 2025-01-15 10:35:47,509 - Epoch: 0 Train acc: 61.56181818181818 Val acc: 76.84 Test acc76.79; Train loss: 0.003860236038944938 Val loss: 0.0006064750194549561
INFO - evaluator.py - 2025-01-15 10:36:09,296 - Epoch: 1 Train acc: 73.65454545454546 Val acc: 79.2 Test acc79.23; Train loss: 0.0026515161189165984 Val loss: 0.0005584351420402526
INFO - evaluator.py - 2025-01-15 10:36:31,142 - Epoch: 2 Train acc: 76.31272727272727 Val acc: 80.08 Test acc79.94; Train loss: 0.002369267986579375 Val loss: 0.0005380274176597595
INFO - evaluator.py - 2025-01-15 10:36:52,997 - Epoch: 3 Train acc: 77.7309090909091 Val acc: 81.17999999999999 Test acc81.52000000000001; Train loss: 0.002230269738219001 Val loss: 0.0004915734469890594
INFO - evaluator.py - 2025-01-15 10:37:14,833 - Epoch: 4 Train acc: 78.88181818181819 Val acc: 82.36 Test acc82.26; Train loss: 0.0021288025899366897 Val loss: 0.00047126196622848513
INFO - evaluator.py - 2025-01-15 10:37:36,679 - Epoch: 5 Train acc: 79.71818181818182 Val acc: 82.6 Test acc82.64; Train loss: 0.002044388474659486 Val loss: 0.0004631267786026001
INFO - evaluator.py - 2025-01-15 10:37:58,489 - Epoch: 6 Train acc: 80.69454545454545 Val acc: 82.39999999999999 Test acc82.78; Train loss: 0.0019691939120942896 Val loss: 0.0004537336587905884
INFO - evaluator.py - 2025-01-15 10:38:20,275 - Epoch: 7 Train acc: 81.21818181818182 Val acc: 78.48 Test acc78.17; Train loss: 0.001899457769502293 Val loss: 0.0005861717700958252
INFO - evaluator.py - 2025-01-15 10:38:42,171 - Epoch: 8 Train acc: 81.76545454545455 Val acc: 81.17999999999999 Test acc81.49; Train loss: 0.0018529877001588996 Val loss: 0.00049238760471344
INFO - evaluator.py - 2025-01-15 10:39:03,928 - Epoch: 9 Train acc: 82.22181818181818 Val acc: 82.19999999999999 Test acc82.07; Train loss: 0.0018009676505218852 Val loss: 0.0005048924922943115
INFO - evaluator.py - 2025-01-15 10:39:25,674 - Epoch: 10 Train acc: 82.74000000000001 Val acc: 78.36 Test acc78.13; Train loss: 0.0017580783502622085 Val loss: 0.0005927799463272095
INFO - evaluator.py - 2025-01-15 10:39:47,429 - Epoch: 11 Train acc: 83.12363636363636 Val acc: 78.78 Test acc78.89; Train loss: 0.0016982453470880336 Val loss: 0.000558082640171051
INFO - evaluator.py - 2025-01-15 10:40:09,181 - Epoch: 12 Train acc: 83.75090909090909 Val acc: 80.17999999999999 Test acc80.01; Train loss: 0.0016542057882655752 Val loss: 0.0005532352209091187
INFO - evaluator.py - 2025-01-15 10:40:30,924 - Epoch: 13 Train acc: 84.10363636363635 Val acc: 81.76 Test acc82.27; Train loss: 0.0016056228160858154 Val loss: 0.0005073603630065918
INFO - evaluator.py - 2025-01-15 10:40:52,656 - Epoch: 14 Train acc: 84.56727272727272 Val acc: 81.82000000000001 Test acc81.67999999999999; Train loss: 0.0015666796654462815 Val loss: 0.00048191310763359067
INFO - evaluator.py - 2025-01-15 10:41:14,509 - Epoch: 15 Train acc: 85.03090909090909 Val acc: 77.92 Test acc77.56; Train loss: 0.001511458496613936 Val loss: 0.0006065353631973267
INFO - evaluator.py - 2025-01-15 10:41:36,231 - Epoch: 16 Train acc: 85.78727272727272 Val acc: 78.78 Test acc78.97; Train loss: 0.0014474217634309421 Val loss: 0.0005974384546279907
INFO - evaluator.py - 2025-01-15 10:41:57,964 - Epoch: 17 Train acc: 86.30363636363636 Val acc: 83.17999999999999 Test acc83.5; Train loss: 0.0013899326692927967 Val loss: 0.0004893086433410645
INFO - evaluator.py - 2025-01-15 10:42:19,674 - Epoch: 18 Train acc: 87.15636363636364 Val acc: 77.60000000000001 Test acc77.03999999999999; Train loss: 0.0013122136059132488 Val loss: 0.0006566752552986145
INFO - evaluator.py - 2025-01-15 10:42:41,398 - Epoch: 19 Train acc: 87.90727272727273 Val acc: 80.80000000000001 Test acc80.95; Train loss: 0.0012340349397876047 Val loss: 0.0005574621796607971
INFO - evaluator.py - 2025-01-15 10:43:03,104 - Epoch: 20 Train acc: 91.24545454545454 Val acc: 83.28 Test acc83.88; Train loss: 0.0009223750268871134 Val loss: 0.0005809439539909363
INFO - evaluator.py - 2025-01-15 10:43:24,823 - Epoch: 21 Train acc: 92.44545454545454 Val acc: 82.8 Test acc83.21; Train loss: 0.0007816601826386018 Val loss: 0.0006787328124046325
INFO - evaluator.py - 2025-01-15 10:43:46,546 - Epoch: 22 Train acc: 93.4090909090909 Val acc: 82.46 Test acc82.97; Train loss: 0.0006886153853752396 Val loss: 0.0007679833889007568
INFO - evaluator.py - 2025-01-15 10:44:08,379 - Epoch: 23 Train acc: 93.82909090909091 Val acc: 81.89999999999999 Test acc82.05; Train loss: 0.0006385593705556609 Val loss: 0.0008440041184425354
INFO - evaluator.py - 2025-01-15 10:44:30,099 - Epoch: 24 Train acc: 94.5909090909091 Val acc: 80.96 Test acc80.93; Train loss: 0.0005653895596211606 Val loss: 0.0009351243615150452
INFO - evaluator.py - 2025-01-15 10:44:51,816 - Epoch: 25 Train acc: 95.02181818181819 Val acc: 80.86 Test acc80.73; Train loss: 0.0005152561064470898 Val loss: 0.0010124528288841248
INFO - evaluator.py - 2025-01-15 10:45:13,529 - Epoch: 26 Train acc: 95.55090909090909 Val acc: 82.12 Test acc82.08; Train loss: 0.0004590181981975382 Val loss: 0.0009470473885536194
INFO - evaluator.py - 2025-01-15 10:45:35,267 - Epoch: 27 Train acc: 96.02181818181819 Val acc: 81.2 Test acc80.95; Train loss: 0.00041422763683579187 Val loss: 0.0011091623067855834
INFO - evaluator.py - 2025-01-15 10:45:56,997 - Epoch: 28 Train acc: 96.42545454545454 Val acc: 80.54 Test acc80.80000000000001; Train loss: 0.0003736302808604457 Val loss: 0.0011468283653259278
INFO - evaluator.py - 2025-01-15 10:46:18,700 - Epoch: 29 Train acc: 96.84545454545454 Val acc: 78.96 Test acc79.05; Train loss: 0.00033466347838667307 Val loss: 0.0013312138080596924
INFO - evaluator.py - 2025-01-15 10:46:40,548 - Epoch: 30 Train acc: 96.9909090909091 Val acc: 80.24 Test acc80.05; Train loss: 0.00031525927741419185 Val loss: 0.0012695242643356323
INFO - evaluator.py - 2025-01-15 10:47:02,246 - Epoch: 31 Train acc: 97.40545454545455 Val acc: 80.60000000000001 Test acc80.53; Train loss: 0.0002705740566958081 Val loss: 0.001273473024368286
INFO - evaluator.py - 2025-01-15 10:47:23,933 - Epoch: 32 Train acc: 97.47818181818182 Val acc: 82.56 Test acc82.3; Train loss: 0.0002626383962279016 Val loss: 0.0011476135730743408
INFO - evaluator.py - 2025-01-15 10:47:45,628 - Epoch: 33 Train acc: 97.92727272727274 Val acc: 81.08 Test acc80.89; Train loss: 0.00022761983141641724 Val loss: 0.0013620707511901855
INFO - evaluator.py - 2025-01-15 10:48:07,350 - Epoch: 34 Train acc: 97.98181818181818 Val acc: 82.52000000000001 Test acc82.65; Train loss: 0.0002151077512313019 Val loss: 0.0011776625633239746
INFO - evaluator.py - 2025-01-15 10:48:29,062 - Epoch: 35 Train acc: 98.0490909090909 Val acc: 82.1 Test acc82.09; Train loss: 0.00020454469282518733 Val loss: 0.0013266005277633667
INFO - evaluator.py - 2025-01-15 10:48:50,786 - Epoch: 36 Train acc: 98.31090909090909 Val acc: 82.32000000000001 Test acc82.11; Train loss: 0.00017986449910835787 Val loss: 0.0013362976789474488
INFO - evaluator.py - 2025-01-15 10:49:12,630 - Epoch: 37 Train acc: 98.39818181818181 Val acc: 80.72 Test acc81.03; Train loss: 0.00017109538953412662 Val loss: 0.0014534226894378662
INFO - evaluator.py - 2025-01-15 10:49:34,338 - Epoch: 38 Train acc: 98.49454545454546 Val acc: 81.66 Test acc81.53; Train loss: 0.0001620746838267554 Val loss: 0.0014001237630844117
INFO - evaluator.py - 2025-01-15 10:49:56,059 - Epoch: 39 Train acc: 98.46545454545455 Val acc: 81.92 Test acc81.72; Train loss: 0.0001638109119947661 Val loss: 0.0013968143939971924
INFO - evaluator.py - 2025-01-15 10:50:17,764 - Epoch: 40 Train acc: 98.96727272727273 Val acc: 81.82000000000001 Test acc81.86; Train loss: 0.00011848705862225457 Val loss: 0.001394519019126892
INFO - evaluator.py - 2025-01-15 10:50:39,488 - Epoch: 41 Train acc: 99.20545454545454 Val acc: 82.0 Test acc82.04; Train loss: 9.260275887156074e-05 Val loss: 0.0013907790184020997
INFO - evaluator.py - 2025-01-15 10:51:01,200 - Epoch: 42 Train acc: 99.23636363636363 Val acc: 81.78 Test acc81.89; Train loss: 8.988859706812284e-05 Val loss: 0.0014340370893478394
INFO - evaluator.py - 2025-01-15 10:51:22,912 - Epoch: 43 Train acc: 99.27454545454546 Val acc: 82.24000000000001 Test acc82.28; Train loss: 8.206697427667677e-05 Val loss: 0.00140625638961792
INFO - evaluator.py - 2025-01-15 10:51:44,651 - Epoch: 44 Train acc: 99.27272727272727 Val acc: 82.02000000000001 Test acc82.23; Train loss: 7.933617235923355e-05 Val loss: 0.0014610793352127075
INFO - evaluator.py - 2025-01-15 10:52:06,487 - Epoch: 45 Train acc: 99.34181818181818 Val acc: 81.67999999999999 Test acc81.78; Train loss: 7.176298514347185e-05 Val loss: 0.0015684335470199586
INFO - evaluator.py - 2025-01-15 10:52:28,214 - Epoch: 46 Train acc: 99.40363636363637 Val acc: 81.82000000000001 Test acc81.88; Train loss: 6.734232049096715e-05 Val loss: 0.0015329000949859618
INFO - evaluator.py - 2025-01-15 10:52:49,938 - Epoch: 47 Train acc: 99.38545454545455 Val acc: 82.1 Test acc82.17999999999999; Train loss: 6.911328358745033e-05 Val loss: 0.0014934947967529296
INFO - evaluator.py - 2025-01-15 10:53:11,664 - Epoch: 48 Train acc: 99.47272727272727 Val acc: 82.12 Test acc81.98; Train loss: 6.259975518438626e-05 Val loss: 0.0015445889711380005
INFO - evaluator.py - 2025-01-15 10:53:33,375 - Epoch: 49 Train acc: 99.34545454545454 Val acc: 81.52000000000001 Test acc81.67; Train loss: 7.407457893714308e-05 Val loss: 0.0016382909297943116
INFO - evaluator.py - 2025-01-15 10:53:33,380 - The best acc of synthetic images on sensitive val and the corresponding acc on test dataset from wrn is 83.28 and 83.88
INFO - evaluator.py - 2025-01-15 10:53:33,380 - The best acc of synthetic images on noisy sensitive val and the corresponding acc on test dataset from wrn is 83.28 and 83.88
INFO - evaluator.py - 2025-01-15 10:53:33,380 - The best acc test dataset from wrn is 83.88
INFO - evaluator.py - 2025-01-15 10:55:01,280 - Epoch: 0 Train acc: 51.84727272727273 Val acc: 68.96 Test acc69.16; Train loss: 0.005830095650933006 Val loss: 0.0008623505711555481
INFO - evaluator.py - 2025-01-15 10:56:27,295 - Epoch: 1 Train acc: 71.73272727272727 Val acc: 72.1 Test acc72.45; Train loss: 0.002838030348040841 Val loss: 0.000803477418422699
INFO - evaluator.py - 2025-01-15 10:57:53,300 - Epoch: 2 Train acc: 75.3709090909091 Val acc: 79.88 Test acc79.72; Train loss: 0.002466308742761612 Val loss: 0.000543397831916809
INFO - evaluator.py - 2025-01-15 10:59:19,081 - Epoch: 3 Train acc: 77.45818181818181 Val acc: 80.56 Test acc80.71000000000001; Train loss: 0.002276589798927307 Val loss: 0.000507809042930603
INFO - evaluator.py - 2025-01-15 11:00:44,831 - Epoch: 4 Train acc: 78.66181818181818 Val acc: 80.5 Test acc80.69; Train loss: 0.0021360692712393673 Val loss: 0.0005219313502311707
INFO - evaluator.py - 2025-01-15 11:02:10,568 - Epoch: 5 Train acc: 80.03454545454545 Val acc: 81.72 Test acc81.89999999999999; Train loss: 0.0020162702587517827 Val loss: 0.0004920095264911652
INFO - evaluator.py - 2025-01-15 11:03:36,302 - Epoch: 6 Train acc: 80.86909090909091 Val acc: 82.58 Test acc82.62; Train loss: 0.0019387153966860338 Val loss: 0.0004676758170127869
INFO - evaluator.py - 2025-01-15 11:05:02,025 - Epoch: 7 Train acc: 81.63090909090909 Val acc: 77.60000000000001 Test acc78.14999999999999; Train loss: 0.0018729372333396565 Val loss: 0.0006112368106842041
INFO - evaluator.py - 2025-01-15 11:06:27,761 - Epoch: 8 Train acc: 82.39272727272727 Val acc: 82.08 Test acc82.47; Train loss: 0.0017855741858482362 Val loss: 0.0004804058372974396
INFO - evaluator.py - 2025-01-15 11:07:53,473 - Epoch: 9 Train acc: 82.87454545454545 Val acc: 75.82 Test acc75.35; Train loss: 0.0017339987781914798 Val loss: 0.000679136323928833
INFO - evaluator.py - 2025-01-15 11:09:19,288 - Epoch: 10 Train acc: 83.5109090909091 Val acc: 71.94 Test acc72.03; Train loss: 0.001665953592820601 Val loss: 0.0008633078336715698
INFO - evaluator.py - 2025-01-15 11:10:44,998 - Epoch: 11 Train acc: 84.16 Val acc: 74.82 Test acc74.92999999999999; Train loss: 0.0016029057253490796 Val loss: 0.0007591527342796326
INFO - evaluator.py - 2025-01-15 11:12:10,688 - Epoch: 12 Train acc: 84.82363636363637 Val acc: 78.97999999999999 Test acc79.42; Train loss: 0.0015258919336579063 Val loss: 0.0006256853222846985
INFO - evaluator.py - 2025-01-15 11:13:36,353 - Epoch: 13 Train acc: 85.6381818181818 Val acc: 72.14 Test acc72.35000000000001; Train loss: 0.0014391201425682414 Val loss: 0.0008971390843391418
INFO - evaluator.py - 2025-01-15 11:15:02,015 - Epoch: 14 Train acc: 86.65454545454546 Val acc: 74.76 Test acc74.42; Train loss: 0.0013649401556361806 Val loss: 0.0007458385944366455
INFO - evaluator.py - 2025-01-15 11:16:27,683 - Epoch: 15 Train acc: 87.6509090909091 Val acc: 76.1 Test acc76.8; Train loss: 0.0012614514979449186 Val loss: 0.0006803716540336609
INFO - evaluator.py - 2025-01-15 11:17:53,320 - Epoch: 16 Train acc: 88.83454545454545 Val acc: 77.03999999999999 Test acc77.56; Train loss: 0.0011564218518408862 Val loss: 0.0006751429200172424
INFO - evaluator.py - 2025-01-15 11:19:19,069 - Epoch: 17 Train acc: 89.54727272727273 Val acc: 76.08 Test acc76.12; Train loss: 0.0010539290509440683 Val loss: 0.0007248161435127259
INFO - evaluator.py - 2025-01-15 11:20:44,702 - Epoch: 18 Train acc: 90.92727272727272 Val acc: 70.3 Test acc70.64; Train loss: 0.0009211222030899741 Val loss: 0.0009146761178970337
INFO - evaluator.py - 2025-01-15 11:22:10,318 - Epoch: 19 Train acc: 92.0909090909091 Val acc: 70.74000000000001 Test acc70.98; Train loss: 0.0008187629392201251 Val loss: 0.0009087031841278076
INFO - evaluator.py - 2025-01-15 11:23:35,927 - Epoch: 20 Train acc: 97.81272727272727 Val acc: 80.62 Test acc80.49; Train loss: 0.0002744192819365046 Val loss: 0.0006618099331855774
INFO - evaluator.py - 2025-01-15 11:25:01,555 - Epoch: 21 Train acc: 99.7 Val acc: 82.46 Test acc82.74000000000001; Train loss: 7.104350728914142e-05 Val loss: 0.0007011846542358399
INFO - evaluator.py - 2025-01-15 11:26:27,175 - Epoch: 22 Train acc: 99.96545454545455 Val acc: 83.12 Test acc83.37; Train loss: 2.3958759919994257e-05 Val loss: 0.0007947166800498963
INFO - evaluator.py - 2025-01-15 11:27:52,782 - Epoch: 23 Train acc: 99.9890909090909 Val acc: 83.26 Test acc83.56; Train loss: 1.1242874087342484e-05 Val loss: 0.0009248854517936707
INFO - evaluator.py - 2025-01-15 11:29:18,381 - Epoch: 24 Train acc: 99.99818181818182 Val acc: 83.17999999999999 Test acc83.27; Train loss: 6.176902537911453e-06 Val loss: 0.0010420073866844177
INFO - evaluator.py - 2025-01-15 11:30:44,118 - Epoch: 25 Train acc: 100.0 Val acc: 82.74000000000001 Test acc82.89999999999999; Train loss: 3.9457693103362215e-06 Val loss: 0.0011678006887435913
INFO - evaluator.py - 2025-01-15 11:32:09,758 - Epoch: 26 Train acc: 100.0 Val acc: 82.72 Test acc82.61; Train loss: 3.0185862206218935e-06 Val loss: 0.001261953115463257
INFO - evaluator.py - 2025-01-15 11:33:35,381 - Epoch: 27 Train acc: 100.0 Val acc: 82.42 Test acc82.59; Train loss: 2.135984960213219e-06 Val loss: 0.001333007264137268
INFO - evaluator.py - 2025-01-15 11:35:00,972 - Epoch: 28 Train acc: 100.0 Val acc: 81.74 Test acc81.96; Train loss: 1.682584839925932e-06 Val loss: 0.001466736674308777
INFO - evaluator.py - 2025-01-15 11:36:26,571 - Epoch: 29 Train acc: 99.99818181818182 Val acc: 81.56 Test acc81.54; Train loss: 1.8669915245316754e-06 Val loss: 0.001572280216217041
INFO - evaluator.py - 2025-01-15 11:37:52,196 - Epoch: 30 Train acc: 100.0 Val acc: 82.19999999999999 Test acc82.24000000000001; Train loss: 1.276396743725689e-06 Val loss: 0.0015377976417541503
INFO - evaluator.py - 2025-01-15 11:39:17,806 - Epoch: 31 Train acc: 100.0 Val acc: 81.72 Test acc82.06; Train loss: 8.847500958257694e-07 Val loss: 0.001617014479637146
INFO - evaluator.py - 2025-01-15 11:40:43,526 - Epoch: 32 Train acc: 100.0 Val acc: 81.34 Test acc81.62; Train loss: 6.985437143488194e-07 Val loss: 0.001723986315727234
INFO - evaluator.py - 2025-01-15 11:42:09,122 - Epoch: 33 Train acc: 100.0 Val acc: 81.38 Test acc81.57; Train loss: 5.904874843756923e-07 Val loss: 0.0017623224020004273
INFO - evaluator.py - 2025-01-15 11:43:34,743 - Epoch: 34 Train acc: 100.0 Val acc: 81.36 Test acc81.52000000000001; Train loss: 5.099558280727996e-07 Val loss: 0.0017804141759872436
INFO - evaluator.py - 2025-01-15 11:45:00,350 - Epoch: 35 Train acc: 100.0 Val acc: 81.06 Test acc81.37; Train loss: 4.3602298974292354e-07 Val loss: 0.001859593939781189
INFO - evaluator.py - 2025-01-15 11:46:25,956 - Epoch: 36 Train acc: 100.0 Val acc: 81.34 Test acc81.58999999999999; Train loss: 3.4449732887548054e-07 Val loss: 0.0018701963424682616
INFO - evaluator.py - 2025-01-15 11:47:51,560 - Epoch: 37 Train acc: 100.0 Val acc: 81.17999999999999 Test acc81.25; Train loss: 2.8745943944324444e-07 Val loss: 0.0019368406295776368
INFO - evaluator.py - 2025-01-15 11:49:17,181 - Epoch: 38 Train acc: 100.0 Val acc: 81.22 Test acc81.3; Train loss: 2.668801108732375e-07 Val loss: 0.0019563653230667112
INFO - evaluator.py - 2025-01-15 11:50:42,797 - Epoch: 39 Train acc: 100.0 Val acc: 80.94 Test acc81.08; Train loss: 2.3168182802196085e-07 Val loss: 0.002000943398475647
INFO - evaluator.py - 2025-01-15 11:52:08,524 - Epoch: 40 Train acc: 100.0 Val acc: 81.2 Test acc81.35; Train loss: 1.8947083233136007e-07 Val loss: 0.0020050493478775025
INFO - evaluator.py - 2025-01-15 11:53:34,116 - Epoch: 41 Train acc: 100.0 Val acc: 81.02000000000001 Test acc81.08; Train loss: 1.8517338698571126e-07 Val loss: 0.002060518479347229
INFO - evaluator.py - 2025-01-15 11:54:59,725 - Epoch: 42 Train acc: 100.0 Val acc: 81.14 Test acc81.17; Train loss: 1.8149042642273178e-07 Val loss: 0.002067263078689575
INFO - evaluator.py - 2025-01-15 11:56:25,324 - Epoch: 43 Train acc: 100.0 Val acc: 81.17999999999999 Test acc81.24; Train loss: 1.8491339112436188e-07 Val loss: 0.002060171175003052
INFO - evaluator.py - 2025-01-15 11:57:50,940 - Epoch: 44 Train acc: 100.0 Val acc: 81.26 Test acc81.43; Train loss: 1.6183913149606352e-07 Val loss: 0.002069420075416565
INFO - evaluator.py - 2025-01-15 11:59:16,536 - Epoch: 45 Train acc: 99.99818181818182 Val acc: 80.80000000000001 Test acc80.88; Train loss: 5.572433893989497e-07 Val loss: 0.0021484893798828127
INFO - evaluator.py - 2025-01-15 12:00:42,138 - Epoch: 46 Train acc: 100.0 Val acc: 80.88 Test acc80.96; Train loss: 2.548308976574018e-07 Val loss: 0.002143903112411499
INFO - evaluator.py - 2025-01-15 12:02:07,871 - Epoch: 47 Train acc: 100.0 Val acc: 81.0 Test acc81.06; Train loss: 1.738699636916863e-07 Val loss: 0.002146812725067139
INFO - evaluator.py - 2025-01-15 12:03:33,465 - Epoch: 48 Train acc: 100.0 Val acc: 81.24 Test acc81.31; Train loss: 1.5906248895176264e-07 Val loss: 0.0021057296991348266
INFO - evaluator.py - 2025-01-15 12:04:59,062 - Epoch: 49 Train acc: 100.0 Val acc: 81.2 Test acc81.34; Train loss: 1.5309200404193358e-07 Val loss: 0.00210921835899353
INFO - evaluator.py - 2025-01-15 12:04:59,065 - The best acc of synthetic images on sensitive val and the corresponding acc on test dataset from resnext is 83.26 and 83.56
INFO - evaluator.py - 2025-01-15 12:04:59,065 - The best acc of synthetic images on noisy sensitive val and the corresponding acc on test dataset from resnext is 83.26 and 83.56
INFO - evaluator.py - 2025-01-15 12:04:59,065 - The best acc test dataset from resnext is 83.56
INFO - evaluator.py - 2025-01-15 12:04:59,065 - The best acc of accuracy (adding noise to the results on the sensitive set of validation set) of synthetic images from resnet, wrn, and resnext are [83.27, 83.88, 83.56].
INFO - evaluator.py - 2025-01-15 12:04:59,066 - The average and std of accuracy of synthetic images are 83.57 and 0.25
INFO - evaluator.py - 2025-01-15 12:27:21,394 - The FID of synthetic images is 43.679509951771934
INFO - evaluator.py - 2025-01-15 12:27:21,395 - The Inception Score of synthetic images is 3.9836769104003906
INFO - evaluator.py - 2025-01-15 12:27:21,395 - The Precision and Recall of synthetic images is 0.2640833258628845 and 0.534166693687439
INFO - evaluator.py - 2025-01-15 12:27:21,395 - The FLD of synthetic images is 15.27392864227295
INFO - evaluator.py - 2025-01-15 12:27:21,396 - The ImageReward of synthetic images is -1.8956167590219213
