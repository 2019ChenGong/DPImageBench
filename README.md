<div align=center>
  
# DPImageBench: A Unified Benchmark for Differentially Private Image Synthesis Algorithms
</div>

## 1. Contents
  - [1. Contents](#1-contents)
  - [2. Introduction](#2-introduction)
    - [2.1 Currently Supported Algorithms](#21-currently-supported-algorithms)
  - [3. Repo Contents](#3-repo-contents)
  - [3. Get Start](#3-get-start)
    - [3.1 Installation](#31-installation)
    - [3.2 Dataset and Files Preparation](#32-dataset-and-files-preparation)
    - [3.3 Training](#33-training)
    - [3.4 Inference](#34-inference)
  - [4. Contacts](#4-contacts)
  - [5. Acknowledgment](#5-acknowledgment)

## Updates 
- ðŸŽ‰ **(2024.11.19)** We're thrilled to announce the release of initial version of DPImageBench!

## Todo

- [ ] recoding the intermediate results of methods with tqdm.

- [ ] setup.master_port=6026

- [ ] keep consistent cond and uncond for dm and gan

- [ ] GSWGAN merge

- [ ] use a bash to represent installation.

- [ ] End to end implementation for PrivImage

## 2. Introduction

### 2.1 Currently Supported Algorithms

We list currently supported DP image synthesis methods as follows.

  | Methods |  Link                                                         |
  | -------------- | ------------------------------------------------------------ |
  | DP-MERF            |  [\[AISTATS 2021\] DP-MERF: Differentially Private Mean Embeddings With Randomfeatures for Practical Privacy-Preserving Data Generation](https://proceedings.mlr.press/v130/harder21a.html) |
  | DP-NTK            |  [\[AISTATS 2021\] Differentially Private Neural Tangent Kernels (DP-NTK) for Privacy-Preserving Data Generation](https://arxiv.org/html/2303.01687v2) |
  | DP-Kernel        |  [\[NeuriPS 2023\] Functional Renyi Differential Privacy for Generative Modeling](https://proceedings.neurips.cc/paper_files/paper/2023/hash/2f9ee101e35b890d9eae79ee27bcd69a-Abstract-Conference.html) |
  | PE          |  [\[ICLR 2024\] Differentially Private Synthetic Data via Foundation Model {API}s 1: Images](https://openreview.net/forum?id=YEhQs8POIo) |
  | GS-WGAN            |  [\[NeuriPS 2020\] GS-WGAN: A Gradient-Sanitized Approach for Learning Differentially Private Generators](https://arxiv.org/pdf/2006.08265) |
  | DP-GAN            |  [\[1802.06739\] Differentially Private Generative Adversarial Network (arxiv.org)](https://arxiv.org/abs/1802.06739) |
  | DPDM          |  [\[TMLR 2023\] Differentially Private Diffusion Models](https://openreview.net/forum?id=ZPpQk7FJXF) |
  | PDP-Diffusion       | [\[2302.13861\] Differentially Private Diffusion Models Generate Useful Synthetic Images (arxiv.org)](https://arxiv.org/abs/2305.15759) |
  | DP-LDM            | [\[TMLR 2024\] Differentially Private Latent Diffusion Models (arxiv.org)](https://arxiv.org/abs/2302.13861)            |
  | PrivImage       | [\[UESNIX Security 2024\] PrivImage: Differentially Private Synthetic Image Generation using Diffusion Models with Semantic-Aware Pretraining](https://www.usenix.org/conference/usenixsecurity24/presentation/li-kecen) |


## 3. Repo Contents

Below is the directory structure of the DPImageBench project, which encapsulates its three core functionalities within the watermark/, visualize/, and evaluation/ directories. To facilitate user understanding and demonstrate the toolkit's ease of use, we provide a variety of test cases. The test code can be found in the test/ directory.


```plaintext
DPImageBench/
â”œâ”€â”€ config/                     # Configuration files for various DP image synthesis algorithms
â”‚   â”œâ”€â”€            
â”‚   â”œâ”€â”€ DP-MERF      
â”‚   â”œâ”€â”€ DP-NTK       
â”‚   â”œâ”€â”€ DP-Kernel
â”‚   â”œâ”€â”€ PE            
â”‚   â”œâ”€â”€ DP-GAN         
â”‚   â”œâ”€â”€ DPDM        
â”‚   â”œâ”€â”€ PDP-Diffusion      
â”‚   â”œâ”€â”€ DP-LDM   
â”‚   â”œâ”€â”€ GS-WGAN
â”‚   â””â”€â”€ PDP-Diffusion         
â”œâ”€â”€ dataset/                    # Datasets studied in the project
â”‚   â”œâ”€â”€ camelyon/
â”‚   â”œâ”€â”€ celeba/
â”‚   â”œâ”€â”€ imagenet/
â”‚   â”œâ”€â”€ mnist/
â”‚   â””â”€â”€ wmt16_de_en/
â”œâ”€â”€ evaluation/                 # Evaluation module of MarkLLM, including tools and pipelines
â”‚   â”œâ”€â”€ dataset.py              # Script for handling dataset operations within evaluations
â”‚   â”œâ”€â”€ examples/               # Scripts for automated evaluations using pipelines
â”‚   â”‚   â”œâ”€â”€ assess_detectability.py  
â”‚   â”‚   â”œâ”€â”€ assess_quality.py    
â”‚   â”‚   â””â”€â”€ assess_robustness.py   
â”‚   â”œâ”€â”€ pipelines/              # Pipelines for structured evaluation processes
â”‚   â”‚   â”œâ”€â”€ detection.py    
â”‚   â”‚   â””â”€â”€ quality_analysis.py 
â”‚   â””â”€â”€ tools/                  # Evaluation tools
â”‚       â”œâ”€â”€ oracle.py
â”‚       â”œâ”€â”€ success_rate_calculator.py  
        â”œâ”€â”€ text_editor.py         
â”‚       â””â”€â”€ text_quality_analyzer.py   
â”œâ”€â”€ exceptions/                 # Custom exception definitions for error handling
â”‚   â””â”€â”€ exceptions.py
â”œâ”€â”€ font/                       # Fonts needed for visualization purposes
â”œâ”€â”€ MarkLLM_demo.ipynb          # Jupyter Notebook
â”œâ”€â”€ test/                       # Test cases and examples for user testing
â”‚   â”œâ”€â”€ test_method.py      
â”‚   â”œâ”€â”€ test_pipeline.py    
â”‚   â””â”€â”€ test_visualize.py   
â”œâ”€â”€ utils/                      # Helper classes and functions supporting various operations
â”‚   â”œâ”€â”€ openai_utils.py     
â”‚   â”œâ”€â”€ transformers_config.py 
â”‚   â””â”€â”€ utils.py            
â”œâ”€â”€ visualize/                  # Visualization Solutions module of MarkLLM
â”‚   â”œâ”€â”€ color_scheme.py    
â”‚   â”œâ”€â”€ data_for_visualization.py  
â”‚   â”œâ”€â”€ font_settings.py    
â”‚   â”œâ”€â”€ legend_settings.py  
â”‚   â”œâ”€â”€ page_layout_settings.py 
â”‚   â””â”€â”€ visualizer.py       
â”œâ”€â”€ watermark/                  # Implementation framework for watermark algorithms
â”‚   â”œâ”€â”€ auto_watermark.py       # AutoWatermark class
â”‚   â”œâ”€â”€ base.py                 # Base classes and functions for watermarking
â”‚   â”œâ”€â”€ ewd/                
â”‚   â”œâ”€â”€ exp/               
â”‚   â”œâ”€â”€ exp_edit/          
â”‚   â”œâ”€â”€ kgw/
â”‚   â”œâ”€â”€ its_edit/                 
â”‚   â”œâ”€â”€ sir/               
â”‚   â”œâ”€â”€ sweet/              
â”‚   â”œâ”€â”€ unigram/           
â”‚   â”œâ”€â”€ upv/                
â”‚   â””â”€â”€ xsir/               
â”œâ”€â”€ README.md                   # Main project documentation
â””â”€â”€ requirements.txt            # Dependencies required for the project
```

## 3. Get Start on DPImageBench

### 3.1 Install DPImageBench

 ```
conda create -n dpimagebench python=3.7
conda activate dpimagebench
pip install torch==1.12.1+cu116 torchvision==0.13.1+cu116 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu116
pip install tensorflow-gpu==1.14.0
pip install requirements.txt
cd opacus; pip install -e .; cd ..
cd models/PE/improved-diffusion; pip install -e .; cd ..; cd ..; cd ..
cd models; gdown https://drive.google.com/uc?id=1yVTWzaSqJVDJy8CsZKtqDoBNeM6154D4; unzip pretrained_models.zip; cd ..
 ```

### 3.2 Prepare Dataset

 ```
mkdir dataset
sh scripts/download_dataset.sh
python preprocess_dataset.py; cd ..
 ```

### 3.3 Running

 ```
conda activate dpimagebench
cd DPImageBench
python run.py --config configs/{model_name}/{dataset_name}_eps{epsilon}.yaml
 ```

Available `model_name` are [`DP-NTK`, `DP-Kernel`, `DP-LDM`, `DP-MERF`, `DP-Promise`, `DPDM`, `PE`, `G-PATE`, `PDP-Diffusion`, `PrivImage`].

Available `epsilon` is [`1.0`].

Available `dataset_name` is [`mnist_28`].

So far, I have only implemented FID in our evaluation.
